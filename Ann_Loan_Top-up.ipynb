{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVyy9I2Nchso",
    "outputId": "59769d02-8e88-4ecd-cd0d-6d566c485aed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Load the Drive helper and mount\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fD_x6cGrcj-a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"D:/Study/Hackathon analytics vidhya/Hackathon LTFS 3 30012021/Data Prepared for Modelling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yAWpUrmUcuE9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# roc curve and auc score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Khh9-iKgdOkl",
    "outputId": "ed4da944-967c-4fca-a7a1-f5ce7697b5db"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"df_train2_corr_removed.csv\")\n",
    "df_test = pd.read_csv('df_test2_corr_removed.csv')\n",
    "df_train = pd.read_csv(\"D:/Study/Hackathon analytics vidhya/Hackathon LTFS 3 30012021/Data Prepared for Modelling/df_train_Data2.csv\")\n",
    "#df = pd.concat((df,df_train['Top-up Month']), axis=1)\n",
    "#dictionary = {6 :'No Top-up Service', 0:'> 48 Months',5 :'36-48 Months', 3:'24-30 Months',\n",
    "#                 4 :'30-36 Months', 2 :'18-24 Months', 1:'12-18 Months'}\n",
    "#df['Top-up Month'] = df['Top-up Month'].map(dictionary)\n",
    "X = df.drop(['Top-up Month'],axis=1)\n",
    "y = df['Top-up Month']\n",
    "\n",
    "df_train1 = pd.concat((pd.DataFrame(X), pd.DataFrame(y)), axis =1)\n",
    "train_cols = df_train1.columns\n",
    "test_cols = df_test.columns\n",
    "\n",
    "common_cols = train_cols.intersection(test_cols)\n",
    "train_not_test = train_cols.difference(test_cols)\n",
    "\n",
    "df_train1 = df[common_cols]\n",
    "#if 'Top-up Month' not in df_train1:\n",
    "#    df_train1['Top-up Month'] = pd.DataFrame(y)\n",
    "df_test1 = df_test[common_cols]\n",
    "\n",
    "df_test1 = df_test1.drop(['Top-up Month'], axis =1)\n",
    "\n",
    "X = df_train1.drop(['Top-up Month'],axis=1)\n",
    "#y = df['Top-up Month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BranchID</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>AssetCost</th>\n",
       "      <th>AmountFinance</th>\n",
       "      <th>EMI</th>\n",
       "      <th>AssetID</th>\n",
       "      <th>ManufacturerID</th>\n",
       "      <th>SupplierID</th>\n",
       "      <th>LTV</th>\n",
       "      <th>AGE</th>\n",
       "      <th>...</th>\n",
       "      <th>ACCOUNT-STATUS_SUIT FILED (WILFUL DEFAULT)</th>\n",
       "      <th>ACCOUNT-STATUS_Settled</th>\n",
       "      <th>ACCOUNT-STATUS_Suit Filed</th>\n",
       "      <th>ACCOUNT-STATUS_WILFUL DEFAULT</th>\n",
       "      <th>ACCOUNT-STATUS_Written Off</th>\n",
       "      <th>ASSET_CLASS_Loss</th>\n",
       "      <th>ASSET_CLASS_Special Mention Account</th>\n",
       "      <th>ASSET_CLASS_Standard</th>\n",
       "      <th>ASSET_CLASS_SubStandard</th>\n",
       "      <th>Loan_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>450000</td>\n",
       "      <td>275000.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>4022465</td>\n",
       "      <td>1568</td>\n",
       "      <td>21946</td>\n",
       "      <td>61.11</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>333</td>\n",
       "      <td>47</td>\n",
       "      <td>485000</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>10500.0</td>\n",
       "      <td>4681175</td>\n",
       "      <td>1062</td>\n",
       "      <td>34802</td>\n",
       "      <td>70.00</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>690000</td>\n",
       "      <td>519728.0</td>\n",
       "      <td>38300.0</td>\n",
       "      <td>25328146</td>\n",
       "      <td>1060</td>\n",
       "      <td>127335</td>\n",
       "      <td>69.77</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125</td>\n",
       "      <td>48</td>\n",
       "      <td>480000</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>11600.0</td>\n",
       "      <td>13021591</td>\n",
       "      <td>1060</td>\n",
       "      <td>25094</td>\n",
       "      <td>80.92</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>152</td>\n",
       "      <td>44</td>\n",
       "      <td>619265</td>\n",
       "      <td>440000.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>3291320</td>\n",
       "      <td>1046</td>\n",
       "      <td>21853</td>\n",
       "      <td>71.05</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BranchID  Tenure  AssetCost  AmountFinance      EMI   AssetID  \\\n",
       "0         1      48     450000       275000.0  24000.0   4022465   \n",
       "1       333      47     485000       350000.0  10500.0   4681175   \n",
       "2         1      68     690000       519728.0  38300.0  25328146   \n",
       "3       125      48     480000       400000.0  11600.0  13021591   \n",
       "4       152      44     619265       440000.0  15000.0   3291320   \n",
       "\n",
       "   ManufacturerID  SupplierID    LTV  AGE  ...  \\\n",
       "0            1568       21946  61.11   49  ...   \n",
       "1            1062       34802  70.00   23  ...   \n",
       "2            1060      127335  69.77   39  ...   \n",
       "3            1060       25094  80.92   24  ...   \n",
       "4            1046       21853  71.05   56  ...   \n",
       "\n",
       "   ACCOUNT-STATUS_SUIT FILED (WILFUL DEFAULT)  ACCOUNT-STATUS_Settled  \\\n",
       "0                                         0.0                     0.0   \n",
       "1                                         0.0                     0.0   \n",
       "2                                         0.0                     0.0   \n",
       "3                                         0.0                     0.0   \n",
       "4                                         1.0                     0.0   \n",
       "\n",
       "   ACCOUNT-STATUS_Suit Filed  ACCOUNT-STATUS_WILFUL DEFAULT  \\\n",
       "0                        0.0                            0.0   \n",
       "1                        0.0                            0.0   \n",
       "2                        0.0                            0.0   \n",
       "3                        0.0                            0.0   \n",
       "4                        0.0                            0.0   \n",
       "\n",
       "   ACCOUNT-STATUS_Written Off  ASSET_CLASS_Loss  \\\n",
       "0                         0.0               0.0   \n",
       "1                         0.0               0.0   \n",
       "2                         0.0               0.0   \n",
       "3                         0.0               0.0   \n",
       "4                         0.0               0.0   \n",
       "\n",
       "   ASSET_CLASS_Special Mention Account  ASSET_CLASS_Standard  \\\n",
       "0                                  0.0                   9.0   \n",
       "1                                  0.0                  13.0   \n",
       "2                                  0.0                  29.0   \n",
       "3                                  0.0                   4.0   \n",
       "4                                  0.0                   6.0   \n",
       "\n",
       "   ASSET_CLASS_SubStandard  Loan_Count  \n",
       "0                      0.0          81  \n",
       "1                      0.0         169  \n",
       "2                      0.0         961  \n",
       "3                      0.0          16  \n",
       "4                      0.0          49  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.15839243e-01, 6.25000000e-02, 2.28743902e-01, ...,\n",
       "        1.66666667e-02, 0.00000000e+00, 1.98413823e-04],\n",
       "       [2.71867612e-01, 3.28629032e-01, 1.43902439e-01, ...,\n",
       "        5.55555556e-03, 0.00000000e+00, 4.53517310e-05],\n",
       "       [5.20094563e-02, 3.83064516e-02, 2.14634146e-01, ...,\n",
       "        2.77777778e-03, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [1.77304965e-01, 8.66935484e-02, 1.65853659e-01, ...,\n",
       "        2.77777778e-03, 0.00000000e+00, 0.00000000e+00],\n",
       "       [2.12765957e-01, 6.25000000e-02, 1.84878049e-01, ...,\n",
       "        2.22222222e-02, 0.00000000e+00, 3.57144882e-04],\n",
       "       [5.39007092e-01, 9.27419355e-02, 2.68292683e-01, ...,\n",
       "        2.77777778e-03, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xeTSCxMScj8U",
    "outputId": "be8ed31b-e1de-4a25-eaa2-2a9188d08abb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": " Cast string to float is not supported\n\t [[node Cast (defined at <ipython-input-14-124e175991d7>:35) ]] [Op:__inference_train_function_2694]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-124e175991d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m# Fitting the ANN to the Training set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mD:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnimplementedError\u001b[0m:  Cast string to float is not supported\n\t [[node Cast (defined at <ipython-input-14-124e175991d7>:35) ]] [Op:__inference_train_function_2694]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.08, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Initialising the ANN\n",
    "model = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "model.add(Dense(64, activation = 'relu', input_dim = 103))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "model.add(Dense(units = 32, activation = 'relu'))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "model.add(Dense(units = 32, activation = 'relu'))\n",
    "\n",
    "# Adding the fourth hidden layer\n",
    "model.add(Dense(units = 32, activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "\n",
    "model.add(Dense(units = 7,activation='softmax'))\n",
    "\n",
    "#model.add(Dense(1))\n",
    "# Compiling the ANN\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy')\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model.fit(X_train, y_train,batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O2L3zDabg1HR",
    "outputId": "e25ebd21-4408-414c-acb0-cd53e27b6844"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06219494],\n",
       "       [0.1572395 ],\n",
       "       [0.07254204],\n",
       "       ...,\n",
       "       [0.08879003],\n",
       "       [0.77856565],\n",
       "       [0.14358464]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29610</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29611</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29612</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29613</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29614</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29615 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "...   ..\n",
       "29610  1\n",
       "29611  0\n",
       "29612  0\n",
       "29613  1\n",
       "29614  0\n",
       "\n",
       "[29615 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN  train roc-auc: 0.8288461895487234\n",
      "ANN test roc-auc: 0.5647074903094262\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.90     23126\n",
      "           1       0.77      0.31      0.44      6489\n",
      "\n",
      "    accuracy                           0.83     29615\n",
      "   macro avg       0.80      0.64      0.67     29615\n",
      "weighted avg       0.82      0.83      0.80     29615\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85      2025\n",
      "           1       0.28      0.11      0.16       551\n",
      "\n",
      "    accuracy                           0.75      2576\n",
      "   macro avg       0.53      0.52      0.51      2576\n",
      "weighted avg       0.68      0.75      0.70      2576\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5647074903094262\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ytrain_pred = model.predict_proba(X_train)\n",
    "print('ANN  train roc-auc: {}'.format(roc_auc_score(y_train, ytrain_pred)))\n",
    "ytest_pred = model.predict_proba(X_test)\n",
    "print('ANN test roc-auc: {}'.format(roc_auc_score(y_test, ytest_pred)))\n",
    "y_pred_train = np.where(model.predict(X_train)>.5,1,0)\n",
    "# Train Prediction classification report\n",
    "print(classification_report(y_train,pd.DataFrame(y_pred_train.flatten()) ))\n",
    "\n",
    "y_pred_test = np.where(model.predict(X_test)>.5,1,0)\n",
    "# Test Prediction classification report\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "plt.show()\n",
    "\n",
    "from sklearn import metrics\n",
    "def plot_roc_curve(fpr, tpr,model):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    auc = metrics.roc_auc_score(y_test, model.predict_proba(X_test))\n",
    "    print('AUC:', auc)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show( )\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test,model.predict_proba(X_test) )\n",
    "plot_roc_curve(fpr,tpr,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thresholds</th>\n",
       "      <th>f1score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>0.191562</td>\n",
       "      <td>0.161954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>0.114814</td>\n",
       "      <td>0.161954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>0.120200</td>\n",
       "      <td>0.161954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>0.119561</td>\n",
       "      <td>0.161954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>0.119448</td>\n",
       "      <td>0.161954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     thresholds   f1score\n",
       "446    0.191562  0.161954\n",
       "599    0.114814  0.161954\n",
       "588    0.120200  0.161954\n",
       "589    0.119561  0.161954\n",
       "590    0.119448  0.161954"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = pd.DataFrame(model.predict(X_test).flatten())\n",
    "from sklearn.metrics import f1_score\n",
    "f1score_ls=[]\n",
    "for thres in thresholds:\n",
    "    y_pred = np.where(y_pred_test>thres,1,0)\n",
    "    f1score_ls.append(f1_score(y_test, y_pred))\n",
    "    \n",
    "f1score_ls = pd.concat([pd.Series(thresholds), pd.Series(f1score_ls)],axis=1)\n",
    "f1score_ls.columns = ['thresholds', 'f1score']\n",
    "f1score_ls.sort_values(by='f1score', ascending=False, inplace=True)\n",
    "f1score_ls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SaCIUbdQ3qrV",
    "outputId": "43311a85-1d8a-4e3d-e6f7-911aae8c3e0c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Making the Confusion Matrix for threshold as accuracy threshold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred_test = np.where(model.predict(X_test)>f1score_ls.iloc[0,0],1,0)\n",
    "cm = confusion_matrix(y_test,  y_pred_test)\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "plt.show()\n",
    "\n",
    "#### Calculate the ROc Curve\n",
    "#fpr, tpr, thresholds = roc_curve(y_test,model.predict_proba(X_test) )\n",
    "#plot_roc_curve(fpr,tpr,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "00ZgEFHU59Y1",
    "outputId": "15acb958-0d9c-4565-f2de-867432585cce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.68      0.78     23126\n",
      "           1       0.41      0.79      0.54      6489\n",
      "\n",
      "    accuracy                           0.70     29615\n",
      "   macro avg       0.67      0.74      0.66     29615\n",
      "weighted avg       0.81      0.70      0.73     29615\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.58      0.68      2025\n",
      "           1       0.25      0.51      0.34       551\n",
      "\n",
      "    accuracy                           0.57      2576\n",
      "   macro avg       0.53      0.55      0.51      2576\n",
      "weighted avg       0.69      0.57      0.61      2576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = np.where(model.predict(X_train)>f1score_ls.iloc[0,0],1,0)\n",
    "# Train Prediction classification report\n",
    "print(classification_report(y_train,pd.DataFrame(y_pred_train.flatten()) ))\n",
    "\n",
    "y_pred_test = np.where(model.predict(X_test)>f1score_ls.iloc[0,0],1,0)\n",
    "# Test Prediction classification report\n",
    "print(classification_report(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thresholds</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.786102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.786102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>0.078467</td>\n",
       "      <td>0.569099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>0.115914</td>\n",
       "      <td>0.569099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>0.120368</td>\n",
       "      <td>0.569099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     thresholds  accuracy\n",
       "0      2.000000  0.786102\n",
       "1      1.000000  0.786102\n",
       "667    0.078467  0.569099\n",
       "598    0.115914  0.569099\n",
       "587    0.120368  0.569099"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = pd.DataFrame(model.predict(X_test).flatten())\n",
    "from sklearn.metrics import f1_score\n",
    "accuracy_ls=[]\n",
    "for thres in thresholds:\n",
    "    y_pred = np.where(y_pred_test>thres,1,0)\n",
    "    accuracy_ls.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "accuracy_ls = pd.concat([pd.Series(thresholds), pd.Series(accuracy_ls)],axis=1)\n",
    "accuracy_ls.columns = ['thresholds', 'accuracy']\n",
    "accuracy_ls.sort_values(by='accuracy', ascending=False, inplace=True)\n",
    "accuracy_ls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.37      0.54     23126\n",
      "           1       0.30      0.96      0.46      6489\n",
      "\n",
      "    accuracy                           0.50     29615\n",
      "   macro avg       0.64      0.67      0.50     29615\n",
      "weighted avg       0.83      0.50      0.52     29615\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.31      0.45      2025\n",
      "           1       0.23      0.77      0.35       551\n",
      "\n",
      "    accuracy                           0.40      2576\n",
      "   macro avg       0.53      0.54      0.40      2576\n",
      "weighted avg       0.70      0.40      0.43      2576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix for threshold as accuracy threshold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred_test = np.where(model.predict(X_test)>accuracy_ls.iloc[2,0],1,0)\n",
    "cm = confusion_matrix(y_test,  y_pred_test)\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "plt.show()\n",
    "\n",
    "y_pred_train = np.where(model.predict(X_train)>accuracy_ls.iloc[2,0],1,0)\n",
    "# Train Prediction classification report\n",
    "print(classification_report(y_train,pd.DataFrame(y_pred_train.flatten()) ))\n",
    "\n",
    "y_pred_test = np.where(model.predict(X_test)>accuracy_ls.iloc[2,0],1,0)\n",
    "# Test Prediction classification report\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "MdenpRMy22ZF"
   },
   "outputs": [],
   "source": [
    "#\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#matrix = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wIgLyiVkcj5f",
    "outputId": "eb73d556-9d82-4627-b2fa-113e559f5351"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, model.predict(X_train).round()) # Overfitting\n",
    "#accuracy_score(y_train, model.predict(X_train).round(), normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mVdKCj9043ba"
   },
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(y_true=y_true_labels, y_pred=y_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y6LrvQ0857dM",
    "outputId": "915e9347-4638-42a0-9cff-efaffdb6113b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.750388\n",
      "Precision: 0.292793\n",
      "Recall: 0.117967\n",
      "F1 score: 0.168176\n",
      "Cohens kappa: 0.051664\n",
      "ROC AUC: 0.559142\n",
      "[[1868  157]\n",
      " [ 486   65]]\n"
     ]
    }
   ],
   "source": [
    "# predict probabilities for test set\n",
    "yhat_probs = model.predict(X_test, verbose=0)\n",
    "# predict crisp classes for test set\n",
    "yhat_classes = model.predict_classes(X_test, verbose=0)\n",
    "# reduce to 1d array\n",
    "yhat_probs = yhat_probs[:, 0]\n",
    "yhat_classes = yhat_classes[:, 0]\n",
    " \n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, yhat_classes)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, yhat_classes)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, yhat_classes)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, yhat_classes)\n",
    "print('F1 score: %f' % f1)\n",
    " \n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_test, yhat_classes)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_test, yhat_probs)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test, yhat_classes)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S-AEKDltwkQD",
    "outputId": "116a69ba-e3e3-4a8f-b7bc-c9e8e74f9a53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# save model and architecture to single file\n",
    "model.save(\"ANN_Loan_Default_1.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IPgrEhUTcj3Y",
    "outputId": "78ec0af2-a8ff-4bb2-ae0c-1eb7766fcffc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 32)                1568      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 3,713\n",
      "Trainable params: 3,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    " \n",
    "# load model\n",
    "model = load_model('ANN_Loan_Default_1.h5')\n",
    "# summarize model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LN6UUUaaAQBR",
    "outputId": "074f58cb-0744-4e15-c1b1-d74497561911"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "dAw8l0BwARZz"
   },
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "YDR3wDmlARV2"
   },
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 10,kernel_initializer='he_uniform',activation='relu',input_dim = 48))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 10, kernel_initializer = 'he_uniform',activation='relu'))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy',f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AM3JlGtIAcNf",
    "outputId": "04ede9e1-8e51-426b-ace5-71e7db37a987"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 10)                490       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 611\n",
      "Trainable params: 611\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y6MGcjWaAg8d",
    "outputId": "2a54c8b0-12e1-474c-8f1a-9b4b8641c36a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "199/199 [==============================] - 1s 3ms/step - loss: 0.6510 - accuracy: 0.6601 - f1_m: 0.1353 - val_loss: 0.5394 - val_accuracy: 0.7811 - val_f1_m: 0.0161\n",
      "Epoch 2/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7783 - f1_m: 0.0096 - val_loss: 0.5211 - val_accuracy: 0.7837 - val_f1_m: 0.0097\n",
      "Epoch 3/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.5210 - accuracy: 0.7788 - f1_m: 0.0051 - val_loss: 0.5147 - val_accuracy: 0.7836 - val_f1_m: 0.0037\n",
      "Epoch 4/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7787 - f1_m: 0.0043 - val_loss: 0.5113 - val_accuracy: 0.7843 - val_f1_m: 0.0029\n",
      "Epoch 5/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7790 - f1_m: 0.0024 - val_loss: 0.5097 - val_accuracy: 0.7843 - val_f1_m: 0.0037\n",
      "Epoch 6/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.5114 - accuracy: 0.7791 - f1_m: 0.0024 - val_loss: 0.5090 - val_accuracy: 0.7844 - val_f1_m: 0.0019\n",
      "Epoch 7/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.5099 - accuracy: 0.7792 - f1_m: 0.0019 - val_loss: 0.5083 - val_accuracy: 0.7842 - val_f1_m: 0.0019\n",
      "Epoch 8/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.5090 - accuracy: 0.7792 - f1_m: 0.0023 - val_loss: 0.5078 - val_accuracy: 0.7843 - val_f1_m: 0.0019\n",
      "Epoch 9/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7792 - f1_m: 0.0019 - val_loss: 0.5076 - val_accuracy: 0.7843 - val_f1_m: 6.8027e-04\n",
      "Epoch 10/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.5074 - accuracy: 0.7794 - f1_m: 0.0029 - val_loss: 0.5076 - val_accuracy: 0.7843 - val_f1_m: 6.8027e-04\n",
      "Epoch 11/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.5067 - accuracy: 0.7793 - f1_m: 0.0019 - val_loss: 0.5075 - val_accuracy: 0.7842 - val_f1_m: 6.8027e-04\n",
      "Epoch 12/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.5061 - accuracy: 0.7794 - f1_m: 0.0024 - val_loss: 0.5078 - val_accuracy: 0.7842 - val_f1_m: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.5058 - accuracy: 0.7794 - f1_m: 0.0021 - val_loss: 0.5076 - val_accuracy: 0.7840 - val_f1_m: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7794 - f1_m: 0.0031 - val_loss: 0.5080 - val_accuracy: 0.7839 - val_f1_m: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7794 - f1_m: 0.0028 - val_loss: 0.5078 - val_accuracy: 0.7840 - val_f1_m: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7794 - f1_m: 0.0034 - val_loss: 0.5080 - val_accuracy: 0.7838 - val_f1_m: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7794 - f1_m: 0.0029 - val_loss: 0.5084 - val_accuracy: 0.7840 - val_f1_m: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7792 - f1_m: 0.0031 - val_loss: 0.5084 - val_accuracy: 0.7840 - val_f1_m: 0.0000e+00\n",
      "Epoch 19/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7793 - f1_m: 0.0033 - val_loss: 0.5087 - val_accuracy: 0.7837 - val_f1_m: 0.0019\n",
      "Epoch 20/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.5031 - accuracy: 0.7794 - f1_m: 0.0046 - val_loss: 0.5087 - val_accuracy: 0.7839 - val_f1_m: 0.0011\n",
      "Epoch 21/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7792 - f1_m: 0.0031 - val_loss: 0.5088 - val_accuracy: 0.7839 - val_f1_m: 0.0019\n",
      "Epoch 22/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7792 - f1_m: 0.0039 - val_loss: 0.5093 - val_accuracy: 0.7838 - val_f1_m: 0.0011\n",
      "Epoch 23/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7790 - f1_m: 0.0041 - val_loss: 0.5090 - val_accuracy: 0.7839 - val_f1_m: 0.0011\n",
      "Epoch 24/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7791 - f1_m: 0.0042 - val_loss: 0.5091 - val_accuracy: 0.7836 - val_f1_m: 0.0011\n",
      "Epoch 25/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.7793 - f1_m: 0.0053 - val_loss: 0.5092 - val_accuracy: 0.7837 - val_f1_m: 0.0019\n",
      "Epoch 26/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.5014 - accuracy: 0.7792 - f1_m: 0.0048 - val_loss: 0.5099 - val_accuracy: 0.7839 - val_f1_m: 0.0011\n",
      "Epoch 27/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7792 - f1_m: 0.0054 - val_loss: 0.5107 - val_accuracy: 0.7830 - val_f1_m: 0.0050\n",
      "Epoch 28/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.5010 - accuracy: 0.7791 - f1_m: 0.0046 - val_loss: 0.5104 - val_accuracy: 0.7842 - val_f1_m: 0.0040\n",
      "Epoch 29/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.7792 - f1_m: 0.0063 - val_loss: 0.5102 - val_accuracy: 0.7835 - val_f1_m: 0.0011\n",
      "Epoch 30/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.5007 - accuracy: 0.7791 - f1_m: 0.0051 - val_loss: 0.5111 - val_accuracy: 0.7837 - val_f1_m: 0.0040\n",
      "Epoch 31/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.7791 - f1_m: 0.0050 - val_loss: 0.5107 - val_accuracy: 0.7836 - val_f1_m: 0.0037\n",
      "Epoch 32/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.7790 - f1_m: 0.0077 - val_loss: 0.5105 - val_accuracy: 0.7834 - val_f1_m: 0.0047\n",
      "Epoch 33/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.7792 - f1_m: 0.0056 - val_loss: 0.5105 - val_accuracy: 0.7833 - val_f1_m: 0.0045\n",
      "Epoch 34/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.7795 - f1_m: 0.0107 - val_loss: 0.5108 - val_accuracy: 0.7834 - val_f1_m: 0.0066\n",
      "Epoch 35/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7794 - f1_m: 0.0086 - val_loss: 0.5113 - val_accuracy: 0.7830 - val_f1_m: 0.0097\n",
      "Epoch 36/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7792 - f1_m: 0.0087 - val_loss: 0.5113 - val_accuracy: 0.7832 - val_f1_m: 0.0064\n",
      "Epoch 37/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7792 - f1_m: 0.0117 - val_loss: 0.5116 - val_accuracy: 0.7835 - val_f1_m: 0.0034\n",
      "Epoch 38/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7796 - f1_m: 0.0107 - val_loss: 0.5120 - val_accuracy: 0.7834 - val_f1_m: 0.0100\n",
      "Epoch 39/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.7794 - f1_m: 0.0116 - val_loss: 0.5114 - val_accuracy: 0.7835 - val_f1_m: 0.0098\n",
      "Epoch 40/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 0.7793 - f1_m: 0.0127 - val_loss: 0.5118 - val_accuracy: 0.7833 - val_f1_m: 0.0073\n",
      "Epoch 41/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4985 - accuracy: 0.7796 - f1_m: 0.0130 - val_loss: 0.5127 - val_accuracy: 0.7834 - val_f1_m: 0.0127\n",
      "Epoch 42/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4982 - accuracy: 0.7796 - f1_m: 0.0140 - val_loss: 0.5123 - val_accuracy: 0.7836 - val_f1_m: 0.0080\n",
      "Epoch 43/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4980 - accuracy: 0.7799 - f1_m: 0.0193 - val_loss: 0.5134 - val_accuracy: 0.7834 - val_f1_m: 0.0054\n",
      "Epoch 44/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4980 - accuracy: 0.7796 - f1_m: 0.0123 - val_loss: 0.5125 - val_accuracy: 0.7836 - val_f1_m: 0.0108\n",
      "Epoch 45/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7794 - f1_m: 0.0173 - val_loss: 0.5125 - val_accuracy: 0.7838 - val_f1_m: 0.0108\n",
      "Epoch 46/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4975 - accuracy: 0.7794 - f1_m: 0.0149 - val_loss: 0.5129 - val_accuracy: 0.7836 - val_f1_m: 0.0089\n",
      "Epoch 47/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4974 - accuracy: 0.7795 - f1_m: 0.0167 - val_loss: 0.5132 - val_accuracy: 0.7830 - val_f1_m: 0.0109\n",
      "Epoch 48/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4974 - accuracy: 0.7798 - f1_m: 0.0186 - val_loss: 0.5130 - val_accuracy: 0.7832 - val_f1_m: 0.0116\n",
      "Epoch 49/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7800 - f1_m: 0.0215 - val_loss: 0.5133 - val_accuracy: 0.7827 - val_f1_m: 0.0097\n",
      "Epoch 50/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.7794 - f1_m: 0.0182 - val_loss: 0.5140 - val_accuracy: 0.7828 - val_f1_m: 0.0164\n",
      "Epoch 51/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7800 - f1_m: 0.0219 - val_loss: 0.5132 - val_accuracy: 0.7830 - val_f1_m: 0.0092\n",
      "Epoch 52/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4966 - accuracy: 0.7796 - f1_m: 0.0183 - val_loss: 0.5143 - val_accuracy: 0.7834 - val_f1_m: 0.0153\n",
      "Epoch 53/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4966 - accuracy: 0.7797 - f1_m: 0.0237 - val_loss: 0.5134 - val_accuracy: 0.7832 - val_f1_m: 0.0154\n",
      "Epoch 54/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4965 - accuracy: 0.7801 - f1_m: 0.0258 - val_loss: 0.5138 - val_accuracy: 0.7832 - val_f1_m: 0.0144\n",
      "Epoch 55/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4960 - accuracy: 0.7798 - f1_m: 0.0221 - val_loss: 0.5141 - val_accuracy: 0.7825 - val_f1_m: 0.0146\n",
      "Epoch 56/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4961 - accuracy: 0.7803 - f1_m: 0.0260 - val_loss: 0.5146 - val_accuracy: 0.7820 - val_f1_m: 0.0170\n",
      "Epoch 57/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4959 - accuracy: 0.7804 - f1_m: 0.0277 - val_loss: 0.5146 - val_accuracy: 0.7829 - val_f1_m: 0.0163\n",
      "Epoch 58/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4959 - accuracy: 0.7803 - f1_m: 0.0275 - val_loss: 0.5145 - val_accuracy: 0.7826 - val_f1_m: 0.0145\n",
      "Epoch 59/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4957 - accuracy: 0.7805 - f1_m: 0.0248 - val_loss: 0.5155 - val_accuracy: 0.7821 - val_f1_m: 0.0170\n",
      "Epoch 60/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4954 - accuracy: 0.7802 - f1_m: 0.0312 - val_loss: 0.5145 - val_accuracy: 0.7827 - val_f1_m: 0.0192\n",
      "Epoch 61/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4953 - accuracy: 0.7808 - f1_m: 0.0328 - val_loss: 0.5147 - val_accuracy: 0.7829 - val_f1_m: 0.0137\n",
      "Epoch 62/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4951 - accuracy: 0.7798 - f1_m: 0.0277 - val_loss: 0.5157 - val_accuracy: 0.7825 - val_f1_m: 0.0162\n",
      "Epoch 63/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.7803 - f1_m: 0.0287 - val_loss: 0.5160 - val_accuracy: 0.7826 - val_f1_m: 0.0140\n",
      "Epoch 64/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.7808 - f1_m: 0.0330 - val_loss: 0.5162 - val_accuracy: 0.7816 - val_f1_m: 0.0178\n",
      "Epoch 65/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4949 - accuracy: 0.7807 - f1_m: 0.0335 - val_loss: 0.5164 - val_accuracy: 0.7806 - val_f1_m: 0.0185\n",
      "Epoch 66/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4949 - accuracy: 0.7806 - f1_m: 0.0324 - val_loss: 0.5159 - val_accuracy: 0.7822 - val_f1_m: 0.0197\n",
      "Epoch 67/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4945 - accuracy: 0.7810 - f1_m: 0.0356 - val_loss: 0.5165 - val_accuracy: 0.7817 - val_f1_m: 0.0159\n",
      "Epoch 68/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4942 - accuracy: 0.7805 - f1_m: 0.0348 - val_loss: 0.5163 - val_accuracy: 0.7824 - val_f1_m: 0.0091\n",
      "Epoch 69/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4946 - accuracy: 0.7807 - f1_m: 0.0329 - val_loss: 0.5162 - val_accuracy: 0.7818 - val_f1_m: 0.0151\n",
      "Epoch 70/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4942 - accuracy: 0.7808 - f1_m: 0.0357 - val_loss: 0.5168 - val_accuracy: 0.7823 - val_f1_m: 0.0152\n",
      "Epoch 71/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4940 - accuracy: 0.7809 - f1_m: 0.0402 - val_loss: 0.5168 - val_accuracy: 0.7824 - val_f1_m: 0.0145\n",
      "Epoch 72/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4935 - accuracy: 0.7808 - f1_m: 0.0354 - val_loss: 0.5175 - val_accuracy: 0.7821 - val_f1_m: 0.0149\n",
      "Epoch 73/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4938 - accuracy: 0.7809 - f1_m: 0.0344 - val_loss: 0.5169 - val_accuracy: 0.7811 - val_f1_m: 0.0209\n",
      "Epoch 74/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4937 - accuracy: 0.7799 - f1_m: 0.0331 - val_loss: 0.5169 - val_accuracy: 0.7812 - val_f1_m: 0.0158\n",
      "Epoch 75/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.7813 - f1_m: 0.0403 - val_loss: 0.5172 - val_accuracy: 0.7813 - val_f1_m: 0.0184\n",
      "Epoch 76/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.7812 - f1_m: 0.0402 - val_loss: 0.5178 - val_accuracy: 0.7816 - val_f1_m: 0.0170\n",
      "Epoch 77/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4934 - accuracy: 0.7810 - f1_m: 0.0422 - val_loss: 0.5175 - val_accuracy: 0.7812 - val_f1_m: 0.0159\n",
      "Epoch 78/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4928 - accuracy: 0.7810 - f1_m: 0.0410 - val_loss: 0.5177 - val_accuracy: 0.7812 - val_f1_m: 0.0191\n",
      "Epoch 79/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4933 - accuracy: 0.7809 - f1_m: 0.0417 - val_loss: 0.5175 - val_accuracy: 0.7811 - val_f1_m: 0.0207\n",
      "Epoch 80/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7812 - f1_m: 0.0419 - val_loss: 0.5176 - val_accuracy: 0.7814 - val_f1_m: 0.0177\n",
      "Epoch 81/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4924 - accuracy: 0.7806 - f1_m: 0.0392 - val_loss: 0.5206 - val_accuracy: 0.7798 - val_f1_m: 0.0302\n",
      "Epoch 82/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4925 - accuracy: 0.7812 - f1_m: 0.0486 - val_loss: 0.5177 - val_accuracy: 0.7813 - val_f1_m: 0.0167\n",
      "Epoch 83/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4926 - accuracy: 0.7805 - f1_m: 0.0415 - val_loss: 0.5184 - val_accuracy: 0.7807 - val_f1_m: 0.0158\n",
      "Epoch 84/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4920 - accuracy: 0.7809 - f1_m: 0.0454 - val_loss: 0.5187 - val_accuracy: 0.7806 - val_f1_m: 0.0162\n",
      "Epoch 85/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4922 - accuracy: 0.7813 - f1_m: 0.0453 - val_loss: 0.5195 - val_accuracy: 0.7805 - val_f1_m: 0.0143\n",
      "Epoch 86/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.7807 - f1_m: 0.0428 - val_loss: 0.5189 - val_accuracy: 0.7788 - val_f1_m: 0.0242\n",
      "Epoch 87/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4920 - accuracy: 0.7811 - f1_m: 0.0491 - val_loss: 0.5182 - val_accuracy: 0.7808 - val_f1_m: 0.0170\n",
      "Epoch 88/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.7810 - f1_m: 0.0473 - val_loss: 0.5185 - val_accuracy: 0.7806 - val_f1_m: 0.0188\n",
      "Epoch 89/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4916 - accuracy: 0.7807 - f1_m: 0.0458 - val_loss: 0.5194 - val_accuracy: 0.7798 - val_f1_m: 0.0243\n",
      "Epoch 90/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4916 - accuracy: 0.7807 - f1_m: 0.0473 - val_loss: 0.5187 - val_accuracy: 0.7801 - val_f1_m: 0.0202\n",
      "Epoch 91/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.7805 - f1_m: 0.0438 - val_loss: 0.5192 - val_accuracy: 0.7793 - val_f1_m: 0.0258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4915 - accuracy: 0.7813 - f1_m: 0.0565 - val_loss: 0.5200 - val_accuracy: 0.7800 - val_f1_m: 0.0222\n",
      "Epoch 93/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7815 - f1_m: 0.0535 - val_loss: 0.5195 - val_accuracy: 0.7787 - val_f1_m: 0.0250\n",
      "Epoch 94/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7812 - f1_m: 0.0549 - val_loss: 0.5198 - val_accuracy: 0.7795 - val_f1_m: 0.0249\n",
      "Epoch 95/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.7810 - f1_m: 0.0542 - val_loss: 0.5209 - val_accuracy: 0.7792 - val_f1_m: 0.0266\n",
      "Epoch 96/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.7818 - f1_m: 0.0535 - val_loss: 0.5204 - val_accuracy: 0.7785 - val_f1_m: 0.0314\n",
      "Epoch 97/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7818 - f1_m: 0.0616 - val_loss: 0.5205 - val_accuracy: 0.7795 - val_f1_m: 0.0254\n",
      "Epoch 98/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7817 - f1_m: 0.0570 - val_loss: 0.5215 - val_accuracy: 0.7765 - val_f1_m: 0.0333\n",
      "Epoch 99/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.7810 - f1_m: 0.0571 - val_loss: 0.5200 - val_accuracy: 0.7797 - val_f1_m: 0.0224\n",
      "Epoch 100/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.7815 - f1_m: 0.0593 - val_loss: 0.5203 - val_accuracy: 0.7795 - val_f1_m: 0.0230\n",
      "Epoch 101/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.7813 - f1_m: 0.0623 - val_loss: 0.5209 - val_accuracy: 0.7782 - val_f1_m: 0.0280\n",
      "Epoch 102/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4905 - accuracy: 0.7814 - f1_m: 0.0571 - val_loss: 0.5208 - val_accuracy: 0.7787 - val_f1_m: 0.0246\n",
      "Epoch 103/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4903 - accuracy: 0.7816 - f1_m: 0.0635 - val_loss: 0.5210 - val_accuracy: 0.7767 - val_f1_m: 0.0367\n",
      "Epoch 104/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.7814 - f1_m: 0.0646 - val_loss: 0.5204 - val_accuracy: 0.7794 - val_f1_m: 0.0217\n",
      "Epoch 105/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.7812 - f1_m: 0.0570 - val_loss: 0.5204 - val_accuracy: 0.7791 - val_f1_m: 0.0241\n",
      "Epoch 106/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4901 - accuracy: 0.7812 - f1_m: 0.0597 - val_loss: 0.5205 - val_accuracy: 0.7785 - val_f1_m: 0.0236\n",
      "Epoch 107/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7821 - f1_m: 0.0619 - val_loss: 0.5218 - val_accuracy: 0.7761 - val_f1_m: 0.0376\n",
      "Epoch 108/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.7813 - f1_m: 0.0630 - val_loss: 0.5222 - val_accuracy: 0.7777 - val_f1_m: 0.0297\n",
      "Epoch 109/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7815 - f1_m: 0.0673 - val_loss: 0.5203 - val_accuracy: 0.7777 - val_f1_m: 0.0361\n",
      "Epoch 110/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.7819 - f1_m: 0.0660 - val_loss: 0.5206 - val_accuracy: 0.7789 - val_f1_m: 0.0302\n",
      "Epoch 111/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7815 - f1_m: 0.0625 - val_loss: 0.5219 - val_accuracy: 0.7769 - val_f1_m: 0.0410\n",
      "Epoch 112/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4898 - accuracy: 0.7815 - f1_m: 0.0679 - val_loss: 0.5217 - val_accuracy: 0.7771 - val_f1_m: 0.0373\n",
      "Epoch 113/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7819 - f1_m: 0.0682 - val_loss: 0.5216 - val_accuracy: 0.7767 - val_f1_m: 0.0397\n",
      "Epoch 114/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.7818 - f1_m: 0.0742 - val_loss: 0.5222 - val_accuracy: 0.7771 - val_f1_m: 0.0307\n",
      "Epoch 115/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4896 - accuracy: 0.7816 - f1_m: 0.0654 - val_loss: 0.5225 - val_accuracy: 0.7785 - val_f1_m: 0.0316\n",
      "Epoch 116/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4899 - accuracy: 0.7813 - f1_m: 0.0638 - val_loss: 0.5232 - val_accuracy: 0.7755 - val_f1_m: 0.0462\n",
      "Epoch 117/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.7823 - f1_m: 0.0757 - val_loss: 0.5213 - val_accuracy: 0.7786 - val_f1_m: 0.0315\n",
      "Epoch 118/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4895 - accuracy: 0.7822 - f1_m: 0.0740 - val_loss: 0.5216 - val_accuracy: 0.7783 - val_f1_m: 0.0397\n",
      "Epoch 119/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.7824 - f1_m: 0.0743 - val_loss: 0.5224 - val_accuracy: 0.7761 - val_f1_m: 0.0408\n",
      "Epoch 120/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7825 - f1_m: 0.0742 - val_loss: 0.5220 - val_accuracy: 0.7770 - val_f1_m: 0.0380\n",
      "Epoch 121/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4891 - accuracy: 0.7820 - f1_m: 0.0761 - val_loss: 0.5221 - val_accuracy: 0.7776 - val_f1_m: 0.0355\n",
      "Epoch 122/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4893 - accuracy: 0.7822 - f1_m: 0.0694 - val_loss: 0.5227 - val_accuracy: 0.7777 - val_f1_m: 0.0317\n",
      "Epoch 123/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4890 - accuracy: 0.7820 - f1_m: 0.0707 - val_loss: 0.5211 - val_accuracy: 0.7773 - val_f1_m: 0.0365\n",
      "Epoch 124/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7821 - f1_m: 0.0757 - val_loss: 0.5225 - val_accuracy: 0.7776 - val_f1_m: 0.0432\n",
      "Epoch 125/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4892 - accuracy: 0.7818 - f1_m: 0.0751 - val_loss: 0.5221 - val_accuracy: 0.7769 - val_f1_m: 0.0427\n",
      "Epoch 126/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4888 - accuracy: 0.7818 - f1_m: 0.0715 - val_loss: 0.5245 - val_accuracy: 0.7742 - val_f1_m: 0.0542\n",
      "Epoch 127/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4888 - accuracy: 0.7824 - f1_m: 0.0777 - val_loss: 0.5234 - val_accuracy: 0.7760 - val_f1_m: 0.0436\n",
      "Epoch 128/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4886 - accuracy: 0.7821 - f1_m: 0.0782 - val_loss: 0.5231 - val_accuracy: 0.7763 - val_f1_m: 0.0375\n",
      "Epoch 129/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4886 - accuracy: 0.7826 - f1_m: 0.0817 - val_loss: 0.5219 - val_accuracy: 0.7772 - val_f1_m: 0.0485\n",
      "Epoch 130/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4891 - accuracy: 0.7821 - f1_m: 0.0769 - val_loss: 0.5227 - val_accuracy: 0.7770 - val_f1_m: 0.0398\n",
      "Epoch 131/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.7823 - f1_m: 0.0779 - val_loss: 0.5229 - val_accuracy: 0.7776 - val_f1_m: 0.0389\n",
      "Epoch 132/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4885 - accuracy: 0.7828 - f1_m: 0.0774 - val_loss: 0.5230 - val_accuracy: 0.7760 - val_f1_m: 0.0472\n",
      "Epoch 133/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7823 - f1_m: 0.0776 - val_loss: 0.5223 - val_accuracy: 0.7776 - val_f1_m: 0.0362\n",
      "Epoch 134/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7821 - f1_m: 0.0792 - val_loss: 0.5225 - val_accuracy: 0.7774 - val_f1_m: 0.0408\n",
      "Epoch 135/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7824 - f1_m: 0.0798 - val_loss: 0.5227 - val_accuracy: 0.7783 - val_f1_m: 0.0352\n",
      "Epoch 136/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.7824 - f1_m: 0.0761 - val_loss: 0.5226 - val_accuracy: 0.7770 - val_f1_m: 0.0400\n",
      "Epoch 137/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.7824 - f1_m: 0.0785 - val_loss: 0.5232 - val_accuracy: 0.7772 - val_f1_m: 0.0446\n",
      "Epoch 138/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.7826 - f1_m: 0.0839 - val_loss: 0.5223 - val_accuracy: 0.7781 - val_f1_m: 0.0377\n",
      "Epoch 139/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7830 - f1_m: 0.0839 - val_loss: 0.5233 - val_accuracy: 0.7767 - val_f1_m: 0.0444\n",
      "Epoch 140/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7826 - f1_m: 0.0823 - val_loss: 0.5232 - val_accuracy: 0.7760 - val_f1_m: 0.0412\n",
      "Epoch 141/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4882 - accuracy: 0.7825 - f1_m: 0.0857 - val_loss: 0.5235 - val_accuracy: 0.7789 - val_f1_m: 0.0355\n",
      "Epoch 142/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4882 - accuracy: 0.7825 - f1_m: 0.0753 - val_loss: 0.5236 - val_accuracy: 0.7776 - val_f1_m: 0.0417\n",
      "Epoch 143/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4881 - accuracy: 0.7832 - f1_m: 0.0873 - val_loss: 0.5238 - val_accuracy: 0.7771 - val_f1_m: 0.0384\n",
      "Epoch 144/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4881 - accuracy: 0.7826 - f1_m: 0.0852 - val_loss: 0.5229 - val_accuracy: 0.7769 - val_f1_m: 0.0443\n",
      "Epoch 145/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.7834 - f1_m: 0.0871 - val_loss: 0.5234 - val_accuracy: 0.7766 - val_f1_m: 0.0422\n",
      "Epoch 146/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.7825 - f1_m: 0.0845 - val_loss: 0.5243 - val_accuracy: 0.7782 - val_f1_m: 0.0339\n",
      "Epoch 147/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.7828 - f1_m: 0.0809 - val_loss: 0.5233 - val_accuracy: 0.7783 - val_f1_m: 0.0429\n",
      "Epoch 148/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 0.7830 - f1_m: 0.0862 - val_loss: 0.5239 - val_accuracy: 0.7791 - val_f1_m: 0.0415\n",
      "Epoch 149/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 0.7829 - f1_m: 0.0855 - val_loss: 0.5243 - val_accuracy: 0.7754 - val_f1_m: 0.0436\n",
      "Epoch 150/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7831 - f1_m: 0.0864 - val_loss: 0.5239 - val_accuracy: 0.7764 - val_f1_m: 0.0413\n",
      "Epoch 151/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.7831 - f1_m: 0.0854 - val_loss: 0.5239 - val_accuracy: 0.7781 - val_f1_m: 0.0408\n",
      "Epoch 152/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.7834 - f1_m: 0.0894 - val_loss: 0.5243 - val_accuracy: 0.7778 - val_f1_m: 0.0383\n",
      "Epoch 153/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4876 - accuracy: 0.7829 - f1_m: 0.0832 - val_loss: 0.5240 - val_accuracy: 0.7787 - val_f1_m: 0.0408\n",
      "Epoch 154/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4875 - accuracy: 0.7826 - f1_m: 0.0818 - val_loss: 0.5251 - val_accuracy: 0.7747 - val_f1_m: 0.0459\n",
      "Epoch 155/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4875 - accuracy: 0.7836 - f1_m: 0.0928 - val_loss: 0.5234 - val_accuracy: 0.7780 - val_f1_m: 0.0424\n",
      "Epoch 156/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4873 - accuracy: 0.7831 - f1_m: 0.0837 - val_loss: 0.5249 - val_accuracy: 0.7755 - val_f1_m: 0.0487\n",
      "Epoch 157/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4875 - accuracy: 0.7827 - f1_m: 0.0898 - val_loss: 0.5236 - val_accuracy: 0.7776 - val_f1_m: 0.0445\n",
      "Epoch 158/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.7830 - f1_m: 0.0865 - val_loss: 0.5237 - val_accuracy: 0.7764 - val_f1_m: 0.0421\n",
      "Epoch 159/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.7832 - f1_m: 0.0876 - val_loss: 0.5243 - val_accuracy: 0.7759 - val_f1_m: 0.0472\n",
      "Epoch 160/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.7827 - f1_m: 0.0885 - val_loss: 0.5253 - val_accuracy: 0.7754 - val_f1_m: 0.0539\n",
      "Epoch 161/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.7824 - f1_m: 0.0889 - val_loss: 0.5241 - val_accuracy: 0.7791 - val_f1_m: 0.0396\n",
      "Epoch 162/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.7833 - f1_m: 0.0904 - val_loss: 0.5248 - val_accuracy: 0.7797 - val_f1_m: 0.0314\n",
      "Epoch 163/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7829 - f1_m: 0.0827 - val_loss: 0.5239 - val_accuracy: 0.7778 - val_f1_m: 0.0414\n",
      "Epoch 164/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.7829 - f1_m: 0.0910 - val_loss: 0.5248 - val_accuracy: 0.7780 - val_f1_m: 0.0394\n",
      "Epoch 165/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.7831 - f1_m: 0.0903 - val_loss: 0.5247 - val_accuracy: 0.7767 - val_f1_m: 0.0502\n",
      "Epoch 166/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7826 - f1_m: 0.0843 - val_loss: 0.5252 - val_accuracy: 0.7763 - val_f1_m: 0.0441\n",
      "Epoch 167/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.7829 - f1_m: 0.0914 - val_loss: 0.5249 - val_accuracy: 0.7764 - val_f1_m: 0.0454\n",
      "Epoch 168/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7827 - f1_m: 0.0887 - val_loss: 0.5248 - val_accuracy: 0.7789 - val_f1_m: 0.0366\n",
      "Epoch 169/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7831 - f1_m: 0.0898 - val_loss: 0.5248 - val_accuracy: 0.7778 - val_f1_m: 0.0380\n",
      "Epoch 170/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4870 - accuracy: 0.7831 - f1_m: 0.0917 - val_loss: 0.5249 - val_accuracy: 0.7776 - val_f1_m: 0.0414\n",
      "Epoch 171/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4868 - accuracy: 0.7828 - f1_m: 0.0884 - val_loss: 0.5253 - val_accuracy: 0.7770 - val_f1_m: 0.0488\n",
      "Epoch 172/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7831 - f1_m: 0.0889 - val_loss: 0.5251 - val_accuracy: 0.7755 - val_f1_m: 0.0481\n",
      "Epoch 173/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4871 - accuracy: 0.7827 - f1_m: 0.0899 - val_loss: 0.5261 - val_accuracy: 0.7755 - val_f1_m: 0.0467\n",
      "Epoch 174/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4871 - accuracy: 0.7833 - f1_m: 0.0910 - val_loss: 0.5256 - val_accuracy: 0.7771 - val_f1_m: 0.0424\n",
      "Epoch 175/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4868 - accuracy: 0.7832 - f1_m: 0.0914 - val_loss: 0.5263 - val_accuracy: 0.7779 - val_f1_m: 0.0379\n",
      "Epoch 176/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7833 - f1_m: 0.0928 - val_loss: 0.5246 - val_accuracy: 0.7783 - val_f1_m: 0.0451\n",
      "Epoch 177/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4871 - accuracy: 0.7822 - f1_m: 0.0903 - val_loss: 0.5254 - val_accuracy: 0.7768 - val_f1_m: 0.0449\n",
      "Epoch 178/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7831 - f1_m: 0.0905 - val_loss: 0.5252 - val_accuracy: 0.7777 - val_f1_m: 0.0433\n",
      "Epoch 179/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7828 - f1_m: 0.0867 - val_loss: 0.5265 - val_accuracy: 0.7751 - val_f1_m: 0.0556\n",
      "Epoch 180/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7839 - f1_m: 0.0930 - val_loss: 0.5271 - val_accuracy: 0.7738 - val_f1_m: 0.0536\n",
      "Epoch 181/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7828 - f1_m: 0.0930 - val_loss: 0.5272 - val_accuracy: 0.7757 - val_f1_m: 0.0464\n",
      "Epoch 182/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7836 - f1_m: 0.0944 - val_loss: 0.5262 - val_accuracy: 0.7772 - val_f1_m: 0.0346\n",
      "Epoch 183/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4868 - accuracy: 0.7822 - f1_m: 0.0871 - val_loss: 0.5265 - val_accuracy: 0.7756 - val_f1_m: 0.0509\n",
      "Epoch 184/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4867 - accuracy: 0.7832 - f1_m: 0.0907 - val_loss: 0.5275 - val_accuracy: 0.7741 - val_f1_m: 0.0517\n",
      "Epoch 185/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4868 - accuracy: 0.7833 - f1_m: 0.0934 - val_loss: 0.5266 - val_accuracy: 0.7737 - val_f1_m: 0.0562\n",
      "Epoch 186/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4868 - accuracy: 0.7832 - f1_m: 0.0921 - val_loss: 0.5275 - val_accuracy: 0.7784 - val_f1_m: 0.0394\n",
      "Epoch 187/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7832 - f1_m: 0.0928 - val_loss: 0.5272 - val_accuracy: 0.7766 - val_f1_m: 0.0504\n",
      "Epoch 188/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4866 - accuracy: 0.7833 - f1_m: 0.0904 - val_loss: 0.5252 - val_accuracy: 0.7757 - val_f1_m: 0.0462\n",
      "Epoch 189/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7828 - f1_m: 0.0880 - val_loss: 0.5266 - val_accuracy: 0.7755 - val_f1_m: 0.0463\n",
      "Epoch 190/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7828 - f1_m: 0.0893 - val_loss: 0.5265 - val_accuracy: 0.7765 - val_f1_m: 0.0467\n",
      "Epoch 191/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.7833 - f1_m: 0.0925 - val_loss: 0.5249 - val_accuracy: 0.7768 - val_f1_m: 0.0441\n",
      "Epoch 192/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7834 - f1_m: 0.0955 - val_loss: 0.5269 - val_accuracy: 0.7782 - val_f1_m: 0.0390\n",
      "Epoch 193/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.7829 - f1_m: 0.0925 - val_loss: 0.5266 - val_accuracy: 0.7781 - val_f1_m: 0.0333\n",
      "Epoch 194/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4862 - accuracy: 0.7838 - f1_m: 0.0960 - val_loss: 0.5260 - val_accuracy: 0.7758 - val_f1_m: 0.0354\n",
      "Epoch 195/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.7831 - f1_m: 0.0906 - val_loss: 0.5273 - val_accuracy: 0.7765 - val_f1_m: 0.0411\n",
      "Epoch 196/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7833 - f1_m: 0.0980 - val_loss: 0.5271 - val_accuracy: 0.7742 - val_f1_m: 0.0519\n",
      "Epoch 197/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.7828 - f1_m: 0.0904 - val_loss: 0.5282 - val_accuracy: 0.7728 - val_f1_m: 0.0646\n",
      "Epoch 198/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.7828 - f1_m: 0.0939 - val_loss: 0.5268 - val_accuracy: 0.7749 - val_f1_m: 0.0460\n",
      "Epoch 199/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.7828 - f1_m: 0.0867 - val_loss: 0.5275 - val_accuracy: 0.7745 - val_f1_m: 0.0519\n",
      "Epoch 200/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.7834 - f1_m: 0.0912 - val_loss: 0.5272 - val_accuracy: 0.7750 - val_f1_m: 0.0467\n",
      "Epoch 201/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4862 - accuracy: 0.7832 - f1_m: 0.0953 - val_loss: 0.5264 - val_accuracy: 0.7764 - val_f1_m: 0.0493\n",
      "Epoch 202/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 0.7828 - f1_m: 0.0911 - val_loss: 0.5259 - val_accuracy: 0.7749 - val_f1_m: 0.0500\n",
      "Epoch 203/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.7827 - f1_m: 0.0939 - val_loss: 0.5259 - val_accuracy: 0.7763 - val_f1_m: 0.0416\n",
      "Epoch 204/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.7828 - f1_m: 0.0923 - val_loss: 0.5271 - val_accuracy: 0.7766 - val_f1_m: 0.0496\n",
      "Epoch 205/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.7835 - f1_m: 0.0964 - val_loss: 0.5279 - val_accuracy: 0.7790 - val_f1_m: 0.0320\n",
      "Epoch 206/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.7824 - f1_m: 0.0862 - val_loss: 0.5272 - val_accuracy: 0.7762 - val_f1_m: 0.0445\n",
      "Epoch 207/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.7839 - f1_m: 0.1009 - val_loss: 0.5260 - val_accuracy: 0.7770 - val_f1_m: 0.0446\n",
      "Epoch 208/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7826 - f1_m: 0.0849 - val_loss: 0.5271 - val_accuracy: 0.7770 - val_f1_m: 0.0428\n",
      "Epoch 209/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.7837 - f1_m: 0.0935 - val_loss: 0.5283 - val_accuracy: 0.7746 - val_f1_m: 0.0559\n",
      "Epoch 210/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4862 - accuracy: 0.7825 - f1_m: 0.1034 - val_loss: 0.5276 - val_accuracy: 0.7749 - val_f1_m: 0.0533\n",
      "Epoch 211/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7835 - f1_m: 0.0930 - val_loss: 0.5277 - val_accuracy: 0.7742 - val_f1_m: 0.0472\n",
      "Epoch 212/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.7842 - f1_m: 0.0976 - val_loss: 0.5279 - val_accuracy: 0.7749 - val_f1_m: 0.0503\n",
      "Epoch 213/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7842 - f1_m: 0.0982 - val_loss: 0.5281 - val_accuracy: 0.7762 - val_f1_m: 0.0418\n",
      "Epoch 214/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4858 - accuracy: 0.7832 - f1_m: 0.0956 - val_loss: 0.5282 - val_accuracy: 0.7752 - val_f1_m: 0.0440\n",
      "Epoch 215/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7835 - f1_m: 0.0914 - val_loss: 0.5293 - val_accuracy: 0.7725 - val_f1_m: 0.0645\n",
      "Epoch 216/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 0.7829 - f1_m: 0.0957 - val_loss: 0.5286 - val_accuracy: 0.7741 - val_f1_m: 0.0581\n",
      "Epoch 217/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.7830 - f1_m: 0.0946 - val_loss: 0.5290 - val_accuracy: 0.7745 - val_f1_m: 0.0507\n",
      "Epoch 218/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7831 - f1_m: 0.0940 - val_loss: 0.5276 - val_accuracy: 0.7751 - val_f1_m: 0.0607\n",
      "Epoch 219/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7825 - f1_m: 0.0940 - val_loss: 0.5300 - val_accuracy: 0.7767 - val_f1_m: 0.0402\n",
      "Epoch 220/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7831 - f1_m: 0.0920 - val_loss: 0.5285 - val_accuracy: 0.7739 - val_f1_m: 0.0612\n",
      "Epoch 221/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7835 - f1_m: 0.0975 - val_loss: 0.5286 - val_accuracy: 0.7748 - val_f1_m: 0.0433\n",
      "Epoch 222/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.7831 - f1_m: 0.0935 - val_loss: 0.5310 - val_accuracy: 0.7719 - val_f1_m: 0.0546\n",
      "Epoch 223/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7831 - f1_m: 0.0986 - val_loss: 0.5295 - val_accuracy: 0.7752 - val_f1_m: 0.0532\n",
      "Epoch 224/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7829 - f1_m: 0.0917 - val_loss: 0.5276 - val_accuracy: 0.7743 - val_f1_m: 0.0477\n",
      "Epoch 225/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4854 - accuracy: 0.7837 - f1_m: 0.0969 - val_loss: 0.5289 - val_accuracy: 0.7748 - val_f1_m: 0.0535\n",
      "Epoch 226/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4855 - accuracy: 0.7833 - f1_m: 0.0974 - val_loss: 0.5305 - val_accuracy: 0.7738 - val_f1_m: 0.0552\n",
      "Epoch 227/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7831 - f1_m: 0.0955 - val_loss: 0.5283 - val_accuracy: 0.7743 - val_f1_m: 0.0597\n",
      "Epoch 228/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7832 - f1_m: 0.1000 - val_loss: 0.5299 - val_accuracy: 0.7736 - val_f1_m: 0.0480\n",
      "Epoch 229/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7830 - f1_m: 0.0962 - val_loss: 0.5296 - val_accuracy: 0.7741 - val_f1_m: 0.0438\n",
      "Epoch 230/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7838 - f1_m: 0.1018 - val_loss: 0.5296 - val_accuracy: 0.7752 - val_f1_m: 0.0464\n",
      "Epoch 231/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7829 - f1_m: 0.0972 - val_loss: 0.5287 - val_accuracy: 0.7747 - val_f1_m: 0.0431\n",
      "Epoch 232/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7836 - f1_m: 0.0983 - val_loss: 0.5302 - val_accuracy: 0.7728 - val_f1_m: 0.0497\n",
      "Epoch 233/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7838 - f1_m: 0.0966 - val_loss: 0.5294 - val_accuracy: 0.7744 - val_f1_m: 0.0486\n",
      "Epoch 234/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7832 - f1_m: 0.0992 - val_loss: 0.5277 - val_accuracy: 0.7748 - val_f1_m: 0.0488\n",
      "Epoch 235/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7829 - f1_m: 0.0942 - val_loss: 0.5289 - val_accuracy: 0.7748 - val_f1_m: 0.0435\n",
      "Epoch 236/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4852 - accuracy: 0.7835 - f1_m: 0.0986 - val_loss: 0.5298 - val_accuracy: 0.7720 - val_f1_m: 0.0554\n",
      "Epoch 237/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4852 - accuracy: 0.7836 - f1_m: 0.1006 - val_loss: 0.5296 - val_accuracy: 0.7766 - val_f1_m: 0.0376\n",
      "Epoch 238/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4855 - accuracy: 0.7831 - f1_m: 0.0960 - val_loss: 0.5294 - val_accuracy: 0.7733 - val_f1_m: 0.0496\n",
      "Epoch 239/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.7836 - f1_m: 0.1027 - val_loss: 0.5296 - val_accuracy: 0.7751 - val_f1_m: 0.0501\n",
      "Epoch 240/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7829 - f1_m: 0.0951 - val_loss: 0.5290 - val_accuracy: 0.7756 - val_f1_m: 0.0474\n",
      "Epoch 241/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7837 - f1_m: 0.0990 - val_loss: 0.5313 - val_accuracy: 0.7739 - val_f1_m: 0.0485\n",
      "Epoch 242/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.7834 - f1_m: 0.0950 - val_loss: 0.5301 - val_accuracy: 0.7734 - val_f1_m: 0.0503\n",
      "Epoch 243/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7831 - f1_m: 0.0968 - val_loss: 0.5305 - val_accuracy: 0.7766 - val_f1_m: 0.0420\n",
      "Epoch 244/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4853 - accuracy: 0.7831 - f1_m: 0.0961 - val_loss: 0.5295 - val_accuracy: 0.7736 - val_f1_m: 0.0529\n",
      "Epoch 245/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.7838 - f1_m: 0.0994 - val_loss: 0.5294 - val_accuracy: 0.7737 - val_f1_m: 0.0459\n",
      "Epoch 246/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4849 - accuracy: 0.7834 - f1_m: 0.1017 - val_loss: 0.5300 - val_accuracy: 0.7746 - val_f1_m: 0.0416\n",
      "Epoch 247/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7829 - f1_m: 0.0985 - val_loss: 0.5299 - val_accuracy: 0.7740 - val_f1_m: 0.0408\n",
      "Epoch 248/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7833 - f1_m: 0.0955 - val_loss: 0.5310 - val_accuracy: 0.7740 - val_f1_m: 0.0494\n",
      "Epoch 249/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7832 - f1_m: 0.1015 - val_loss: 0.5297 - val_accuracy: 0.7741 - val_f1_m: 0.0419\n",
      "Epoch 250/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7832 - f1_m: 0.0977 - val_loss: 0.5314 - val_accuracy: 0.7736 - val_f1_m: 0.0508\n",
      "Epoch 251/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.7830 - f1_m: 0.0959 - val_loss: 0.5299 - val_accuracy: 0.7741 - val_f1_m: 0.0483\n",
      "Epoch 252/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7828 - f1_m: 0.0985 - val_loss: 0.5314 - val_accuracy: 0.7737 - val_f1_m: 0.0523\n",
      "Epoch 253/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7835 - f1_m: 0.0988 - val_loss: 0.5303 - val_accuracy: 0.7741 - val_f1_m: 0.0427\n",
      "Epoch 254/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7832 - f1_m: 0.0999 - val_loss: 0.5313 - val_accuracy: 0.7765 - val_f1_m: 0.0403\n",
      "Epoch 255/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7829 - f1_m: 0.1012 - val_loss: 0.5288 - val_accuracy: 0.7738 - val_f1_m: 0.0509\n",
      "Epoch 256/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.7832 - f1_m: 0.1016 - val_loss: 0.5293 - val_accuracy: 0.7746 - val_f1_m: 0.0409\n",
      "Epoch 257/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4853 - accuracy: 0.7830 - f1_m: 0.0937 - val_loss: 0.5282 - val_accuracy: 0.7743 - val_f1_m: 0.0484\n",
      "Epoch 258/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7832 - f1_m: 0.0982 - val_loss: 0.5295 - val_accuracy: 0.7750 - val_f1_m: 0.0433\n",
      "Epoch 259/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.7837 - f1_m: 0.0989 - val_loss: 0.5297 - val_accuracy: 0.7733 - val_f1_m: 0.0540\n",
      "Epoch 260/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7835 - f1_m: 0.1037 - val_loss: 0.5310 - val_accuracy: 0.7746 - val_f1_m: 0.0469\n",
      "Epoch 261/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.7828 - f1_m: 0.0971 - val_loss: 0.5288 - val_accuracy: 0.7755 - val_f1_m: 0.0472\n",
      "Epoch 262/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.7832 - f1_m: 0.0976 - val_loss: 0.5292 - val_accuracy: 0.7737 - val_f1_m: 0.0478\n",
      "Epoch 263/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.7836 - f1_m: 0.0999 - val_loss: 0.5303 - val_accuracy: 0.7734 - val_f1_m: 0.0553\n",
      "Epoch 264/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7828 - f1_m: 0.1006 - val_loss: 0.5301 - val_accuracy: 0.7747 - val_f1_m: 0.0457\n",
      "Epoch 265/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7836 - f1_m: 0.0991 - val_loss: 0.5311 - val_accuracy: 0.7727 - val_f1_m: 0.0481\n",
      "Epoch 266/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4849 - accuracy: 0.7829 - f1_m: 0.0987 - val_loss: 0.5302 - val_accuracy: 0.7741 - val_f1_m: 0.0382\n",
      "Epoch 267/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.7835 - f1_m: 0.0980 - val_loss: 0.5315 - val_accuracy: 0.7732 - val_f1_m: 0.0476\n",
      "Epoch 268/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.7834 - f1_m: 0.0970 - val_loss: 0.5325 - val_accuracy: 0.7724 - val_f1_m: 0.0529\n",
      "Epoch 269/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4847 - accuracy: 0.7831 - f1_m: 0.0980 - val_loss: 0.5296 - val_accuracy: 0.7735 - val_f1_m: 0.0415\n",
      "Epoch 270/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.7835 - f1_m: 0.1025 - val_loss: 0.5317 - val_accuracy: 0.7729 - val_f1_m: 0.0543\n",
      "Epoch 271/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7835 - f1_m: 0.1024 - val_loss: 0.5311 - val_accuracy: 0.7759 - val_f1_m: 0.0467\n",
      "Epoch 272/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7835 - f1_m: 0.0976 - val_loss: 0.5299 - val_accuracy: 0.7762 - val_f1_m: 0.0441\n",
      "Epoch 273/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.7835 - f1_m: 0.0971 - val_loss: 0.5303 - val_accuracy: 0.7729 - val_f1_m: 0.0554\n",
      "Epoch 274/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4847 - accuracy: 0.7835 - f1_m: 0.1002 - val_loss: 0.5324 - val_accuracy: 0.7711 - val_f1_m: 0.0590\n",
      "Epoch 275/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4847 - accuracy: 0.7836 - f1_m: 0.1063 - val_loss: 0.5305 - val_accuracy: 0.7741 - val_f1_m: 0.0466\n",
      "Epoch 276/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.7835 - f1_m: 0.1019 - val_loss: 0.5306 - val_accuracy: 0.7729 - val_f1_m: 0.0512\n",
      "Epoch 277/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7834 - f1_m: 0.0969 - val_loss: 0.5318 - val_accuracy: 0.7702 - val_f1_m: 0.0587\n",
      "Epoch 278/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.7837 - f1_m: 0.1040 - val_loss: 0.5316 - val_accuracy: 0.7712 - val_f1_m: 0.0526\n",
      "Epoch 279/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.7837 - f1_m: 0.1016 - val_loss: 0.5308 - val_accuracy: 0.7744 - val_f1_m: 0.0446\n",
      "Epoch 280/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7830 - f1_m: 0.1011 - val_loss: 0.5315 - val_accuracy: 0.7739 - val_f1_m: 0.0448\n",
      "Epoch 281/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4849 - accuracy: 0.7833 - f1_m: 0.0989 - val_loss: 0.5310 - val_accuracy: 0.7735 - val_f1_m: 0.0580\n",
      "Epoch 282/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7836 - f1_m: 0.1016 - val_loss: 0.5309 - val_accuracy: 0.7737 - val_f1_m: 0.0494\n",
      "Epoch 283/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.7835 - f1_m: 0.1022 - val_loss: 0.5324 - val_accuracy: 0.7716 - val_f1_m: 0.0522\n",
      "Epoch 284/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4847 - accuracy: 0.7830 - f1_m: 0.0969 - val_loss: 0.5297 - val_accuracy: 0.7748 - val_f1_m: 0.0401\n",
      "Epoch 285/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7832 - f1_m: 0.0996 - val_loss: 0.5319 - val_accuracy: 0.7721 - val_f1_m: 0.0515\n",
      "Epoch 286/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.7834 - f1_m: 0.1048 - val_loss: 0.5303 - val_accuracy: 0.7747 - val_f1_m: 0.0523\n",
      "Epoch 287/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7837 - f1_m: 0.0977 - val_loss: 0.5320 - val_accuracy: 0.7769 - val_f1_m: 0.0377\n",
      "Epoch 288/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.7833 - f1_m: 0.1018 - val_loss: 0.5306 - val_accuracy: 0.7737 - val_f1_m: 0.0528\n",
      "Epoch 289/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.7840 - f1_m: 0.0977 - val_loss: 0.5317 - val_accuracy: 0.7720 - val_f1_m: 0.0531\n",
      "Epoch 290/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7843 - f1_m: 0.1054 - val_loss: 0.5315 - val_accuracy: 0.7744 - val_f1_m: 0.0439\n",
      "Epoch 291/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7843 - f1_m: 0.1013 - val_loss: 0.5314 - val_accuracy: 0.7748 - val_f1_m: 0.0432\n",
      "Epoch 292/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4849 - accuracy: 0.7838 - f1_m: 0.1035 - val_loss: 0.5325 - val_accuracy: 0.7723 - val_f1_m: 0.0578\n",
      "Epoch 293/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.7837 - f1_m: 0.0970 - val_loss: 0.5319 - val_accuracy: 0.7728 - val_f1_m: 0.0493\n",
      "Epoch 294/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.7835 - f1_m: 0.1026 - val_loss: 0.5312 - val_accuracy: 0.7722 - val_f1_m: 0.0568\n",
      "Epoch 295/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4842 - accuracy: 0.7835 - f1_m: 0.1029 - val_loss: 0.5322 - val_accuracy: 0.7751 - val_f1_m: 0.0443\n",
      "Epoch 296/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7833 - f1_m: 0.0980 - val_loss: 0.5296 - val_accuracy: 0.7768 - val_f1_m: 0.0440\n",
      "Epoch 297/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.7837 - f1_m: 0.0960 - val_loss: 0.5306 - val_accuracy: 0.7736 - val_f1_m: 0.0541\n",
      "Epoch 298/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.7840 - f1_m: 0.1060 - val_loss: 0.5305 - val_accuracy: 0.7744 - val_f1_m: 0.0466\n",
      "Epoch 299/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7839 - f1_m: 0.1048 - val_loss: 0.5300 - val_accuracy: 0.7755 - val_f1_m: 0.0462\n",
      "Epoch 300/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.7834 - f1_m: 0.1035 - val_loss: 0.5318 - val_accuracy: 0.7728 - val_f1_m: 0.0502\n",
      "Epoch 301/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4842 - accuracy: 0.7832 - f1_m: 0.1048 - val_loss: 0.5303 - val_accuracy: 0.7760 - val_f1_m: 0.0442\n",
      "Epoch 302/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4842 - accuracy: 0.7845 - f1_m: 0.1012 - val_loss: 0.5310 - val_accuracy: 0.7745 - val_f1_m: 0.0484\n",
      "Epoch 303/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7838 - f1_m: 0.1048 - val_loss: 0.5308 - val_accuracy: 0.7776 - val_f1_m: 0.0393\n",
      "Epoch 304/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.7840 - f1_m: 0.1020 - val_loss: 0.5310 - val_accuracy: 0.7740 - val_f1_m: 0.0501\n",
      "Epoch 305/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.7834 - f1_m: 0.1024 - val_loss: 0.5304 - val_accuracy: 0.7735 - val_f1_m: 0.0481\n",
      "Epoch 306/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7839 - f1_m: 0.1030 - val_loss: 0.5321 - val_accuracy: 0.7742 - val_f1_m: 0.0476\n",
      "Epoch 307/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7837 - f1_m: 0.1006 - val_loss: 0.5319 - val_accuracy: 0.7741 - val_f1_m: 0.0428\n",
      "Epoch 308/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.7837 - f1_m: 0.1027 - val_loss: 0.5325 - val_accuracy: 0.7733 - val_f1_m: 0.0451\n",
      "Epoch 309/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7834 - f1_m: 0.1015 - val_loss: 0.5309 - val_accuracy: 0.7736 - val_f1_m: 0.0478\n",
      "Epoch 310/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.7837 - f1_m: 0.1043 - val_loss: 0.5323 - val_accuracy: 0.7718 - val_f1_m: 0.0492\n",
      "Epoch 311/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.7837 - f1_m: 0.1034 - val_loss: 0.5289 - val_accuracy: 0.7746 - val_f1_m: 0.0477\n",
      "Epoch 312/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.7836 - f1_m: 0.1014 - val_loss: 0.5305 - val_accuracy: 0.7753 - val_f1_m: 0.0416\n",
      "Epoch 313/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4840 - accuracy: 0.7839 - f1_m: 0.1062 - val_loss: 0.5315 - val_accuracy: 0.7767 - val_f1_m: 0.0371\n",
      "Epoch 314/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4840 - accuracy: 0.7834 - f1_m: 0.1040 - val_loss: 0.5298 - val_accuracy: 0.7744 - val_f1_m: 0.0432\n",
      "Epoch 315/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.7841 - f1_m: 0.0996 - val_loss: 0.5316 - val_accuracy: 0.7730 - val_f1_m: 0.0493\n",
      "Epoch 316/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4839 - accuracy: 0.7839 - f1_m: 0.1050 - val_loss: 0.5307 - val_accuracy: 0.7746 - val_f1_m: 0.0429\n",
      "Epoch 317/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7836 - f1_m: 0.1015 - val_loss: 0.5294 - val_accuracy: 0.7744 - val_f1_m: 0.0497\n",
      "Epoch 318/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7831 - f1_m: 0.0960 - val_loss: 0.5312 - val_accuracy: 0.7730 - val_f1_m: 0.0554\n",
      "Epoch 319/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7833 - f1_m: 0.1090 - val_loss: 0.5304 - val_accuracy: 0.7770 - val_f1_m: 0.0393\n",
      "Epoch 320/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7840 - f1_m: 0.1022 - val_loss: 0.5305 - val_accuracy: 0.7755 - val_f1_m: 0.0471\n",
      "Epoch 321/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7840 - f1_m: 0.1043 - val_loss: 0.5314 - val_accuracy: 0.7730 - val_f1_m: 0.0471\n",
      "Epoch 322/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7835 - f1_m: 0.1057 - val_loss: 0.5312 - val_accuracy: 0.7721 - val_f1_m: 0.0507\n",
      "Epoch 323/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4839 - accuracy: 0.7844 - f1_m: 0.1074 - val_loss: 0.5323 - val_accuracy: 0.7726 - val_f1_m: 0.0530\n",
      "Epoch 324/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7841 - f1_m: 0.1054 - val_loss: 0.5324 - val_accuracy: 0.7737 - val_f1_m: 0.0470\n",
      "Epoch 325/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7837 - f1_m: 0.1075 - val_loss: 0.5299 - val_accuracy: 0.7740 - val_f1_m: 0.0475\n",
      "Epoch 326/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7844 - f1_m: 0.1053 - val_loss: 0.5311 - val_accuracy: 0.7735 - val_f1_m: 0.0467\n",
      "Epoch 327/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7836 - f1_m: 0.1057 - val_loss: 0.5305 - val_accuracy: 0.7753 - val_f1_m: 0.0423\n",
      "Epoch 328/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7830 - f1_m: 0.1024 - val_loss: 0.5310 - val_accuracy: 0.7732 - val_f1_m: 0.0557\n",
      "Epoch 329/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7839 - f1_m: 0.1030 - val_loss: 0.5337 - val_accuracy: 0.7713 - val_f1_m: 0.0511\n",
      "Epoch 330/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7839 - f1_m: 0.1072 - val_loss: 0.5298 - val_accuracy: 0.7748 - val_f1_m: 0.0524\n",
      "Epoch 331/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7838 - f1_m: 0.1014 - val_loss: 0.5328 - val_accuracy: 0.7746 - val_f1_m: 0.0441\n",
      "Epoch 332/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4836 - accuracy: 0.7838 - f1_m: 0.1035 - val_loss: 0.5312 - val_accuracy: 0.7749 - val_f1_m: 0.0426\n",
      "Epoch 333/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4842 - accuracy: 0.7833 - f1_m: 0.1038 - val_loss: 0.5305 - val_accuracy: 0.7729 - val_f1_m: 0.0544\n",
      "Epoch 334/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4839 - accuracy: 0.7835 - f1_m: 0.1015 - val_loss: 0.5315 - val_accuracy: 0.7770 - val_f1_m: 0.0381\n",
      "Epoch 335/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4834 - accuracy: 0.7837 - f1_m: 0.1038 - val_loss: 0.5324 - val_accuracy: 0.7725 - val_f1_m: 0.0518\n",
      "Epoch 336/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4836 - accuracy: 0.7845 - f1_m: 0.1039 - val_loss: 0.5313 - val_accuracy: 0.7719 - val_f1_m: 0.0482\n",
      "Epoch 337/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7841 - f1_m: 0.1044 - val_loss: 0.5311 - val_accuracy: 0.7737 - val_f1_m: 0.0498\n",
      "Epoch 338/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7834 - f1_m: 0.1031 - val_loss: 0.5303 - val_accuracy: 0.7750 - val_f1_m: 0.0521\n",
      "Epoch 339/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7837 - f1_m: 0.1037 - val_loss: 0.5302 - val_accuracy: 0.7732 - val_f1_m: 0.0553\n",
      "Epoch 340/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4832 - accuracy: 0.7839 - f1_m: 0.1047 - val_loss: 0.5305 - val_accuracy: 0.7757 - val_f1_m: 0.0412\n",
      "Epoch 341/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4837 - accuracy: 0.7836 - f1_m: 0.1024 - val_loss: 0.5320 - val_accuracy: 0.7737 - val_f1_m: 0.0486\n",
      "Epoch 342/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4834 - accuracy: 0.7843 - f1_m: 0.1065 - val_loss: 0.5319 - val_accuracy: 0.7748 - val_f1_m: 0.0407\n",
      "Epoch 343/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.7837 - f1_m: 0.1018 - val_loss: 0.5301 - val_accuracy: 0.7744 - val_f1_m: 0.0473\n",
      "Epoch 344/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4836 - accuracy: 0.7838 - f1_m: 0.0999 - val_loss: 0.5315 - val_accuracy: 0.7781 - val_f1_m: 0.0382\n",
      "Epoch 345/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7845 - f1_m: 0.1010 - val_loss: 0.5305 - val_accuracy: 0.7750 - val_f1_m: 0.0463\n",
      "Epoch 346/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.7840 - f1_m: 0.1065 - val_loss: 0.5306 - val_accuracy: 0.7760 - val_f1_m: 0.0478\n",
      "Epoch 347/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4835 - accuracy: 0.7839 - f1_m: 0.1046 - val_loss: 0.5314 - val_accuracy: 0.7740 - val_f1_m: 0.0433\n",
      "Epoch 348/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4835 - accuracy: 0.7841 - f1_m: 0.1031 - val_loss: 0.5314 - val_accuracy: 0.7733 - val_f1_m: 0.0539\n",
      "Epoch 349/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7846 - f1_m: 0.1066 - val_loss: 0.5323 - val_accuracy: 0.7727 - val_f1_m: 0.0552\n",
      "Epoch 350/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7841 - f1_m: 0.1075 - val_loss: 0.5316 - val_accuracy: 0.7722 - val_f1_m: 0.0527\n",
      "Epoch 351/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4832 - accuracy: 0.7839 - f1_m: 0.1071 - val_loss: 0.5332 - val_accuracy: 0.7745 - val_f1_m: 0.0435\n",
      "Epoch 352/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4835 - accuracy: 0.7848 - f1_m: 0.1111 - val_loss: 0.5320 - val_accuracy: 0.7727 - val_f1_m: 0.0479\n",
      "Epoch 353/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4833 - accuracy: 0.7837 - f1_m: 0.1071 - val_loss: 0.5318 - val_accuracy: 0.7742 - val_f1_m: 0.0479\n",
      "Epoch 354/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4834 - accuracy: 0.7846 - f1_m: 0.1125 - val_loss: 0.5325 - val_accuracy: 0.7721 - val_f1_m: 0.0519\n",
      "Epoch 355/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7841 - f1_m: 0.1084 - val_loss: 0.5319 - val_accuracy: 0.7769 - val_f1_m: 0.0377\n",
      "Epoch 356/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4835 - accuracy: 0.7837 - f1_m: 0.1126 - val_loss: 0.5306 - val_accuracy: 0.7770 - val_f1_m: 0.0411\n",
      "Epoch 357/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4834 - accuracy: 0.7843 - f1_m: 0.1024 - val_loss: 0.5318 - val_accuracy: 0.7732 - val_f1_m: 0.0462\n",
      "Epoch 358/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4833 - accuracy: 0.7838 - f1_m: 0.1039 - val_loss: 0.5314 - val_accuracy: 0.7730 - val_f1_m: 0.0509\n",
      "Epoch 359/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4833 - accuracy: 0.7845 - f1_m: 0.1119 - val_loss: 0.5328 - val_accuracy: 0.7788 - val_f1_m: 0.0355\n",
      "Epoch 360/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7851 - f1_m: 0.1116 - val_loss: 0.5318 - val_accuracy: 0.7735 - val_f1_m: 0.0497\n",
      "Epoch 361/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4831 - accuracy: 0.7842 - f1_m: 0.1084 - val_loss: 0.5330 - val_accuracy: 0.7745 - val_f1_m: 0.0430\n",
      "Epoch 362/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4833 - accuracy: 0.7842 - f1_m: 0.1099 - val_loss: 0.5318 - val_accuracy: 0.7755 - val_f1_m: 0.0437\n",
      "Epoch 363/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4831 - accuracy: 0.7836 - f1_m: 0.1034 - val_loss: 0.5318 - val_accuracy: 0.7732 - val_f1_m: 0.0517\n",
      "Epoch 364/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4833 - accuracy: 0.7840 - f1_m: 0.1082 - val_loss: 0.5321 - val_accuracy: 0.7727 - val_f1_m: 0.0458\n",
      "Epoch 365/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4834 - accuracy: 0.7847 - f1_m: 0.1101 - val_loss: 0.5325 - val_accuracy: 0.7748 - val_f1_m: 0.0474\n",
      "Epoch 366/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4832 - accuracy: 0.7845 - f1_m: 0.1075 - val_loss: 0.5327 - val_accuracy: 0.7739 - val_f1_m: 0.0483\n",
      "Epoch 367/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4832 - accuracy: 0.7846 - f1_m: 0.1109 - val_loss: 0.5326 - val_accuracy: 0.7727 - val_f1_m: 0.0494\n",
      "Epoch 368/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4834 - accuracy: 0.7843 - f1_m: 0.1093 - val_loss: 0.5347 - val_accuracy: 0.7744 - val_f1_m: 0.0476\n",
      "Epoch 369/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4834 - accuracy: 0.7841 - f1_m: 0.1095 - val_loss: 0.5322 - val_accuracy: 0.7771 - val_f1_m: 0.0395\n",
      "Epoch 370/1000\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.4820 - accuracy: 0.7857 - f1_m: 0.105 - 0s 1ms/step - loss: 0.4831 - accuracy: 0.7843 - f1_m: 0.1077 - val_loss: 0.5316 - val_accuracy: 0.7736 - val_f1_m: 0.0528\n",
      "Epoch 371/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4833 - accuracy: 0.7841 - f1_m: 0.1081 - val_loss: 0.5318 - val_accuracy: 0.7741 - val_f1_m: 0.0470\n",
      "Epoch 372/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4833 - accuracy: 0.7844 - f1_m: 0.1078 - val_loss: 0.5306 - val_accuracy: 0.7764 - val_f1_m: 0.0416\n",
      "Epoch 373/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4830 - accuracy: 0.7845 - f1_m: 0.1047 - val_loss: 0.5330 - val_accuracy: 0.7707 - val_f1_m: 0.0571\n",
      "Epoch 374/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7840 - f1_m: 0.1098 - val_loss: 0.5324 - val_accuracy: 0.7758 - val_f1_m: 0.0461\n",
      "Epoch 375/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4831 - accuracy: 0.7847 - f1_m: 0.1082 - val_loss: 0.5315 - val_accuracy: 0.7737 - val_f1_m: 0.0437\n",
      "Epoch 376/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4832 - accuracy: 0.7850 - f1_m: 0.1084 - val_loss: 0.5324 - val_accuracy: 0.7729 - val_f1_m: 0.0467\n",
      "Epoch 377/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7844 - f1_m: 0.1054 - val_loss: 0.5337 - val_accuracy: 0.7710 - val_f1_m: 0.0499\n",
      "Epoch 378/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7849 - f1_m: 0.1087 - val_loss: 0.5323 - val_accuracy: 0.7750 - val_f1_m: 0.0401\n",
      "Epoch 379/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7838 - f1_m: 0.1077 - val_loss: 0.5311 - val_accuracy: 0.7779 - val_f1_m: 0.0384\n",
      "Epoch 380/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4830 - accuracy: 0.7841 - f1_m: 0.1074 - val_loss: 0.5326 - val_accuracy: 0.7761 - val_f1_m: 0.0422\n",
      "Epoch 381/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7846 - f1_m: 0.1073 - val_loss: 0.5339 - val_accuracy: 0.7715 - val_f1_m: 0.0537\n",
      "Epoch 382/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7833 - f1_m: 0.1019 - val_loss: 0.5326 - val_accuracy: 0.7723 - val_f1_m: 0.0561\n",
      "Epoch 383/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4831 - accuracy: 0.7844 - f1_m: 0.1128 - val_loss: 0.5323 - val_accuracy: 0.7735 - val_f1_m: 0.0515\n",
      "Epoch 384/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4831 - accuracy: 0.7848 - f1_m: 0.1060 - val_loss: 0.5330 - val_accuracy: 0.7724 - val_f1_m: 0.0573\n",
      "Epoch 385/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4830 - accuracy: 0.7837 - f1_m: 0.1033 - val_loss: 0.5318 - val_accuracy: 0.7747 - val_f1_m: 0.0496\n",
      "Epoch 386/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4830 - accuracy: 0.7848 - f1_m: 0.1116 - val_loss: 0.5317 - val_accuracy: 0.7727 - val_f1_m: 0.0470\n",
      "Epoch 387/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7845 - f1_m: 0.1098 - val_loss: 0.5315 - val_accuracy: 0.7746 - val_f1_m: 0.0498\n",
      "Epoch 388/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7845 - f1_m: 0.1069 - val_loss: 0.5345 - val_accuracy: 0.7739 - val_f1_m: 0.0397\n",
      "Epoch 389/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.7840 - f1_m: 0.1074 - val_loss: 0.5330 - val_accuracy: 0.7719 - val_f1_m: 0.0553\n",
      "Epoch 390/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4830 - accuracy: 0.7846 - f1_m: 0.1090 - val_loss: 0.5330 - val_accuracy: 0.7741 - val_f1_m: 0.0574\n",
      "Epoch 391/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.7847 - f1_m: 0.1089 - val_loss: 0.5313 - val_accuracy: 0.7764 - val_f1_m: 0.0348\n",
      "Epoch 392/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7848 - f1_m: 0.1143 - val_loss: 0.5317 - val_accuracy: 0.7746 - val_f1_m: 0.0465\n",
      "Epoch 393/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4831 - accuracy: 0.7847 - f1_m: 0.1116 - val_loss: 0.5310 - val_accuracy: 0.7727 - val_f1_m: 0.0544\n",
      "Epoch 394/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7844 - f1_m: 0.1071 - val_loss: 0.5316 - val_accuracy: 0.7735 - val_f1_m: 0.0527\n",
      "Epoch 395/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4826 - accuracy: 0.7853 - f1_m: 0.1104 - val_loss: 0.5324 - val_accuracy: 0.7722 - val_f1_m: 0.0566\n",
      "Epoch 396/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7850 - f1_m: 0.1085 - val_loss: 0.5335 - val_accuracy: 0.7725 - val_f1_m: 0.0613\n",
      "Epoch 397/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7843 - f1_m: 0.1118 - val_loss: 0.5311 - val_accuracy: 0.7755 - val_f1_m: 0.0444\n",
      "Epoch 398/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7850 - f1_m: 0.1092 - val_loss: 0.5316 - val_accuracy: 0.7759 - val_f1_m: 0.0422\n",
      "Epoch 399/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7848 - f1_m: 0.1075 - val_loss: 0.5330 - val_accuracy: 0.7739 - val_f1_m: 0.0398\n",
      "Epoch 400/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7841 - f1_m: 0.1085 - val_loss: 0.5321 - val_accuracy: 0.7745 - val_f1_m: 0.0403\n",
      "Epoch 401/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7855 - f1_m: 0.1084 - val_loss: 0.5340 - val_accuracy: 0.7719 - val_f1_m: 0.0543\n",
      "Epoch 402/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4828 - accuracy: 0.7860 - f1_m: 0.1171 - val_loss: 0.5312 - val_accuracy: 0.7740 - val_f1_m: 0.0505\n",
      "Epoch 403/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.7850 - f1_m: 0.1071 - val_loss: 0.5327 - val_accuracy: 0.7730 - val_f1_m: 0.0540\n",
      "Epoch 404/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4832 - accuracy: 0.7847 - f1_m: 0.1110 - val_loss: 0.5370 - val_accuracy: 0.7738 - val_f1_m: 0.0417\n",
      "Epoch 405/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4832 - accuracy: 0.7847 - f1_m: 0.1065 - val_loss: 0.5348 - val_accuracy: 0.7696 - val_f1_m: 0.0595\n",
      "Epoch 406/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4829 - accuracy: 0.7837 - f1_m: 0.1089 - val_loss: 0.5332 - val_accuracy: 0.7744 - val_f1_m: 0.0439\n",
      "Epoch 407/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7845 - f1_m: 0.1029 - val_loss: 0.5326 - val_accuracy: 0.7720 - val_f1_m: 0.0582\n",
      "Epoch 408/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4828 - accuracy: 0.7848 - f1_m: 0.1064 - val_loss: 0.5323 - val_accuracy: 0.7715 - val_f1_m: 0.0555\n",
      "Epoch 409/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.7848 - f1_m: 0.1128 - val_loss: 0.5323 - val_accuracy: 0.7735 - val_f1_m: 0.0478\n",
      "Epoch 410/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4828 - accuracy: 0.7841 - f1_m: 0.1043 - val_loss: 0.5328 - val_accuracy: 0.7712 - val_f1_m: 0.0587\n",
      "Epoch 411/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4825 - accuracy: 0.7851 - f1_m: 0.1097 - val_loss: 0.5342 - val_accuracy: 0.7703 - val_f1_m: 0.0624\n",
      "Epoch 412/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.7849 - f1_m: 0.1105 - val_loss: 0.5332 - val_accuracy: 0.7719 - val_f1_m: 0.0566\n",
      "Epoch 413/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4826 - accuracy: 0.7847 - f1_m: 0.1133 - val_loss: 0.5331 - val_accuracy: 0.7729 - val_f1_m: 0.0551\n",
      "Epoch 414/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4824 - accuracy: 0.7849 - f1_m: 0.1064 - val_loss: 0.5337 - val_accuracy: 0.7712 - val_f1_m: 0.0577\n",
      "Epoch 415/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.7848 - f1_m: 0.1087 - val_loss: 0.5324 - val_accuracy: 0.7734 - val_f1_m: 0.0480\n",
      "Epoch 416/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7850 - f1_m: 0.1070 - val_loss: 0.5310 - val_accuracy: 0.7729 - val_f1_m: 0.0496\n",
      "Epoch 417/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4824 - accuracy: 0.7850 - f1_m: 0.1106 - val_loss: 0.5316 - val_accuracy: 0.7747 - val_f1_m: 0.0482\n",
      "Epoch 418/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7843 - f1_m: 0.1037 - val_loss: 0.5319 - val_accuracy: 0.7711 - val_f1_m: 0.0660\n",
      "Epoch 419/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7848 - f1_m: 0.1117 - val_loss: 0.5333 - val_accuracy: 0.7721 - val_f1_m: 0.0479\n",
      "Epoch 420/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4829 - accuracy: 0.7847 - f1_m: 0.1088 - val_loss: 0.5329 - val_accuracy: 0.7718 - val_f1_m: 0.0513\n",
      "Epoch 421/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4826 - accuracy: 0.7854 - f1_m: 0.1119 - val_loss: 0.5315 - val_accuracy: 0.7745 - val_f1_m: 0.0522\n",
      "Epoch 422/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7847 - f1_m: 0.1091 - val_loss: 0.5319 - val_accuracy: 0.7732 - val_f1_m: 0.0499\n",
      "Epoch 423/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.7850 - f1_m: 0.1143 - val_loss: 0.5330 - val_accuracy: 0.7716 - val_f1_m: 0.0563\n",
      "Epoch 424/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7849 - f1_m: 0.1102 - val_loss: 0.5334 - val_accuracy: 0.7725 - val_f1_m: 0.0443\n",
      "Epoch 425/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4820 - accuracy: 0.7846 - f1_m: 0.1086 - val_loss: 0.5331 - val_accuracy: 0.7740 - val_f1_m: 0.0411\n",
      "Epoch 426/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.7851 - f1_m: 0.1097 - val_loss: 0.5335 - val_accuracy: 0.7710 - val_f1_m: 0.0539\n",
      "Epoch 427/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4825 - accuracy: 0.7847 - f1_m: 0.1094 - val_loss: 0.5328 - val_accuracy: 0.7742 - val_f1_m: 0.0441\n",
      "Epoch 428/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7851 - f1_m: 0.1115 - val_loss: 0.5330 - val_accuracy: 0.7726 - val_f1_m: 0.0519\n",
      "Epoch 429/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4821 - accuracy: 0.7849 - f1_m: 0.1122 - val_loss: 0.5339 - val_accuracy: 0.7742 - val_f1_m: 0.0429\n",
      "Epoch 430/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7845 - f1_m: 0.1083 - val_loss: 0.5316 - val_accuracy: 0.7753 - val_f1_m: 0.0465\n",
      "Epoch 431/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4820 - accuracy: 0.7852 - f1_m: 0.1129 - val_loss: 0.5323 - val_accuracy: 0.7727 - val_f1_m: 0.0552\n",
      "Epoch 432/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7846 - f1_m: 0.1114 - val_loss: 0.5321 - val_accuracy: 0.7709 - val_f1_m: 0.0552\n",
      "Epoch 433/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7851 - f1_m: 0.1110 - val_loss: 0.5317 - val_accuracy: 0.7736 - val_f1_m: 0.0489\n",
      "Epoch 434/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7848 - f1_m: 0.1113 - val_loss: 0.5329 - val_accuracy: 0.7722 - val_f1_m: 0.0514\n",
      "Epoch 435/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7856 - f1_m: 0.1140 - val_loss: 0.5332 - val_accuracy: 0.7723 - val_f1_m: 0.0458\n",
      "Epoch 436/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7856 - f1_m: 0.1097 - val_loss: 0.5335 - val_accuracy: 0.7737 - val_f1_m: 0.0447\n",
      "Epoch 437/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7852 - f1_m: 0.1127 - val_loss: 0.5303 - val_accuracy: 0.7743 - val_f1_m: 0.0459\n",
      "Epoch 438/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7848 - f1_m: 0.1114 - val_loss: 0.5334 - val_accuracy: 0.7723 - val_f1_m: 0.0497\n",
      "Epoch 439/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7841 - f1_m: 0.1034 - val_loss: 0.5329 - val_accuracy: 0.7714 - val_f1_m: 0.0592\n",
      "Epoch 440/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7853 - f1_m: 0.1136 - val_loss: 0.5353 - val_accuracy: 0.7701 - val_f1_m: 0.0656\n",
      "Epoch 441/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7853 - f1_m: 0.1140 - val_loss: 0.5336 - val_accuracy: 0.7715 - val_f1_m: 0.0579\n",
      "Epoch 442/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7850 - f1_m: 0.1101 - val_loss: 0.5327 - val_accuracy: 0.7742 - val_f1_m: 0.0394\n",
      "Epoch 443/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4819 - accuracy: 0.7845 - f1_m: 0.1070 - val_loss: 0.5331 - val_accuracy: 0.7745 - val_f1_m: 0.0453\n",
      "Epoch 444/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7857 - f1_m: 0.1119 - val_loss: 0.5324 - val_accuracy: 0.7741 - val_f1_m: 0.0433\n",
      "Epoch 445/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4820 - accuracy: 0.7850 - f1_m: 0.1154 - val_loss: 0.5328 - val_accuracy: 0.7737 - val_f1_m: 0.0420\n",
      "Epoch 446/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4819 - accuracy: 0.7849 - f1_m: 0.1114 - val_loss: 0.5311 - val_accuracy: 0.7742 - val_f1_m: 0.0459\n",
      "Epoch 447/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7845 - f1_m: 0.1066 - val_loss: 0.5318 - val_accuracy: 0.7713 - val_f1_m: 0.0560\n",
      "Epoch 448/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7846 - f1_m: 0.1121 - val_loss: 0.5313 - val_accuracy: 0.7757 - val_f1_m: 0.0443\n",
      "Epoch 449/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4820 - accuracy: 0.7856 - f1_m: 0.1097 - val_loss: 0.5337 - val_accuracy: 0.7717 - val_f1_m: 0.0528\n",
      "Epoch 450/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4818 - accuracy: 0.7850 - f1_m: 0.1124 - val_loss: 0.5313 - val_accuracy: 0.7732 - val_f1_m: 0.0530\n",
      "Epoch 451/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4818 - accuracy: 0.7846 - f1_m: 0.1095 - val_loss: 0.5331 - val_accuracy: 0.7730 - val_f1_m: 0.0467\n",
      "Epoch 452/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.7852 - f1_m: 0.1142 - val_loss: 0.5338 - val_accuracy: 0.7754 - val_f1_m: 0.0410\n",
      "Epoch 453/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7850 - f1_m: 0.1131 - val_loss: 0.5332 - val_accuracy: 0.7721 - val_f1_m: 0.0475\n",
      "Epoch 454/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7859 - f1_m: 0.1187 - val_loss: 0.5342 - val_accuracy: 0.7713 - val_f1_m: 0.0575\n",
      "Epoch 455/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4818 - accuracy: 0.7853 - f1_m: 0.1150 - val_loss: 0.5333 - val_accuracy: 0.7712 - val_f1_m: 0.0515\n",
      "Epoch 456/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4817 - accuracy: 0.7847 - f1_m: 0.1114 - val_loss: 0.5325 - val_accuracy: 0.7725 - val_f1_m: 0.0473\n",
      "Epoch 457/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4814 - accuracy: 0.7849 - f1_m: 0.1109 - val_loss: 0.5327 - val_accuracy: 0.7729 - val_f1_m: 0.0582\n",
      "Epoch 458/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4820 - accuracy: 0.7852 - f1_m: 0.1136 - val_loss: 0.5327 - val_accuracy: 0.7735 - val_f1_m: 0.0457\n",
      "Epoch 459/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4815 - accuracy: 0.7847 - f1_m: 0.1105 - val_loss: 0.5330 - val_accuracy: 0.7741 - val_f1_m: 0.0485\n",
      "Epoch 460/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7851 - f1_m: 0.1105 - val_loss: 0.5325 - val_accuracy: 0.7742 - val_f1_m: 0.0470\n",
      "Epoch 461/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4820 - accuracy: 0.7849 - f1_m: 0.1096 - val_loss: 0.5314 - val_accuracy: 0.7741 - val_f1_m: 0.0559\n",
      "Epoch 462/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4818 - accuracy: 0.7852 - f1_m: 0.1127 - val_loss: 0.5324 - val_accuracy: 0.7726 - val_f1_m: 0.0556\n",
      "Epoch 463/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4818 - accuracy: 0.7851 - f1_m: 0.1127 - val_loss: 0.5335 - val_accuracy: 0.7721 - val_f1_m: 0.0561\n",
      "Epoch 464/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4814 - accuracy: 0.7855 - f1_m: 0.1128 - val_loss: 0.5313 - val_accuracy: 0.7732 - val_f1_m: 0.0534\n",
      "Epoch 465/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.7851 - f1_m: 0.1101 - val_loss: 0.5322 - val_accuracy: 0.7729 - val_f1_m: 0.0542\n",
      "Epoch 466/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.7850 - f1_m: 0.1164 - val_loss: 0.5318 - val_accuracy: 0.7719 - val_f1_m: 0.0600\n",
      "Epoch 467/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4818 - accuracy: 0.7849 - f1_m: 0.1111 - val_loss: 0.5317 - val_accuracy: 0.7728 - val_f1_m: 0.0468\n",
      "Epoch 468/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7850 - f1_m: 0.1114 - val_loss: 0.5343 - val_accuracy: 0.7694 - val_f1_m: 0.0621\n",
      "Epoch 469/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4819 - accuracy: 0.7845 - f1_m: 0.1123 - val_loss: 0.5311 - val_accuracy: 0.7740 - val_f1_m: 0.0489\n",
      "Epoch 470/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4820 - accuracy: 0.7855 - f1_m: 0.1156 - val_loss: 0.5311 - val_accuracy: 0.7743 - val_f1_m: 0.0499\n",
      "Epoch 471/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4813 - accuracy: 0.7853 - f1_m: 0.1162 - val_loss: 0.5318 - val_accuracy: 0.7718 - val_f1_m: 0.0573\n",
      "Epoch 472/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4815 - accuracy: 0.7849 - f1_m: 0.1077 - val_loss: 0.5341 - val_accuracy: 0.7700 - val_f1_m: 0.0633\n",
      "Epoch 473/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4812 - accuracy: 0.7844 - f1_m: 0.1127 - val_loss: 0.5326 - val_accuracy: 0.7730 - val_f1_m: 0.0506\n",
      "Epoch 474/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4814 - accuracy: 0.7849 - f1_m: 0.1099 - val_loss: 0.5344 - val_accuracy: 0.7695 - val_f1_m: 0.0601\n",
      "Epoch 475/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7858 - f1_m: 0.1163 - val_loss: 0.5331 - val_accuracy: 0.7732 - val_f1_m: 0.0413\n",
      "Epoch 476/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4818 - accuracy: 0.7851 - f1_m: 0.1182 - val_loss: 0.5325 - val_accuracy: 0.7747 - val_f1_m: 0.0385\n",
      "Epoch 477/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.7855 - f1_m: 0.1077 - val_loss: 0.5325 - val_accuracy: 0.7710 - val_f1_m: 0.0557\n",
      "Epoch 478/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4815 - accuracy: 0.7861 - f1_m: 0.1195 - val_loss: 0.5316 - val_accuracy: 0.7752 - val_f1_m: 0.0465\n",
      "Epoch 479/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.7848 - f1_m: 0.1116 - val_loss: 0.5333 - val_accuracy: 0.7733 - val_f1_m: 0.0419\n",
      "Epoch 480/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4818 - accuracy: 0.7839 - f1_m: 0.1101 - val_loss: 0.5310 - val_accuracy: 0.7745 - val_f1_m: 0.0506\n",
      "Epoch 481/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7852 - f1_m: 0.1124 - val_loss: 0.5324 - val_accuracy: 0.7739 - val_f1_m: 0.0546\n",
      "Epoch 482/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4815 - accuracy: 0.7857 - f1_m: 0.1142 - val_loss: 0.5333 - val_accuracy: 0.7726 - val_f1_m: 0.0513\n",
      "Epoch 483/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4813 - accuracy: 0.7847 - f1_m: 0.1115 - val_loss: 0.5351 - val_accuracy: 0.7698 - val_f1_m: 0.0598\n",
      "Epoch 484/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4812 - accuracy: 0.7854 - f1_m: 0.1129 - val_loss: 0.5323 - val_accuracy: 0.7728 - val_f1_m: 0.0507\n",
      "Epoch 485/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4812 - accuracy: 0.7851 - f1_m: 0.1130 - val_loss: 0.5329 - val_accuracy: 0.7759 - val_f1_m: 0.0408\n",
      "Epoch 486/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4818 - accuracy: 0.7838 - f1_m: 0.1045 - val_loss: 0.5325 - val_accuracy: 0.7712 - val_f1_m: 0.0597\n",
      "Epoch 487/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7852 - f1_m: 0.1181 - val_loss: 0.5313 - val_accuracy: 0.7705 - val_f1_m: 0.0581\n",
      "Epoch 488/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7858 - f1_m: 0.1130 - val_loss: 0.5331 - val_accuracy: 0.7743 - val_f1_m: 0.0444\n",
      "Epoch 489/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4810 - accuracy: 0.7849 - f1_m: 0.1129 - val_loss: 0.5372 - val_accuracy: 0.7700 - val_f1_m: 0.0494\n",
      "Epoch 490/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7852 - f1_m: 0.1127 - val_loss: 0.5334 - val_accuracy: 0.7700 - val_f1_m: 0.0556\n",
      "Epoch 491/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7852 - f1_m: 0.1182 - val_loss: 0.5339 - val_accuracy: 0.7719 - val_f1_m: 0.0568\n",
      "Epoch 492/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4812 - accuracy: 0.7852 - f1_m: 0.1146 - val_loss: 0.5351 - val_accuracy: 0.7727 - val_f1_m: 0.0489\n",
      "Epoch 493/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7849 - f1_m: 0.1168 - val_loss: 0.5342 - val_accuracy: 0.7686 - val_f1_m: 0.0579\n",
      "Epoch 494/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4815 - accuracy: 0.7848 - f1_m: 0.1146 - val_loss: 0.5324 - val_accuracy: 0.7728 - val_f1_m: 0.0496\n",
      "Epoch 495/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4810 - accuracy: 0.7851 - f1_m: 0.1139 - val_loss: 0.5332 - val_accuracy: 0.7734 - val_f1_m: 0.0449\n",
      "Epoch 496/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4810 - accuracy: 0.7856 - f1_m: 0.1180 - val_loss: 0.5355 - val_accuracy: 0.7712 - val_f1_m: 0.0559\n",
      "Epoch 497/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4813 - accuracy: 0.7852 - f1_m: 0.1153 - val_loss: 0.5343 - val_accuracy: 0.7701 - val_f1_m: 0.0544\n",
      "Epoch 498/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4811 - accuracy: 0.7843 - f1_m: 0.1147 - val_loss: 0.5341 - val_accuracy: 0.7746 - val_f1_m: 0.0421\n",
      "Epoch 499/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4811 - accuracy: 0.7850 - f1_m: 0.1126 - val_loss: 0.5332 - val_accuracy: 0.7725 - val_f1_m: 0.0488\n",
      "Epoch 500/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7845 - f1_m: 0.1112 - val_loss: 0.5329 - val_accuracy: 0.7734 - val_f1_m: 0.0521\n",
      "Epoch 501/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7854 - f1_m: 0.1216 - val_loss: 0.5324 - val_accuracy: 0.7739 - val_f1_m: 0.0445\n",
      "Epoch 502/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4813 - accuracy: 0.7846 - f1_m: 0.1134 - val_loss: 0.5342 - val_accuracy: 0.7736 - val_f1_m: 0.0478\n",
      "Epoch 503/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7849 - f1_m: 0.1130 - val_loss: 0.5317 - val_accuracy: 0.7739 - val_f1_m: 0.0482\n",
      "Epoch 504/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4815 - accuracy: 0.7847 - f1_m: 0.1136 - val_loss: 0.5334 - val_accuracy: 0.7738 - val_f1_m: 0.0539\n",
      "Epoch 505/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4812 - accuracy: 0.7850 - f1_m: 0.1154 - val_loss: 0.5348 - val_accuracy: 0.7701 - val_f1_m: 0.0571\n",
      "Epoch 506/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7850 - f1_m: 0.1160 - val_loss: 0.5362 - val_accuracy: 0.7713 - val_f1_m: 0.0491\n",
      "Epoch 507/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7849 - f1_m: 0.1157 - val_loss: 0.5331 - val_accuracy: 0.7719 - val_f1_m: 0.0556\n",
      "Epoch 508/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4812 - accuracy: 0.7854 - f1_m: 0.1155 - val_loss: 0.5333 - val_accuracy: 0.7726 - val_f1_m: 0.0528\n",
      "Epoch 509/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7855 - f1_m: 0.1144 - val_loss: 0.5336 - val_accuracy: 0.7709 - val_f1_m: 0.0586\n",
      "Epoch 510/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7853 - f1_m: 0.1147 - val_loss: 0.5351 - val_accuracy: 0.7712 - val_f1_m: 0.0612\n",
      "Epoch 511/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7852 - f1_m: 0.1191 - val_loss: 0.5350 - val_accuracy: 0.7711 - val_f1_m: 0.0547\n",
      "Epoch 512/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7858 - f1_m: 0.1160 - val_loss: 0.5328 - val_accuracy: 0.7708 - val_f1_m: 0.0540\n",
      "Epoch 513/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4811 - accuracy: 0.7849 - f1_m: 0.1124 - val_loss: 0.5328 - val_accuracy: 0.7715 - val_f1_m: 0.0539\n",
      "Epoch 514/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7849 - f1_m: 0.1170 - val_loss: 0.5347 - val_accuracy: 0.7720 - val_f1_m: 0.0551\n",
      "Epoch 515/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7859 - f1_m: 0.1238 - val_loss: 0.5339 - val_accuracy: 0.7720 - val_f1_m: 0.0524\n",
      "Epoch 516/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7854 - f1_m: 0.1136 - val_loss: 0.5349 - val_accuracy: 0.7704 - val_f1_m: 0.0565\n",
      "Epoch 517/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7847 - f1_m: 0.1128 - val_loss: 0.5330 - val_accuracy: 0.7712 - val_f1_m: 0.0594\n",
      "Epoch 518/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4815 - accuracy: 0.7857 - f1_m: 0.1202 - val_loss: 0.5344 - val_accuracy: 0.7710 - val_f1_m: 0.0573\n",
      "Epoch 519/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4808 - accuracy: 0.7856 - f1_m: 0.1166 - val_loss: 0.5338 - val_accuracy: 0.7728 - val_f1_m: 0.0505\n",
      "Epoch 520/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7852 - f1_m: 0.1145 - val_loss: 0.5336 - val_accuracy: 0.7734 - val_f1_m: 0.0526\n",
      "Epoch 521/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4810 - accuracy: 0.7843 - f1_m: 0.1139 - val_loss: 0.5356 - val_accuracy: 0.7735 - val_f1_m: 0.0454\n",
      "Epoch 522/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4812 - accuracy: 0.7852 - f1_m: 0.1153 - val_loss: 0.5359 - val_accuracy: 0.7710 - val_f1_m: 0.0528\n",
      "Epoch 523/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4812 - accuracy: 0.7849 - f1_m: 0.1126 - val_loss: 0.5335 - val_accuracy: 0.7720 - val_f1_m: 0.0504\n",
      "Epoch 524/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7852 - f1_m: 0.1102 - val_loss: 0.5335 - val_accuracy: 0.7706 - val_f1_m: 0.0580\n",
      "Epoch 525/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7851 - f1_m: 0.1117 - val_loss: 0.5342 - val_accuracy: 0.7725 - val_f1_m: 0.0508\n",
      "Epoch 526/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7848 - f1_m: 0.1156 - val_loss: 0.5350 - val_accuracy: 0.7716 - val_f1_m: 0.0543\n",
      "Epoch 527/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4811 - accuracy: 0.7849 - f1_m: 0.1141 - val_loss: 0.5366 - val_accuracy: 0.7692 - val_f1_m: 0.0585\n",
      "Epoch 528/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7851 - f1_m: 0.1167 - val_loss: 0.5342 - val_accuracy: 0.7712 - val_f1_m: 0.0506\n",
      "Epoch 529/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7855 - f1_m: 0.1145 - val_loss: 0.5320 - val_accuracy: 0.7708 - val_f1_m: 0.0633\n",
      "Epoch 530/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4815 - accuracy: 0.7852 - f1_m: 0.1209 - val_loss: 0.5342 - val_accuracy: 0.7705 - val_f1_m: 0.0572\n",
      "Epoch 531/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7853 - f1_m: 0.1141 - val_loss: 0.5340 - val_accuracy: 0.7722 - val_f1_m: 0.0482\n",
      "Epoch 532/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4811 - accuracy: 0.7853 - f1_m: 0.1142 - val_loss: 0.5362 - val_accuracy: 0.7674 - val_f1_m: 0.0649\n",
      "Epoch 533/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4812 - accuracy: 0.7850 - f1_m: 0.1227 - val_loss: 0.5348 - val_accuracy: 0.7715 - val_f1_m: 0.0546\n",
      "Epoch 534/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7852 - f1_m: 0.1133 - val_loss: 0.5349 - val_accuracy: 0.7717 - val_f1_m: 0.0521\n",
      "Epoch 535/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4805 - accuracy: 0.7851 - f1_m: 0.1134 - val_loss: 0.5340 - val_accuracy: 0.7710 - val_f1_m: 0.0558\n",
      "Epoch 536/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7860 - f1_m: 0.1210 - val_loss: 0.5330 - val_accuracy: 0.7740 - val_f1_m: 0.0472\n",
      "Epoch 537/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7854 - f1_m: 0.1137 - val_loss: 0.5351 - val_accuracy: 0.7696 - val_f1_m: 0.0616\n",
      "Epoch 538/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4810 - accuracy: 0.7854 - f1_m: 0.1199 - val_loss: 0.5342 - val_accuracy: 0.7759 - val_f1_m: 0.0441\n",
      "Epoch 539/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7850 - f1_m: 0.1089 - val_loss: 0.5342 - val_accuracy: 0.7716 - val_f1_m: 0.0506\n",
      "Epoch 540/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7847 - f1_m: 0.1168 - val_loss: 0.5342 - val_accuracy: 0.7722 - val_f1_m: 0.0508\n",
      "Epoch 541/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4808 - accuracy: 0.7855 - f1_m: 0.1157 - val_loss: 0.5334 - val_accuracy: 0.7708 - val_f1_m: 0.0589\n",
      "Epoch 542/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7849 - f1_m: 0.1152 - val_loss: 0.5338 - val_accuracy: 0.7711 - val_f1_m: 0.0552\n",
      "Epoch 543/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7857 - f1_m: 0.1144 - val_loss: 0.5345 - val_accuracy: 0.7738 - val_f1_m: 0.0449\n",
      "Epoch 544/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7849 - f1_m: 0.1150 - val_loss: 0.5347 - val_accuracy: 0.7710 - val_f1_m: 0.0552\n",
      "Epoch 545/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7845 - f1_m: 0.1133 - val_loss: 0.5340 - val_accuracy: 0.7702 - val_f1_m: 0.0590\n",
      "Epoch 546/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7851 - f1_m: 0.1151 - val_loss: 0.5331 - val_accuracy: 0.7719 - val_f1_m: 0.0504\n",
      "Epoch 547/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7856 - f1_m: 0.1209 - val_loss: 0.5360 - val_accuracy: 0.7719 - val_f1_m: 0.0553\n",
      "Epoch 548/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7847 - f1_m: 0.1131 - val_loss: 0.5350 - val_accuracy: 0.7707 - val_f1_m: 0.0599\n",
      "Epoch 549/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7856 - f1_m: 0.1190 - val_loss: 0.5347 - val_accuracy: 0.7720 - val_f1_m: 0.0513\n",
      "Epoch 550/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7860 - f1_m: 0.1193 - val_loss: 0.5343 - val_accuracy: 0.7716 - val_f1_m: 0.0528\n",
      "Epoch 551/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7857 - f1_m: 0.1222 - val_loss: 0.5345 - val_accuracy: 0.7743 - val_f1_m: 0.0453\n",
      "Epoch 552/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7857 - f1_m: 0.1155 - val_loss: 0.5338 - val_accuracy: 0.7714 - val_f1_m: 0.0526\n",
      "Epoch 553/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7853 - f1_m: 0.1125 - val_loss: 0.5340 - val_accuracy: 0.7710 - val_f1_m: 0.0576\n",
      "Epoch 554/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4804 - accuracy: 0.7867 - f1_m: 0.1258 - val_loss: 0.5343 - val_accuracy: 0.7728 - val_f1_m: 0.0502\n",
      "Epoch 555/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.7852 - f1_m: 0.1152 - val_loss: 0.5330 - val_accuracy: 0.7742 - val_f1_m: 0.0514\n",
      "Epoch 556/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7851 - f1_m: 0.1125 - val_loss: 0.5340 - val_accuracy: 0.7725 - val_f1_m: 0.0500\n",
      "Epoch 557/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7853 - f1_m: 0.1132 - val_loss: 0.5341 - val_accuracy: 0.7706 - val_f1_m: 0.0568\n",
      "Epoch 558/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7855 - f1_m: 0.1161 - val_loss: 0.5337 - val_accuracy: 0.7734 - val_f1_m: 0.0485\n",
      "Epoch 559/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7857 - f1_m: 0.1153 - val_loss: 0.5352 - val_accuracy: 0.7727 - val_f1_m: 0.0489\n",
      "Epoch 560/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7855 - f1_m: 0.1240 - val_loss: 0.5352 - val_accuracy: 0.7720 - val_f1_m: 0.0513\n",
      "Epoch 561/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7850 - f1_m: 0.1150 - val_loss: 0.5349 - val_accuracy: 0.7715 - val_f1_m: 0.0518\n",
      "Epoch 562/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7855 - f1_m: 0.1129 - val_loss: 0.5360 - val_accuracy: 0.7700 - val_f1_m: 0.0537\n",
      "Epoch 563/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7853 - f1_m: 0.1213 - val_loss: 0.5330 - val_accuracy: 0.7739 - val_f1_m: 0.0478\n",
      "Epoch 564/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.7853 - f1_m: 0.1174 - val_loss: 0.5393 - val_accuracy: 0.7718 - val_f1_m: 0.0467\n",
      "Epoch 565/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7852 - f1_m: 0.1179 - val_loss: 0.5351 - val_accuracy: 0.7729 - val_f1_m: 0.0492\n",
      "Epoch 566/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7854 - f1_m: 0.1177 - val_loss: 0.5346 - val_accuracy: 0.7727 - val_f1_m: 0.0513\n",
      "Epoch 567/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7855 - f1_m: 0.1162 - val_loss: 0.5344 - val_accuracy: 0.7730 - val_f1_m: 0.0454\n",
      "Epoch 568/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7849 - f1_m: 0.1137 - val_loss: 0.5329 - val_accuracy: 0.7723 - val_f1_m: 0.0561\n",
      "Epoch 569/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7851 - f1_m: 0.1136 - val_loss: 0.5352 - val_accuracy: 0.7726 - val_f1_m: 0.0538\n",
      "Epoch 570/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7853 - f1_m: 0.1170 - val_loss: 0.5320 - val_accuracy: 0.7733 - val_f1_m: 0.0481\n",
      "Epoch 571/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4808 - accuracy: 0.7854 - f1_m: 0.1165 - val_loss: 0.5344 - val_accuracy: 0.7727 - val_f1_m: 0.0530\n",
      "Epoch 572/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7854 - f1_m: 0.1165 - val_loss: 0.5346 - val_accuracy: 0.7734 - val_f1_m: 0.0523\n",
      "Epoch 573/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4806 - accuracy: 0.7857 - f1_m: 0.1180 - val_loss: 0.5343 - val_accuracy: 0.7723 - val_f1_m: 0.0518\n",
      "Epoch 574/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7855 - f1_m: 0.1209 - val_loss: 0.5350 - val_accuracy: 0.7717 - val_f1_m: 0.0547\n",
      "Epoch 575/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7848 - f1_m: 0.1189 - val_loss: 0.5345 - val_accuracy: 0.7720 - val_f1_m: 0.0497\n",
      "Epoch 576/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.7857 - f1_m: 0.1161 - val_loss: 0.5342 - val_accuracy: 0.7737 - val_f1_m: 0.0501\n",
      "Epoch 577/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4810 - accuracy: 0.7847 - f1_m: 0.1149 - val_loss: 0.5343 - val_accuracy: 0.7726 - val_f1_m: 0.0454\n",
      "Epoch 578/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4801 - accuracy: 0.7860 - f1_m: 0.1211 - val_loss: 0.5328 - val_accuracy: 0.7722 - val_f1_m: 0.0486\n",
      "Epoch 579/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7851 - f1_m: 0.1167 - val_loss: 0.5353 - val_accuracy: 0.7722 - val_f1_m: 0.0483\n",
      "Epoch 580/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.7849 - f1_m: 0.1200 - val_loss: 0.5337 - val_accuracy: 0.7714 - val_f1_m: 0.0500\n",
      "Epoch 581/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7849 - f1_m: 0.1154 - val_loss: 0.5348 - val_accuracy: 0.7706 - val_f1_m: 0.0533\n",
      "Epoch 582/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4804 - accuracy: 0.7847 - f1_m: 0.1153 - val_loss: 0.5376 - val_accuracy: 0.7681 - val_f1_m: 0.0626\n",
      "Epoch 583/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.7858 - f1_m: 0.1223 - val_loss: 0.5357 - val_accuracy: 0.7724 - val_f1_m: 0.0485\n",
      "Epoch 584/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4801 - accuracy: 0.7859 - f1_m: 0.1186 - val_loss: 0.5378 - val_accuracy: 0.7748 - val_f1_m: 0.0344\n",
      "Epoch 585/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7852 - f1_m: 0.1189 - val_loss: 0.5344 - val_accuracy: 0.7722 - val_f1_m: 0.0509\n",
      "Epoch 586/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7853 - f1_m: 0.1150 - val_loss: 0.5342 - val_accuracy: 0.7710 - val_f1_m: 0.0563\n",
      "Epoch 587/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7854 - f1_m: 0.1171 - val_loss: 0.5345 - val_accuracy: 0.7732 - val_f1_m: 0.0506\n",
      "Epoch 588/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.7846 - f1_m: 0.1204 - val_loss: 0.5325 - val_accuracy: 0.7737 - val_f1_m: 0.0516\n",
      "Epoch 589/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4803 - accuracy: 0.7855 - f1_m: 0.1160 - val_loss: 0.5340 - val_accuracy: 0.7736 - val_f1_m: 0.0486\n",
      "Epoch 590/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7855 - f1_m: 0.1156 - val_loss: 0.5359 - val_accuracy: 0.7722 - val_f1_m: 0.0487\n",
      "Epoch 591/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7857 - f1_m: 0.1165 - val_loss: 0.5341 - val_accuracy: 0.7715 - val_f1_m: 0.0520\n",
      "Epoch 592/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.7852 - f1_m: 0.1237 - val_loss: 0.5348 - val_accuracy: 0.7715 - val_f1_m: 0.0563\n",
      "Epoch 593/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.7853 - f1_m: 0.1172 - val_loss: 0.5351 - val_accuracy: 0.7703 - val_f1_m: 0.0583\n",
      "Epoch 594/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4801 - accuracy: 0.7858 - f1_m: 0.1265 - val_loss: 0.5348 - val_accuracy: 0.7733 - val_f1_m: 0.0490\n",
      "Epoch 595/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4801 - accuracy: 0.7847 - f1_m: 0.1125 - val_loss: 0.5355 - val_accuracy: 0.7717 - val_f1_m: 0.0517\n",
      "Epoch 596/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.7858 - f1_m: 0.1201 - val_loss: 0.5360 - val_accuracy: 0.7709 - val_f1_m: 0.0551\n",
      "Epoch 597/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4801 - accuracy: 0.7850 - f1_m: 0.1169 - val_loss: 0.5352 - val_accuracy: 0.7693 - val_f1_m: 0.0590\n",
      "Epoch 598/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4805 - accuracy: 0.7855 - f1_m: 0.1205 - val_loss: 0.5333 - val_accuracy: 0.7739 - val_f1_m: 0.0447\n",
      "Epoch 599/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4811 - accuracy: 0.7853 - f1_m: 0.1236 - val_loss: 0.5351 - val_accuracy: 0.7740 - val_f1_m: 0.0444\n",
      "Epoch 600/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4805 - accuracy: 0.7860 - f1_m: 0.1222 - val_loss: 0.5359 - val_accuracy: 0.7718 - val_f1_m: 0.0481\n",
      "Epoch 601/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4803 - accuracy: 0.7860 - f1_m: 0.1180 - val_loss: 0.5353 - val_accuracy: 0.7706 - val_f1_m: 0.0549\n",
      "Epoch 602/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4798 - accuracy: 0.7857 - f1_m: 0.1178 - val_loss: 0.5361 - val_accuracy: 0.7686 - val_f1_m: 0.0637\n",
      "Epoch 603/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4801 - accuracy: 0.7856 - f1_m: 0.1243 - val_loss: 0.5358 - val_accuracy: 0.7701 - val_f1_m: 0.0549\n",
      "Epoch 604/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.7855 - f1_m: 0.1196 - val_loss: 0.5364 - val_accuracy: 0.7714 - val_f1_m: 0.0529\n",
      "Epoch 605/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.7858 - f1_m: 0.1199 - val_loss: 0.5360 - val_accuracy: 0.7697 - val_f1_m: 0.0543\n",
      "Epoch 606/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4803 - accuracy: 0.7860 - f1_m: 0.1244 - val_loss: 0.5359 - val_accuracy: 0.7724 - val_f1_m: 0.0495\n",
      "Epoch 607/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4798 - accuracy: 0.7857 - f1_m: 0.1197 - val_loss: 0.5341 - val_accuracy: 0.7689 - val_f1_m: 0.0597\n",
      "Epoch 608/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4806 - accuracy: 0.7861 - f1_m: 0.1275 - val_loss: 0.5341 - val_accuracy: 0.7726 - val_f1_m: 0.0488\n",
      "Epoch 609/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.7863 - f1_m: 0.1217 - val_loss: 0.5356 - val_accuracy: 0.7733 - val_f1_m: 0.0498\n",
      "Epoch 610/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4806 - accuracy: 0.7854 - f1_m: 0.1232 - val_loss: 0.5337 - val_accuracy: 0.7715 - val_f1_m: 0.0512\n",
      "Epoch 611/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.7854 - f1_m: 0.1209 - val_loss: 0.5342 - val_accuracy: 0.7710 - val_f1_m: 0.0542\n",
      "Epoch 612/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7861 - f1_m: 0.1179 - val_loss: 0.5361 - val_accuracy: 0.7696 - val_f1_m: 0.0603\n",
      "Epoch 613/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4798 - accuracy: 0.7859 - f1_m: 0.1216 - val_loss: 0.5352 - val_accuracy: 0.7718 - val_f1_m: 0.0586\n",
      "Epoch 614/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7855 - f1_m: 0.1196 - val_loss: 0.5347 - val_accuracy: 0.7716 - val_f1_m: 0.0563\n",
      "Epoch 615/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7854 - f1_m: 0.1167 - val_loss: 0.5357 - val_accuracy: 0.7739 - val_f1_m: 0.0460\n",
      "Epoch 616/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.7857 - f1_m: 0.1212 - val_loss: 0.5372 - val_accuracy: 0.7716 - val_f1_m: 0.0564\n",
      "Epoch 617/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.7855 - f1_m: 0.1164 - val_loss: 0.5367 - val_accuracy: 0.7709 - val_f1_m: 0.0545\n",
      "Epoch 618/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.7856 - f1_m: 0.1209 - val_loss: 0.5350 - val_accuracy: 0.7728 - val_f1_m: 0.0514\n",
      "Epoch 619/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7860 - f1_m: 0.1178 - val_loss: 0.5349 - val_accuracy: 0.7709 - val_f1_m: 0.0519\n",
      "Epoch 620/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.7863 - f1_m: 0.1243 - val_loss: 0.5354 - val_accuracy: 0.7707 - val_f1_m: 0.0552\n",
      "Epoch 621/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.7856 - f1_m: 0.1213 - val_loss: 0.5363 - val_accuracy: 0.7683 - val_f1_m: 0.0573\n",
      "Epoch 622/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.7863 - f1_m: 0.1299 - val_loss: 0.5346 - val_accuracy: 0.7724 - val_f1_m: 0.0507\n",
      "Epoch 623/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7852 - f1_m: 0.1184 - val_loss: 0.5354 - val_accuracy: 0.7715 - val_f1_m: 0.0537\n",
      "Epoch 624/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4806 - accuracy: 0.7856 - f1_m: 0.1208 - val_loss: 0.5354 - val_accuracy: 0.7709 - val_f1_m: 0.0557\n",
      "Epoch 625/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.7854 - f1_m: 0.1190 - val_loss: 0.5364 - val_accuracy: 0.7702 - val_f1_m: 0.0558\n",
      "Epoch 626/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7860 - f1_m: 0.1242 - val_loss: 0.5360 - val_accuracy: 0.7712 - val_f1_m: 0.0580\n",
      "Epoch 627/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4801 - accuracy: 0.7860 - f1_m: 0.1217 - val_loss: 0.5345 - val_accuracy: 0.7716 - val_f1_m: 0.0561\n",
      "Epoch 628/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.7860 - f1_m: 0.1199 - val_loss: 0.5357 - val_accuracy: 0.7708 - val_f1_m: 0.0533\n",
      "Epoch 629/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7859 - f1_m: 0.1192 - val_loss: 0.5361 - val_accuracy: 0.7697 - val_f1_m: 0.0616\n",
      "Epoch 630/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4803 - accuracy: 0.7855 - f1_m: 0.1210 - val_loss: 0.5370 - val_accuracy: 0.7691 - val_f1_m: 0.0582\n",
      "Epoch 631/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7860 - f1_m: 0.1224 - val_loss: 0.5347 - val_accuracy: 0.7715 - val_f1_m: 0.0538\n",
      "Epoch 632/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7860 - f1_m: 0.1216 - val_loss: 0.5368 - val_accuracy: 0.7733 - val_f1_m: 0.0494\n",
      "Epoch 633/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7863 - f1_m: 0.1232 - val_loss: 0.5349 - val_accuracy: 0.7726 - val_f1_m: 0.0519\n",
      "Epoch 634/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.7858 - f1_m: 0.1208 - val_loss: 0.5353 - val_accuracy: 0.7730 - val_f1_m: 0.0519\n",
      "Epoch 635/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.7853 - f1_m: 0.1208 - val_loss: 0.5363 - val_accuracy: 0.7690 - val_f1_m: 0.0597\n",
      "Epoch 636/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7858 - f1_m: 0.1252 - val_loss: 0.5349 - val_accuracy: 0.7724 - val_f1_m: 0.0531\n",
      "Epoch 637/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4798 - accuracy: 0.7856 - f1_m: 0.1229 - val_loss: 0.5360 - val_accuracy: 0.7700 - val_f1_m: 0.0553\n",
      "Epoch 638/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7856 - f1_m: 0.1205 - val_loss: 0.5353 - val_accuracy: 0.7705 - val_f1_m: 0.0570\n",
      "Epoch 639/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4798 - accuracy: 0.7855 - f1_m: 0.1224 - val_loss: 0.5345 - val_accuracy: 0.7722 - val_f1_m: 0.0517\n",
      "Epoch 640/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.7853 - f1_m: 0.1219 - val_loss: 0.5345 - val_accuracy: 0.7724 - val_f1_m: 0.0464\n",
      "Epoch 641/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.7853 - f1_m: 0.1153 - val_loss: 0.5368 - val_accuracy: 0.7716 - val_f1_m: 0.0537\n",
      "Epoch 642/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4801 - accuracy: 0.7863 - f1_m: 0.1216 - val_loss: 0.5351 - val_accuracy: 0.7712 - val_f1_m: 0.0537\n",
      "Epoch 643/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7861 - f1_m: 0.1246 - val_loss: 0.5357 - val_accuracy: 0.7716 - val_f1_m: 0.0489\n",
      "Epoch 644/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7857 - f1_m: 0.1176 - val_loss: 0.5358 - val_accuracy: 0.7732 - val_f1_m: 0.0492\n",
      "Epoch 645/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7858 - f1_m: 0.1219 - val_loss: 0.5380 - val_accuracy: 0.7708 - val_f1_m: 0.0608\n",
      "Epoch 646/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.7860 - f1_m: 0.1207 - val_loss: 0.5395 - val_accuracy: 0.7671 - val_f1_m: 0.0607\n",
      "Epoch 647/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7855 - f1_m: 0.1206 - val_loss: 0.5375 - val_accuracy: 0.7697 - val_f1_m: 0.0588\n",
      "Epoch 648/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4805 - accuracy: 0.7855 - f1_m: 0.1233 - val_loss: 0.5371 - val_accuracy: 0.7722 - val_f1_m: 0.0532\n",
      "Epoch 649/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.7855 - f1_m: 0.1199 - val_loss: 0.5354 - val_accuracy: 0.7748 - val_f1_m: 0.0455\n",
      "Epoch 650/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4798 - accuracy: 0.7849 - f1_m: 0.1150 - val_loss: 0.5352 - val_accuracy: 0.7737 - val_f1_m: 0.0452\n",
      "Epoch 651/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7865 - f1_m: 0.1238 - val_loss: 0.5395 - val_accuracy: 0.7680 - val_f1_m: 0.0627\n",
      "Epoch 652/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7860 - f1_m: 0.1219 - val_loss: 0.5374 - val_accuracy: 0.7710 - val_f1_m: 0.0519\n",
      "Epoch 653/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.7857 - f1_m: 0.1233 - val_loss: 0.5372 - val_accuracy: 0.7702 - val_f1_m: 0.0546\n",
      "Epoch 654/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7860 - f1_m: 0.1238 - val_loss: 0.5369 - val_accuracy: 0.7694 - val_f1_m: 0.0575\n",
      "Epoch 655/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7854 - f1_m: 0.1206 - val_loss: 0.5373 - val_accuracy: 0.7694 - val_f1_m: 0.0584\n",
      "Epoch 656/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7851 - f1_m: 0.1215 - val_loss: 0.5363 - val_accuracy: 0.7708 - val_f1_m: 0.0559\n",
      "Epoch 657/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7858 - f1_m: 0.1238 - val_loss: 0.5376 - val_accuracy: 0.7708 - val_f1_m: 0.0565\n",
      "Epoch 658/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4798 - accuracy: 0.7861 - f1_m: 0.1230 - val_loss: 0.5364 - val_accuracy: 0.7730 - val_f1_m: 0.0512\n",
      "Epoch 659/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7855 - f1_m: 0.1150 - val_loss: 0.5375 - val_accuracy: 0.7697 - val_f1_m: 0.0568\n",
      "Epoch 660/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4796 - accuracy: 0.7858 - f1_m: 0.1270 - val_loss: 0.5351 - val_accuracy: 0.7700 - val_f1_m: 0.0545\n",
      "Epoch 661/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7852 - f1_m: 0.1123 - val_loss: 0.5383 - val_accuracy: 0.7712 - val_f1_m: 0.0547\n",
      "Epoch 662/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7856 - f1_m: 0.1215 - val_loss: 0.5353 - val_accuracy: 0.7702 - val_f1_m: 0.0588\n",
      "Epoch 663/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7865 - f1_m: 0.1221 - val_loss: 0.5366 - val_accuracy: 0.7715 - val_f1_m: 0.0529\n",
      "Epoch 664/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4795 - accuracy: 0.7861 - f1_m: 0.1253 - val_loss: 0.5369 - val_accuracy: 0.7714 - val_f1_m: 0.0590\n",
      "Epoch 665/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4795 - accuracy: 0.7862 - f1_m: 0.1298 - val_loss: 0.5355 - val_accuracy: 0.7714 - val_f1_m: 0.0627\n",
      "Epoch 666/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7863 - f1_m: 0.1217 - val_loss: 0.5379 - val_accuracy: 0.7688 - val_f1_m: 0.0585\n",
      "Epoch 667/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4798 - accuracy: 0.7851 - f1_m: 0.1197 - val_loss: 0.5358 - val_accuracy: 0.7733 - val_f1_m: 0.0520\n",
      "Epoch 668/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4798 - accuracy: 0.7858 - f1_m: 0.1197 - val_loss: 0.5358 - val_accuracy: 0.7714 - val_f1_m: 0.0551\n",
      "Epoch 669/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7864 - f1_m: 0.1238 - val_loss: 0.5369 - val_accuracy: 0.7714 - val_f1_m: 0.0549\n",
      "Epoch 670/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7864 - f1_m: 0.1219 - val_loss: 0.5356 - val_accuracy: 0.7742 - val_f1_m: 0.0467\n",
      "Epoch 671/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4798 - accuracy: 0.7860 - f1_m: 0.1203 - val_loss: 0.5363 - val_accuracy: 0.7689 - val_f1_m: 0.0641\n",
      "Epoch 672/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7860 - f1_m: 0.1210 - val_loss: 0.5370 - val_accuracy: 0.7693 - val_f1_m: 0.0566\n",
      "Epoch 673/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4796 - accuracy: 0.7854 - f1_m: 0.1246 - val_loss: 0.5365 - val_accuracy: 0.7710 - val_f1_m: 0.0553\n",
      "Epoch 674/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7863 - f1_m: 0.1231 - val_loss: 0.5372 - val_accuracy: 0.7697 - val_f1_m: 0.0568\n",
      "Epoch 675/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7858 - f1_m: 0.1291 - val_loss: 0.5378 - val_accuracy: 0.7709 - val_f1_m: 0.0535\n",
      "Epoch 676/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7858 - f1_m: 0.1205 - val_loss: 0.5368 - val_accuracy: 0.7740 - val_f1_m: 0.0499\n",
      "Epoch 677/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7861 - f1_m: 0.1192 - val_loss: 0.5373 - val_accuracy: 0.7722 - val_f1_m: 0.0548\n",
      "Epoch 678/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4796 - accuracy: 0.7856 - f1_m: 0.1233 - val_loss: 0.5354 - val_accuracy: 0.7723 - val_f1_m: 0.0585\n",
      "Epoch 679/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.7859 - f1_m: 0.1209 - val_loss: 0.5367 - val_accuracy: 0.7724 - val_f1_m: 0.0517\n",
      "Epoch 680/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4796 - accuracy: 0.7860 - f1_m: 0.1218 - val_loss: 0.5389 - val_accuracy: 0.7673 - val_f1_m: 0.0646\n",
      "Epoch 681/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.7860 - f1_m: 0.1283 - val_loss: 0.5375 - val_accuracy: 0.7700 - val_f1_m: 0.0587\n",
      "Epoch 682/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.7857 - f1_m: 0.1227 - val_loss: 0.5374 - val_accuracy: 0.7732 - val_f1_m: 0.0497\n",
      "Epoch 683/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4795 - accuracy: 0.7859 - f1_m: 0.1209 - val_loss: 0.5366 - val_accuracy: 0.7723 - val_f1_m: 0.0558\n",
      "Epoch 684/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.7861 - f1_m: 0.1263 - val_loss: 0.5358 - val_accuracy: 0.7699 - val_f1_m: 0.0623\n",
      "Epoch 685/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4798 - accuracy: 0.7867 - f1_m: 0.1228 - val_loss: 0.5358 - val_accuracy: 0.7699 - val_f1_m: 0.0611\n",
      "Epoch 686/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7857 - f1_m: 0.1203 - val_loss: 0.5371 - val_accuracy: 0.7727 - val_f1_m: 0.0579\n",
      "Epoch 687/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4796 - accuracy: 0.7854 - f1_m: 0.1195 - val_loss: 0.5382 - val_accuracy: 0.7720 - val_f1_m: 0.0517\n",
      "Epoch 688/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.7868 - f1_m: 0.1228 - val_loss: 0.5364 - val_accuracy: 0.7723 - val_f1_m: 0.0539\n",
      "Epoch 689/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7852 - f1_m: 0.1190 - val_loss: 0.5388 - val_accuracy: 0.7691 - val_f1_m: 0.0549\n",
      "Epoch 690/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4796 - accuracy: 0.7858 - f1_m: 0.1218 - val_loss: 0.5382 - val_accuracy: 0.7727 - val_f1_m: 0.0488\n",
      "Epoch 691/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4798 - accuracy: 0.7862 - f1_m: 0.1212 - val_loss: 0.5375 - val_accuracy: 0.7671 - val_f1_m: 0.0613\n",
      "Epoch 692/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4795 - accuracy: 0.7856 - f1_m: 0.1263 - val_loss: 0.5367 - val_accuracy: 0.7730 - val_f1_m: 0.0542\n",
      "Epoch 693/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.7862 - f1_m: 0.1259 - val_loss: 0.5371 - val_accuracy: 0.7752 - val_f1_m: 0.0451\n",
      "Epoch 694/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.7859 - f1_m: 0.1215 - val_loss: 0.5360 - val_accuracy: 0.7741 - val_f1_m: 0.0473\n",
      "Epoch 695/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4796 - accuracy: 0.7861 - f1_m: 0.1229 - val_loss: 0.5358 - val_accuracy: 0.7742 - val_f1_m: 0.0473\n",
      "Epoch 696/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.7865 - f1_m: 0.1259 - val_loss: 0.5371 - val_accuracy: 0.7704 - val_f1_m: 0.0565\n",
      "Epoch 697/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.7867 - f1_m: 0.1245 - val_loss: 0.5374 - val_accuracy: 0.7718 - val_f1_m: 0.0552\n",
      "Epoch 698/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.7857 - f1_m: 0.1240 - val_loss: 0.5390 - val_accuracy: 0.7730 - val_f1_m: 0.0527\n",
      "Epoch 699/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7864 - f1_m: 0.1225 - val_loss: 0.5380 - val_accuracy: 0.7699 - val_f1_m: 0.0575\n",
      "Epoch 700/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7856 - f1_m: 0.1269 - val_loss: 0.5375 - val_accuracy: 0.7719 - val_f1_m: 0.0532\n",
      "Epoch 701/1000\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.4765 - accuracy: 0.7889 - f1_m: 0.127 - 0s 1ms/step - loss: 0.4793 - accuracy: 0.7869 - f1_m: 0.1255 - val_loss: 0.5373 - val_accuracy: 0.7700 - val_f1_m: 0.0597\n",
      "Epoch 702/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4792 - accuracy: 0.7866 - f1_m: 0.1286 - val_loss: 0.5362 - val_accuracy: 0.7727 - val_f1_m: 0.0533\n",
      "Epoch 703/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.7865 - f1_m: 0.1224 - val_loss: 0.5365 - val_accuracy: 0.7733 - val_f1_m: 0.0542\n",
      "Epoch 704/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4792 - accuracy: 0.7868 - f1_m: 0.1250 - val_loss: 0.5365 - val_accuracy: 0.7742 - val_f1_m: 0.0505\n",
      "Epoch 705/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.7861 - f1_m: 0.1242 - val_loss: 0.5375 - val_accuracy: 0.7705 - val_f1_m: 0.0596\n",
      "Epoch 706/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7864 - f1_m: 0.1256 - val_loss: 0.5370 - val_accuracy: 0.7714 - val_f1_m: 0.0554\n",
      "Epoch 707/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7857 - f1_m: 0.1232 - val_loss: 0.5369 - val_accuracy: 0.7721 - val_f1_m: 0.0539\n",
      "Epoch 708/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7862 - f1_m: 0.1241 - val_loss: 0.5364 - val_accuracy: 0.7715 - val_f1_m: 0.0566\n",
      "Epoch 709/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.7860 - f1_m: 0.1241 - val_loss: 0.5385 - val_accuracy: 0.7693 - val_f1_m: 0.0619\n",
      "Epoch 710/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7867 - f1_m: 0.1290 - val_loss: 0.5379 - val_accuracy: 0.7730 - val_f1_m: 0.0522\n",
      "Epoch 711/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4791 - accuracy: 0.7867 - f1_m: 0.1230 - val_loss: 0.5375 - val_accuracy: 0.7724 - val_f1_m: 0.0526\n",
      "Epoch 712/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7870 - f1_m: 0.1268 - val_loss: 0.5394 - val_accuracy: 0.7703 - val_f1_m: 0.0578\n",
      "Epoch 713/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.7861 - f1_m: 0.1212 - val_loss: 0.5390 - val_accuracy: 0.7667 - val_f1_m: 0.0645\n",
      "Epoch 714/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7862 - f1_m: 0.1290 - val_loss: 0.5389 - val_accuracy: 0.7710 - val_f1_m: 0.0553\n",
      "Epoch 715/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.7866 - f1_m: 0.1233 - val_loss: 0.5378 - val_accuracy: 0.7691 - val_f1_m: 0.0629\n",
      "Epoch 716/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7866 - f1_m: 0.1276 - val_loss: 0.5377 - val_accuracy: 0.7689 - val_f1_m: 0.0572\n",
      "Epoch 717/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4790 - accuracy: 0.7863 - f1_m: 0.1347 - val_loss: 0.5370 - val_accuracy: 0.7740 - val_f1_m: 0.0449\n",
      "Epoch 718/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7862 - f1_m: 0.1188 - val_loss: 0.5369 - val_accuracy: 0.7713 - val_f1_m: 0.0547\n",
      "Epoch 719/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7858 - f1_m: 0.1199 - val_loss: 0.5366 - val_accuracy: 0.7722 - val_f1_m: 0.0562\n",
      "Epoch 720/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7858 - f1_m: 0.1277 - val_loss: 0.5382 - val_accuracy: 0.7735 - val_f1_m: 0.0521\n",
      "Epoch 721/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7872 - f1_m: 0.1257 - val_loss: 0.5396 - val_accuracy: 0.7713 - val_f1_m: 0.0547\n",
      "Epoch 722/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7867 - f1_m: 0.1270 - val_loss: 0.5389 - val_accuracy: 0.7730 - val_f1_m: 0.0492\n",
      "Epoch 723/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7865 - f1_m: 0.1251 - val_loss: 0.5401 - val_accuracy: 0.7675 - val_f1_m: 0.0601\n",
      "Epoch 724/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7860 - f1_m: 0.1239 - val_loss: 0.5387 - val_accuracy: 0.7713 - val_f1_m: 0.0555\n",
      "Epoch 725/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7871 - f1_m: 0.1317 - val_loss: 0.5396 - val_accuracy: 0.7686 - val_f1_m: 0.0631\n",
      "Epoch 726/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7864 - f1_m: 0.1270 - val_loss: 0.5362 - val_accuracy: 0.7705 - val_f1_m: 0.0499\n",
      "Epoch 727/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7877 - f1_m: 0.1291 - val_loss: 0.5370 - val_accuracy: 0.7719 - val_f1_m: 0.0549\n",
      "Epoch 728/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7868 - f1_m: 0.1253 - val_loss: 0.5387 - val_accuracy: 0.7723 - val_f1_m: 0.0527\n",
      "Epoch 729/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.7866 - f1_m: 0.1257 - val_loss: 0.5379 - val_accuracy: 0.7709 - val_f1_m: 0.0631\n",
      "Epoch 730/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7869 - f1_m: 0.1255 - val_loss: 0.5369 - val_accuracy: 0.7717 - val_f1_m: 0.0522\n",
      "Epoch 731/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7867 - f1_m: 0.1292 - val_loss: 0.5388 - val_accuracy: 0.7733 - val_f1_m: 0.0494\n",
      "Epoch 732/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7870 - f1_m: 0.1279 - val_loss: 0.5393 - val_accuracy: 0.7714 - val_f1_m: 0.0537\n",
      "Epoch 733/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4791 - accuracy: 0.7867 - f1_m: 0.1244 - val_loss: 0.5400 - val_accuracy: 0.7706 - val_f1_m: 0.0621\n",
      "Epoch 734/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7864 - f1_m: 0.1304 - val_loss: 0.5382 - val_accuracy: 0.7722 - val_f1_m: 0.0490\n",
      "Epoch 735/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4790 - accuracy: 0.7864 - f1_m: 0.1238 - val_loss: 0.5376 - val_accuracy: 0.7704 - val_f1_m: 0.0545\n",
      "Epoch 736/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4791 - accuracy: 0.7855 - f1_m: 0.1256 - val_loss: 0.5404 - val_accuracy: 0.7699 - val_f1_m: 0.0568\n",
      "Epoch 737/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4790 - accuracy: 0.7871 - f1_m: 0.1326 - val_loss: 0.5379 - val_accuracy: 0.7705 - val_f1_m: 0.0559\n",
      "Epoch 738/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.7856 - f1_m: 0.1217 - val_loss: 0.5391 - val_accuracy: 0.7701 - val_f1_m: 0.0616\n",
      "Epoch 739/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.7862 - f1_m: 0.1278 - val_loss: 0.5399 - val_accuracy: 0.7719 - val_f1_m: 0.0607\n",
      "Epoch 740/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7867 - f1_m: 0.1223 - val_loss: 0.5381 - val_accuracy: 0.7728 - val_f1_m: 0.0522\n",
      "Epoch 741/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4788 - accuracy: 0.7869 - f1_m: 0.1308 - val_loss: 0.5382 - val_accuracy: 0.7714 - val_f1_m: 0.0598\n",
      "Epoch 742/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4792 - accuracy: 0.7863 - f1_m: 0.1284 - val_loss: 0.5383 - val_accuracy: 0.7696 - val_f1_m: 0.0651\n",
      "Epoch 743/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7866 - f1_m: 0.1288 - val_loss: 0.5377 - val_accuracy: 0.7728 - val_f1_m: 0.0512\n",
      "Epoch 744/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4792 - accuracy: 0.7864 - f1_m: 0.1297 - val_loss: 0.5380 - val_accuracy: 0.7713 - val_f1_m: 0.0575\n",
      "Epoch 745/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4789 - accuracy: 0.7871 - f1_m: 0.1266 - val_loss: 0.5397 - val_accuracy: 0.7686 - val_f1_m: 0.0583\n",
      "Epoch 746/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4791 - accuracy: 0.7872 - f1_m: 0.1326 - val_loss: 0.5387 - val_accuracy: 0.7717 - val_f1_m: 0.0502\n",
      "Epoch 747/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4792 - accuracy: 0.7866 - f1_m: 0.1259 - val_loss: 0.5375 - val_accuracy: 0.7701 - val_f1_m: 0.0562\n",
      "Epoch 748/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4788 - accuracy: 0.7871 - f1_m: 0.1272 - val_loss: 0.5380 - val_accuracy: 0.7680 - val_f1_m: 0.0652\n",
      "Epoch 749/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4791 - accuracy: 0.7869 - f1_m: 0.1292 - val_loss: 0.5373 - val_accuracy: 0.7741 - val_f1_m: 0.0515\n",
      "Epoch 750/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7876 - f1_m: 0.1260 - val_loss: 0.5392 - val_accuracy: 0.7728 - val_f1_m: 0.0519\n",
      "Epoch 751/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4791 - accuracy: 0.7868 - f1_m: 0.1284 - val_loss: 0.5373 - val_accuracy: 0.7712 - val_f1_m: 0.0552\n",
      "Epoch 752/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4790 - accuracy: 0.7869 - f1_m: 0.1259 - val_loss: 0.5390 - val_accuracy: 0.7685 - val_f1_m: 0.0582\n",
      "Epoch 753/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4789 - accuracy: 0.7872 - f1_m: 0.1258 - val_loss: 0.5391 - val_accuracy: 0.7678 - val_f1_m: 0.0610\n",
      "Epoch 754/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4789 - accuracy: 0.7873 - f1_m: 0.1324 - val_loss: 0.5376 - val_accuracy: 0.7720 - val_f1_m: 0.0525\n",
      "Epoch 755/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4789 - accuracy: 0.7862 - f1_m: 0.1266 - val_loss: 0.5384 - val_accuracy: 0.7727 - val_f1_m: 0.0526\n",
      "Epoch 756/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4791 - accuracy: 0.7866 - f1_m: 0.1240 - val_loss: 0.5384 - val_accuracy: 0.7700 - val_f1_m: 0.0642\n",
      "Epoch 757/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4790 - accuracy: 0.7874 - f1_m: 0.1367 - val_loss: 0.5395 - val_accuracy: 0.7718 - val_f1_m: 0.0556\n",
      "Epoch 758/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4789 - accuracy: 0.7862 - f1_m: 0.1254 - val_loss: 0.5401 - val_accuracy: 0.7678 - val_f1_m: 0.0583\n",
      "Epoch 759/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7873 - f1_m: 0.1307 - val_loss: 0.5390 - val_accuracy: 0.7734 - val_f1_m: 0.0484\n",
      "Epoch 760/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4788 - accuracy: 0.7868 - f1_m: 0.1244 - val_loss: 0.5395 - val_accuracy: 0.7678 - val_f1_m: 0.0644\n",
      "Epoch 761/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4790 - accuracy: 0.7869 - f1_m: 0.1303 - val_loss: 0.5389 - val_accuracy: 0.7712 - val_f1_m: 0.0572\n",
      "Epoch 762/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4792 - accuracy: 0.7875 - f1_m: 0.1301 - val_loss: 0.5381 - val_accuracy: 0.7706 - val_f1_m: 0.0546\n",
      "Epoch 763/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4790 - accuracy: 0.7870 - f1_m: 0.1267 - val_loss: 0.5397 - val_accuracy: 0.7698 - val_f1_m: 0.0555\n",
      "Epoch 764/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7871 - f1_m: 0.1295 - val_loss: 0.5402 - val_accuracy: 0.7697 - val_f1_m: 0.0570\n",
      "Epoch 765/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4785 - accuracy: 0.7864 - f1_m: 0.1316 - val_loss: 0.5376 - val_accuracy: 0.7743 - val_f1_m: 0.0472\n",
      "Epoch 766/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4789 - accuracy: 0.7862 - f1_m: 0.1230 - val_loss: 0.5373 - val_accuracy: 0.7708 - val_f1_m: 0.0589\n",
      "Epoch 767/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7871 - f1_m: 0.1279 - val_loss: 0.5393 - val_accuracy: 0.7679 - val_f1_m: 0.0657\n",
      "Epoch 768/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4785 - accuracy: 0.7870 - f1_m: 0.1328 - val_loss: 0.5370 - val_accuracy: 0.7728 - val_f1_m: 0.0550\n",
      "Epoch 769/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4791 - accuracy: 0.7863 - f1_m: 0.1239 - val_loss: 0.5381 - val_accuracy: 0.7704 - val_f1_m: 0.0576\n",
      "Epoch 770/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4789 - accuracy: 0.7872 - f1_m: 0.1275 - val_loss: 0.5369 - val_accuracy: 0.7712 - val_f1_m: 0.0576\n",
      "Epoch 771/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7872 - f1_m: 0.1323 - val_loss: 0.5402 - val_accuracy: 0.7663 - val_f1_m: 0.0587\n",
      "Epoch 772/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7865 - f1_m: 0.1295 - val_loss: 0.5388 - val_accuracy: 0.7702 - val_f1_m: 0.0538\n",
      "Epoch 773/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4788 - accuracy: 0.7873 - f1_m: 0.1332 - val_loss: 0.5383 - val_accuracy: 0.7709 - val_f1_m: 0.0619\n",
      "Epoch 774/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7872 - f1_m: 0.1295 - val_loss: 0.5387 - val_accuracy: 0.7700 - val_f1_m: 0.0632\n",
      "Epoch 775/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7871 - f1_m: 0.1330 - val_loss: 0.5384 - val_accuracy: 0.7718 - val_f1_m: 0.0559\n",
      "Epoch 776/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7861 - f1_m: 0.1212 - val_loss: 0.5375 - val_accuracy: 0.7705 - val_f1_m: 0.0634\n",
      "Epoch 777/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4790 - accuracy: 0.7869 - f1_m: 0.1324 - val_loss: 0.5373 - val_accuracy: 0.7704 - val_f1_m: 0.0582\n",
      "Epoch 778/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7874 - f1_m: 0.1372 - val_loss: 0.5384 - val_accuracy: 0.7688 - val_f1_m: 0.0584\n",
      "Epoch 779/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7866 - f1_m: 0.1287 - val_loss: 0.5389 - val_accuracy: 0.7714 - val_f1_m: 0.0529\n",
      "Epoch 780/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4785 - accuracy: 0.7870 - f1_m: 0.1279 - val_loss: 0.5417 - val_accuracy: 0.7686 - val_f1_m: 0.0579\n",
      "Epoch 781/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7873 - f1_m: 0.1311 - val_loss: 0.5388 - val_accuracy: 0.7702 - val_f1_m: 0.0551\n",
      "Epoch 782/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7863 - f1_m: 0.1274 - val_loss: 0.5407 - val_accuracy: 0.7721 - val_f1_m: 0.0552\n",
      "Epoch 783/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7867 - f1_m: 0.1248 - val_loss: 0.5398 - val_accuracy: 0.7698 - val_f1_m: 0.0607\n",
      "Epoch 784/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7871 - f1_m: 0.1351 - val_loss: 0.5390 - val_accuracy: 0.7705 - val_f1_m: 0.0595\n",
      "Epoch 785/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4788 - accuracy: 0.7871 - f1_m: 0.1314 - val_loss: 0.5414 - val_accuracy: 0.7685 - val_f1_m: 0.0612\n",
      "Epoch 786/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4789 - accuracy: 0.7865 - f1_m: 0.1267 - val_loss: 0.5397 - val_accuracy: 0.7720 - val_f1_m: 0.0540\n",
      "Epoch 787/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4788 - accuracy: 0.7867 - f1_m: 0.1304 - val_loss: 0.5403 - val_accuracy: 0.7704 - val_f1_m: 0.0560\n",
      "Epoch 788/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7863 - f1_m: 0.1222 - val_loss: 0.5407 - val_accuracy: 0.7664 - val_f1_m: 0.0669\n",
      "Epoch 789/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7868 - f1_m: 0.1338 - val_loss: 0.5407 - val_accuracy: 0.7701 - val_f1_m: 0.0557\n",
      "Epoch 790/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7867 - f1_m: 0.1279 - val_loss: 0.5394 - val_accuracy: 0.7694 - val_f1_m: 0.0577\n",
      "Epoch 791/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7873 - f1_m: 0.1300 - val_loss: 0.5393 - val_accuracy: 0.7728 - val_f1_m: 0.0532\n",
      "Epoch 792/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7867 - f1_m: 0.1314 - val_loss: 0.5408 - val_accuracy: 0.7675 - val_f1_m: 0.0656\n",
      "Epoch 793/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7873 - f1_m: 0.1306 - val_loss: 0.5414 - val_accuracy: 0.7697 - val_f1_m: 0.0545\n",
      "Epoch 794/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4785 - accuracy: 0.7870 - f1_m: 0.1352 - val_loss: 0.5405 - val_accuracy: 0.7711 - val_f1_m: 0.0569\n",
      "Epoch 795/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4786 - accuracy: 0.7871 - f1_m: 0.1303 - val_loss: 0.5407 - val_accuracy: 0.7678 - val_f1_m: 0.0586\n",
      "Epoch 796/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7871 - f1_m: 0.1341 - val_loss: 0.5403 - val_accuracy: 0.7696 - val_f1_m: 0.0572\n",
      "Epoch 797/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7865 - f1_m: 0.1284 - val_loss: 0.5423 - val_accuracy: 0.7685 - val_f1_m: 0.0559\n",
      "Epoch 798/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7870 - f1_m: 0.1350 - val_loss: 0.5398 - val_accuracy: 0.7686 - val_f1_m: 0.0608\n",
      "Epoch 799/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4788 - accuracy: 0.7868 - f1_m: 0.1305 - val_loss: 0.5411 - val_accuracy: 0.7694 - val_f1_m: 0.0562\n",
      "Epoch 800/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7864 - f1_m: 0.1253 - val_loss: 0.5403 - val_accuracy: 0.7712 - val_f1_m: 0.0563\n",
      "Epoch 801/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4788 - accuracy: 0.7873 - f1_m: 0.1292 - val_loss: 0.5398 - val_accuracy: 0.7698 - val_f1_m: 0.0602\n",
      "Epoch 802/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7872 - f1_m: 0.1390 - val_loss: 0.5421 - val_accuracy: 0.7739 - val_f1_m: 0.0513\n",
      "Epoch 803/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4789 - accuracy: 0.7862 - f1_m: 0.1231 - val_loss: 0.5399 - val_accuracy: 0.7679 - val_f1_m: 0.0606\n",
      "Epoch 804/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7873 - f1_m: 0.1312 - val_loss: 0.5428 - val_accuracy: 0.7684 - val_f1_m: 0.0619\n",
      "Epoch 805/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7863 - f1_m: 0.1265 - val_loss: 0.5389 - val_accuracy: 0.7689 - val_f1_m: 0.0610\n",
      "Epoch 806/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4784 - accuracy: 0.7877 - f1_m: 0.1355 - val_loss: 0.5407 - val_accuracy: 0.7736 - val_f1_m: 0.0474\n",
      "Epoch 807/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7872 - f1_m: 0.1347 - val_loss: 0.5398 - val_accuracy: 0.7741 - val_f1_m: 0.0483\n",
      "Epoch 808/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7861 - f1_m: 0.1219 - val_loss: 0.5408 - val_accuracy: 0.7705 - val_f1_m: 0.0542\n",
      "Epoch 809/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7870 - f1_m: 0.1282 - val_loss: 0.5386 - val_accuracy: 0.7704 - val_f1_m: 0.0561\n",
      "Epoch 810/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7869 - f1_m: 0.1345 - val_loss: 0.5380 - val_accuracy: 0.7694 - val_f1_m: 0.0640\n",
      "Epoch 811/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7871 - f1_m: 0.1363 - val_loss: 0.5396 - val_accuracy: 0.7720 - val_f1_m: 0.0560\n",
      "Epoch 812/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7871 - f1_m: 0.1352 - val_loss: 0.5385 - val_accuracy: 0.7722 - val_f1_m: 0.0529\n",
      "Epoch 813/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7866 - f1_m: 0.1243 - val_loss: 0.5390 - val_accuracy: 0.7711 - val_f1_m: 0.0534\n",
      "Epoch 814/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7866 - f1_m: 0.1337 - val_loss: 0.5402 - val_accuracy: 0.7709 - val_f1_m: 0.0554\n",
      "Epoch 815/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7866 - f1_m: 0.1284 - val_loss: 0.5390 - val_accuracy: 0.7714 - val_f1_m: 0.0513\n",
      "Epoch 816/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7872 - f1_m: 0.1358 - val_loss: 0.5408 - val_accuracy: 0.7678 - val_f1_m: 0.0613\n",
      "Epoch 817/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7873 - f1_m: 0.1308 - val_loss: 0.5413 - val_accuracy: 0.7666 - val_f1_m: 0.0686\n",
      "Epoch 818/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7880 - f1_m: 0.1404 - val_loss: 0.5399 - val_accuracy: 0.7703 - val_f1_m: 0.0559\n",
      "Epoch 819/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7874 - f1_m: 0.1311 - val_loss: 0.5389 - val_accuracy: 0.7688 - val_f1_m: 0.0579\n",
      "Epoch 820/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7878 - f1_m: 0.1347 - val_loss: 0.5395 - val_accuracy: 0.7726 - val_f1_m: 0.0515\n",
      "Epoch 821/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7866 - f1_m: 0.1305 - val_loss: 0.5400 - val_accuracy: 0.7694 - val_f1_m: 0.0620\n",
      "Epoch 822/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4786 - accuracy: 0.7872 - f1_m: 0.1339 - val_loss: 0.5391 - val_accuracy: 0.7712 - val_f1_m: 0.0520\n",
      "Epoch 823/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7867 - f1_m: 0.1277 - val_loss: 0.5391 - val_accuracy: 0.7719 - val_f1_m: 0.0517\n",
      "Epoch 824/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7871 - f1_m: 0.1308 - val_loss: 0.5411 - val_accuracy: 0.7682 - val_f1_m: 0.0551\n",
      "Epoch 825/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7868 - f1_m: 0.1300 - val_loss: 0.5392 - val_accuracy: 0.7685 - val_f1_m: 0.0667\n",
      "Epoch 826/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7871 - f1_m: 0.1329 - val_loss: 0.5400 - val_accuracy: 0.7708 - val_f1_m: 0.0548\n",
      "Epoch 827/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7869 - f1_m: 0.1296 - val_loss: 0.5398 - val_accuracy: 0.7690 - val_f1_m: 0.0583\n",
      "Epoch 828/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7875 - f1_m: 0.1345 - val_loss: 0.5427 - val_accuracy: 0.7710 - val_f1_m: 0.0472\n",
      "Epoch 829/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7871 - f1_m: 0.1276 - val_loss: 0.5414 - val_accuracy: 0.7682 - val_f1_m: 0.0613\n",
      "Epoch 830/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7878 - f1_m: 0.1393 - val_loss: 0.5378 - val_accuracy: 0.7732 - val_f1_m: 0.0477\n",
      "Epoch 831/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7868 - f1_m: 0.1315 - val_loss: 0.5387 - val_accuracy: 0.7723 - val_f1_m: 0.0526\n",
      "Epoch 832/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7875 - f1_m: 0.1253 - val_loss: 0.5404 - val_accuracy: 0.7677 - val_f1_m: 0.0627\n",
      "Epoch 833/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7873 - f1_m: 0.1366 - val_loss: 0.5379 - val_accuracy: 0.7710 - val_f1_m: 0.0571\n",
      "Epoch 834/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7869 - f1_m: 0.1306 - val_loss: 0.5392 - val_accuracy: 0.7696 - val_f1_m: 0.0593\n",
      "Epoch 835/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7864 - f1_m: 0.1248 - val_loss: 0.5400 - val_accuracy: 0.7699 - val_f1_m: 0.0580\n",
      "Epoch 836/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4784 - accuracy: 0.7872 - f1_m: 0.1306 - val_loss: 0.5385 - val_accuracy: 0.7725 - val_f1_m: 0.0511\n",
      "Epoch 837/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7875 - f1_m: 0.1327 - val_loss: 0.5403 - val_accuracy: 0.7715 - val_f1_m: 0.0562\n",
      "Epoch 838/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7871 - f1_m: 0.1362 - val_loss: 0.5408 - val_accuracy: 0.7744 - val_f1_m: 0.0450\n",
      "Epoch 839/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7866 - f1_m: 0.1327 - val_loss: 0.5400 - val_accuracy: 0.7685 - val_f1_m: 0.0668\n",
      "Epoch 840/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7872 - f1_m: 0.1298 - val_loss: 0.5401 - val_accuracy: 0.7652 - val_f1_m: 0.0690\n",
      "Epoch 841/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7875 - f1_m: 0.1425 - val_loss: 0.5379 - val_accuracy: 0.7706 - val_f1_m: 0.0572\n",
      "Epoch 842/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4788 - accuracy: 0.7872 - f1_m: 0.1307 - val_loss: 0.5394 - val_accuracy: 0.7695 - val_f1_m: 0.0536\n",
      "Epoch 843/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7867 - f1_m: 0.1344 - val_loss: 0.5402 - val_accuracy: 0.7716 - val_f1_m: 0.0538\n",
      "Epoch 844/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7868 - f1_m: 0.1307 - val_loss: 0.5401 - val_accuracy: 0.7701 - val_f1_m: 0.0589\n",
      "Epoch 845/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4784 - accuracy: 0.7868 - f1_m: 0.1300 - val_loss: 0.5440 - val_accuracy: 0.7625 - val_f1_m: 0.0783\n",
      "Epoch 846/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7870 - f1_m: 0.1395 - val_loss: 0.5419 - val_accuracy: 0.7649 - val_f1_m: 0.0721\n",
      "Epoch 847/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7866 - f1_m: 0.1353 - val_loss: 0.5407 - val_accuracy: 0.7689 - val_f1_m: 0.0569\n",
      "Epoch 848/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7874 - f1_m: 0.1348 - val_loss: 0.5410 - val_accuracy: 0.7703 - val_f1_m: 0.0587\n",
      "Epoch 849/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7867 - f1_m: 0.1343 - val_loss: 0.5404 - val_accuracy: 0.7720 - val_f1_m: 0.0496\n",
      "Epoch 850/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7877 - f1_m: 0.1311 - val_loss: 0.5414 - val_accuracy: 0.7704 - val_f1_m: 0.0524\n",
      "Epoch 851/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 0.7876 - f1_m: 0.1367 - val_loss: 0.5380 - val_accuracy: 0.7711 - val_f1_m: 0.0518\n",
      "Epoch 852/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4781 - accuracy: 0.7883 - f1_m: 0.1344 - val_loss: 0.5429 - val_accuracy: 0.7685 - val_f1_m: 0.0644\n",
      "Epoch 853/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7869 - f1_m: 0.1296 - val_loss: 0.5440 - val_accuracy: 0.7689 - val_f1_m: 0.0566\n",
      "Epoch 854/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7874 - f1_m: 0.1346 - val_loss: 0.5414 - val_accuracy: 0.7680 - val_f1_m: 0.0637\n",
      "Epoch 855/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4781 - accuracy: 0.7882 - f1_m: 0.1379 - val_loss: 0.5434 - val_accuracy: 0.7685 - val_f1_m: 0.0637\n",
      "Epoch 856/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7875 - f1_m: 0.1373 - val_loss: 0.5396 - val_accuracy: 0.7709 - val_f1_m: 0.0535\n",
      "Epoch 857/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7874 - f1_m: 0.1375 - val_loss: 0.5422 - val_accuracy: 0.7715 - val_f1_m: 0.0515\n",
      "Epoch 858/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4785 - accuracy: 0.7876 - f1_m: 0.1373 - val_loss: 0.5435 - val_accuracy: 0.7671 - val_f1_m: 0.0620\n",
      "Epoch 859/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7868 - f1_m: 0.1303 - val_loss: 0.5403 - val_accuracy: 0.7711 - val_f1_m: 0.0564\n",
      "Epoch 860/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.7873 - f1_m: 0.1305 - val_loss: 0.5411 - val_accuracy: 0.7657 - val_f1_m: 0.0684\n",
      "Epoch 861/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7879 - f1_m: 0.1358 - val_loss: 0.5406 - val_accuracy: 0.7688 - val_f1_m: 0.0582\n",
      "Epoch 862/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 0.7878 - f1_m: 0.1344 - val_loss: 0.5405 - val_accuracy: 0.7698 - val_f1_m: 0.0552\n",
      "Epoch 863/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.7880 - f1_m: 0.1430 - val_loss: 0.5404 - val_accuracy: 0.7719 - val_f1_m: 0.0485\n",
      "Epoch 864/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4787 - accuracy: 0.7869 - f1_m: 0.1280 - val_loss: 0.5431 - val_accuracy: 0.7673 - val_f1_m: 0.0664\n",
      "Epoch 865/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7870 - f1_m: 0.1369 - val_loss: 0.5388 - val_accuracy: 0.7718 - val_f1_m: 0.0524\n",
      "Epoch 866/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4788 - accuracy: 0.7868 - f1_m: 0.1267 - val_loss: 0.5379 - val_accuracy: 0.7692 - val_f1_m: 0.0595\n",
      "Epoch 867/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7878 - f1_m: 0.1355 - val_loss: 0.5411 - val_accuracy: 0.7672 - val_f1_m: 0.0619\n",
      "Epoch 868/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7886 - f1_m: 0.1419 - val_loss: 0.5402 - val_accuracy: 0.7681 - val_f1_m: 0.0589\n",
      "Epoch 869/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7876 - f1_m: 0.1346 - val_loss: 0.5416 - val_accuracy: 0.7681 - val_f1_m: 0.0595\n",
      "Epoch 870/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7879 - f1_m: 0.1388 - val_loss: 0.5426 - val_accuracy: 0.7698 - val_f1_m: 0.0556\n",
      "Epoch 871/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4785 - accuracy: 0.7878 - f1_m: 0.1339 - val_loss: 0.5405 - val_accuracy: 0.7685 - val_f1_m: 0.0598\n",
      "Epoch 872/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7879 - f1_m: 0.1319 - val_loss: 0.5424 - val_accuracy: 0.7647 - val_f1_m: 0.0758\n",
      "Epoch 873/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7865 - f1_m: 0.1291 - val_loss: 0.5436 - val_accuracy: 0.7662 - val_f1_m: 0.0618\n",
      "Epoch 874/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7866 - f1_m: 0.1360 - val_loss: 0.5393 - val_accuracy: 0.7730 - val_f1_m: 0.0497\n",
      "Epoch 875/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7881 - f1_m: 0.1351 - val_loss: 0.5411 - val_accuracy: 0.7709 - val_f1_m: 0.0489\n",
      "Epoch 876/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7873 - f1_m: 0.1288 - val_loss: 0.5414 - val_accuracy: 0.7681 - val_f1_m: 0.0611\n",
      "Epoch 877/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7880 - f1_m: 0.1362 - val_loss: 0.5412 - val_accuracy: 0.7672 - val_f1_m: 0.0611\n",
      "Epoch 878/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7883 - f1_m: 0.1413 - val_loss: 0.5400 - val_accuracy: 0.7730 - val_f1_m: 0.0477\n",
      "Epoch 879/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7871 - f1_m: 0.1288 - val_loss: 0.5429 - val_accuracy: 0.7671 - val_f1_m: 0.0629\n",
      "Epoch 880/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7877 - f1_m: 0.1385 - val_loss: 0.5408 - val_accuracy: 0.7679 - val_f1_m: 0.0590\n",
      "Epoch 881/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7876 - f1_m: 0.1317 - val_loss: 0.5411 - val_accuracy: 0.7724 - val_f1_m: 0.0509\n",
      "Epoch 882/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7877 - f1_m: 0.1416 - val_loss: 0.5422 - val_accuracy: 0.7755 - val_f1_m: 0.0381\n",
      "Epoch 883/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4784 - accuracy: 0.7871 - f1_m: 0.1296 - val_loss: 0.5398 - val_accuracy: 0.7735 - val_f1_m: 0.0457\n",
      "Epoch 884/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7866 - f1_m: 0.1250 - val_loss: 0.5389 - val_accuracy: 0.7671 - val_f1_m: 0.0604\n",
      "Epoch 885/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4778 - accuracy: 0.7880 - f1_m: 0.1409 - val_loss: 0.5405 - val_accuracy: 0.7739 - val_f1_m: 0.0486\n",
      "Epoch 886/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7876 - f1_m: 0.1335 - val_loss: 0.5404 - val_accuracy: 0.7700 - val_f1_m: 0.0544\n",
      "Epoch 887/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 0.7881 - f1_m: 0.1346 - val_loss: 0.5411 - val_accuracy: 0.7661 - val_f1_m: 0.0661\n",
      "Epoch 888/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7881 - f1_m: 0.1389 - val_loss: 0.5396 - val_accuracy: 0.7701 - val_f1_m: 0.0524\n",
      "Epoch 889/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7883 - f1_m: 0.1342 - val_loss: 0.5406 - val_accuracy: 0.7716 - val_f1_m: 0.0508\n",
      "Epoch 890/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7879 - f1_m: 0.1362 - val_loss: 0.5396 - val_accuracy: 0.7740 - val_f1_m: 0.0498\n",
      "Epoch 891/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7867 - f1_m: 0.1228 - val_loss: 0.5410 - val_accuracy: 0.7650 - val_f1_m: 0.0761\n",
      "Epoch 892/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7875 - f1_m: 0.1395 - val_loss: 0.5413 - val_accuracy: 0.7712 - val_f1_m: 0.0539\n",
      "Epoch 893/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7880 - f1_m: 0.1372 - val_loss: 0.5402 - val_accuracy: 0.7680 - val_f1_m: 0.0562\n",
      "Epoch 894/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.7872 - f1_m: 0.1298 - val_loss: 0.5416 - val_accuracy: 0.7644 - val_f1_m: 0.0804\n",
      "Epoch 895/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7874 - f1_m: 0.1320 - val_loss: 0.5405 - val_accuracy: 0.7701 - val_f1_m: 0.0637\n",
      "Epoch 896/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.7871 - f1_m: 0.1310 - val_loss: 0.5411 - val_accuracy: 0.7707 - val_f1_m: 0.0532\n",
      "Epoch 897/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7873 - f1_m: 0.1283 - val_loss: 0.5414 - val_accuracy: 0.7683 - val_f1_m: 0.0644\n",
      "Epoch 898/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7882 - f1_m: 0.1370 - val_loss: 0.5392 - val_accuracy: 0.7694 - val_f1_m: 0.0646\n",
      "Epoch 899/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7882 - f1_m: 0.1359 - val_loss: 0.5417 - val_accuracy: 0.7678 - val_f1_m: 0.0694\n",
      "Epoch 900/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7876 - f1_m: 0.1334 - val_loss: 0.5419 - val_accuracy: 0.7694 - val_f1_m: 0.0561\n",
      "Epoch 901/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7880 - f1_m: 0.1376 - val_loss: 0.5407 - val_accuracy: 0.7686 - val_f1_m: 0.0589\n",
      "Epoch 902/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7871 - f1_m: 0.1331 - val_loss: 0.5398 - val_accuracy: 0.7707 - val_f1_m: 0.0499\n",
      "Epoch 903/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7873 - f1_m: 0.1340 - val_loss: 0.5412 - val_accuracy: 0.7696 - val_f1_m: 0.0603\n",
      "Epoch 904/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 0.7875 - f1_m: 0.1304 - val_loss: 0.5405 - val_accuracy: 0.7691 - val_f1_m: 0.0574\n",
      "Epoch 905/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7877 - f1_m: 0.1324 - val_loss: 0.5419 - val_accuracy: 0.7695 - val_f1_m: 0.0539\n",
      "Epoch 906/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7876 - f1_m: 0.1345 - val_loss: 0.5411 - val_accuracy: 0.7706 - val_f1_m: 0.0572\n",
      "Epoch 907/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4779 - accuracy: 0.7883 - f1_m: 0.1378 - val_loss: 0.5403 - val_accuracy: 0.7670 - val_f1_m: 0.0699\n",
      "Epoch 908/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7881 - f1_m: 0.1403 - val_loss: 0.5426 - val_accuracy: 0.7677 - val_f1_m: 0.0651\n",
      "Epoch 909/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4786 - accuracy: 0.7868 - f1_m: 0.1321 - val_loss: 0.5404 - val_accuracy: 0.7698 - val_f1_m: 0.0562\n",
      "Epoch 910/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4779 - accuracy: 0.7878 - f1_m: 0.1340 - val_loss: 0.5425 - val_accuracy: 0.7689 - val_f1_m: 0.0582\n",
      "Epoch 911/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7878 - f1_m: 0.1359 - val_loss: 0.5416 - val_accuracy: 0.7682 - val_f1_m: 0.0587\n",
      "Epoch 912/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7883 - f1_m: 0.1432 - val_loss: 0.5390 - val_accuracy: 0.7709 - val_f1_m: 0.0534\n",
      "Epoch 913/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7879 - f1_m: 0.1395 - val_loss: 0.5404 - val_accuracy: 0.7720 - val_f1_m: 0.0519\n",
      "Epoch 914/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7876 - f1_m: 0.1340 - val_loss: 0.5417 - val_accuracy: 0.7710 - val_f1_m: 0.0492\n",
      "Epoch 915/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7869 - f1_m: 0.1324 - val_loss: 0.5400 - val_accuracy: 0.7724 - val_f1_m: 0.0522\n",
      "Epoch 916/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7875 - f1_m: 0.1255 - val_loss: 0.5414 - val_accuracy: 0.7685 - val_f1_m: 0.0522\n",
      "Epoch 917/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7878 - f1_m: 0.1433 - val_loss: 0.5405 - val_accuracy: 0.7712 - val_f1_m: 0.0509\n",
      "Epoch 918/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.7876 - f1_m: 0.1429 - val_loss: 0.5405 - val_accuracy: 0.7711 - val_f1_m: 0.0535\n",
      "Epoch 919/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7877 - f1_m: 0.1322 - val_loss: 0.5404 - val_accuracy: 0.7698 - val_f1_m: 0.0636\n",
      "Epoch 920/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4784 - accuracy: 0.7876 - f1_m: 0.1364 - val_loss: 0.5413 - val_accuracy: 0.7700 - val_f1_m: 0.0584\n",
      "Epoch 921/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7876 - f1_m: 0.1376 - val_loss: 0.5402 - val_accuracy: 0.7705 - val_f1_m: 0.0548\n",
      "Epoch 922/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7882 - f1_m: 0.1405 - val_loss: 0.5404 - val_accuracy: 0.7702 - val_f1_m: 0.0541\n",
      "Epoch 923/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 0.7876 - f1_m: 0.1376 - val_loss: 0.5411 - val_accuracy: 0.7675 - val_f1_m: 0.0609\n",
      "Epoch 924/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7873 - f1_m: 0.1391 - val_loss: 0.5402 - val_accuracy: 0.7718 - val_f1_m: 0.0510\n",
      "Epoch 925/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7880 - f1_m: 0.1357 - val_loss: 0.5425 - val_accuracy: 0.7675 - val_f1_m: 0.0598\n",
      "Epoch 926/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7880 - f1_m: 0.1362 - val_loss: 0.5416 - val_accuracy: 0.7666 - val_f1_m: 0.0693\n",
      "Epoch 927/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7875 - f1_m: 0.1342 - val_loss: 0.5420 - val_accuracy: 0.7690 - val_f1_m: 0.0617\n",
      "Epoch 928/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7884 - f1_m: 0.1422 - val_loss: 0.5388 - val_accuracy: 0.7730 - val_f1_m: 0.0551\n",
      "Epoch 929/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7870 - f1_m: 0.1312 - val_loss: 0.5393 - val_accuracy: 0.7700 - val_f1_m: 0.0575\n",
      "Epoch 930/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7881 - f1_m: 0.1440 - val_loss: 0.5421 - val_accuracy: 0.7732 - val_f1_m: 0.0462\n",
      "Epoch 931/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7869 - f1_m: 0.1346 - val_loss: 0.5397 - val_accuracy: 0.7669 - val_f1_m: 0.0651\n",
      "Epoch 932/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7881 - f1_m: 0.1395 - val_loss: 0.5399 - val_accuracy: 0.7704 - val_f1_m: 0.0552\n",
      "Epoch 933/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7878 - f1_m: 0.1382 - val_loss: 0.5402 - val_accuracy: 0.7732 - val_f1_m: 0.0537\n",
      "Epoch 934/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7870 - f1_m: 0.1354 - val_loss: 0.5408 - val_accuracy: 0.7724 - val_f1_m: 0.0509\n",
      "Epoch 935/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7866 - f1_m: 0.1309 - val_loss: 0.5414 - val_accuracy: 0.7718 - val_f1_m: 0.0487\n",
      "Epoch 936/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7881 - f1_m: 0.1383 - val_loss: 0.5402 - val_accuracy: 0.7709 - val_f1_m: 0.0621\n",
      "Epoch 937/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7875 - f1_m: 0.1347 - val_loss: 0.5407 - val_accuracy: 0.7710 - val_f1_m: 0.0540\n",
      "Epoch 938/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7872 - f1_m: 0.1390 - val_loss: 0.5439 - val_accuracy: 0.7655 - val_f1_m: 0.0700\n",
      "Epoch 939/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4784 - accuracy: 0.7877 - f1_m: 0.1329 - val_loss: 0.5420 - val_accuracy: 0.7674 - val_f1_m: 0.0705\n",
      "Epoch 940/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7874 - f1_m: 0.1381 - val_loss: 0.5392 - val_accuracy: 0.7721 - val_f1_m: 0.0593\n",
      "Epoch 941/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4778 - accuracy: 0.7875 - f1_m: 0.1363 - val_loss: 0.5401 - val_accuracy: 0.7681 - val_f1_m: 0.0613\n",
      "Epoch 942/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 0.7876 - f1_m: 0.1351 - val_loss: 0.5400 - val_accuracy: 0.7694 - val_f1_m: 0.0544\n",
      "Epoch 943/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7871 - f1_m: 0.1394 - val_loss: 0.5423 - val_accuracy: 0.7686 - val_f1_m: 0.0653\n",
      "Epoch 944/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7883 - f1_m: 0.1365 - val_loss: 0.5423 - val_accuracy: 0.7682 - val_f1_m: 0.0541\n",
      "Epoch 945/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7881 - f1_m: 0.1380 - val_loss: 0.5408 - val_accuracy: 0.7682 - val_f1_m: 0.0651\n",
      "Epoch 946/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7875 - f1_m: 0.1413 - val_loss: 0.5401 - val_accuracy: 0.7717 - val_f1_m: 0.0521\n",
      "Epoch 947/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7877 - f1_m: 0.1373 - val_loss: 0.5420 - val_accuracy: 0.7703 - val_f1_m: 0.0544\n",
      "Epoch 948/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7881 - f1_m: 0.1423 - val_loss: 0.5391 - val_accuracy: 0.7696 - val_f1_m: 0.0552\n",
      "Epoch 949/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7875 - f1_m: 0.1356 - val_loss: 0.5441 - val_accuracy: 0.7651 - val_f1_m: 0.0793\n",
      "Epoch 950/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7879 - f1_m: 0.1376 - val_loss: 0.5415 - val_accuracy: 0.7661 - val_f1_m: 0.0603\n",
      "Epoch 951/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7862 - f1_m: 0.1335 - val_loss: 0.5419 - val_accuracy: 0.7674 - val_f1_m: 0.0789\n",
      "Epoch 952/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4779 - accuracy: 0.7871 - f1_m: 0.1402 - val_loss: 0.5405 - val_accuracy: 0.7665 - val_f1_m: 0.0638\n",
      "Epoch 953/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7880 - f1_m: 0.1411 - val_loss: 0.5419 - val_accuracy: 0.7683 - val_f1_m: 0.0578\n",
      "Epoch 954/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7876 - f1_m: 0.1387 - val_loss: 0.5406 - val_accuracy: 0.7707 - val_f1_m: 0.0598\n",
      "Epoch 955/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7882 - f1_m: 0.1448 - val_loss: 0.5429 - val_accuracy: 0.7706 - val_f1_m: 0.0489\n",
      "Epoch 956/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.7882 - f1_m: 0.1412 - val_loss: 0.5413 - val_accuracy: 0.7689 - val_f1_m: 0.0565\n",
      "Epoch 957/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4778 - accuracy: 0.7873 - f1_m: 0.1271 - val_loss: 0.5416 - val_accuracy: 0.7712 - val_f1_m: 0.0538\n",
      "Epoch 958/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4779 - accuracy: 0.7876 - f1_m: 0.1401 - val_loss: 0.5406 - val_accuracy: 0.7669 - val_f1_m: 0.0641\n",
      "Epoch 959/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7882 - f1_m: 0.1399 - val_loss: 0.5406 - val_accuracy: 0.7709 - val_f1_m: 0.0560\n",
      "Epoch 960/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 0.7877 - f1_m: 0.1335 - val_loss: 0.5421 - val_accuracy: 0.7671 - val_f1_m: 0.0657\n",
      "Epoch 961/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7871 - f1_m: 0.1326 - val_loss: 0.5433 - val_accuracy: 0.7651 - val_f1_m: 0.0728\n",
      "Epoch 962/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7872 - f1_m: 0.1338 - val_loss: 0.5420 - val_accuracy: 0.7675 - val_f1_m: 0.0617\n",
      "Epoch 963/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.7881 - f1_m: 0.1462 - val_loss: 0.5394 - val_accuracy: 0.7726 - val_f1_m: 0.0489\n",
      "Epoch 964/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7875 - f1_m: 0.1337 - val_loss: 0.5428 - val_accuracy: 0.7663 - val_f1_m: 0.0684\n",
      "Epoch 965/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4781 - accuracy: 0.7876 - f1_m: 0.1425 - val_loss: 0.5420 - val_accuracy: 0.7697 - val_f1_m: 0.0542\n",
      "Epoch 966/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7878 - f1_m: 0.1396 - val_loss: 0.5398 - val_accuracy: 0.7708 - val_f1_m: 0.0499\n",
      "Epoch 967/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.7875 - f1_m: 0.1363 - val_loss: 0.5447 - val_accuracy: 0.7644 - val_f1_m: 0.0758\n",
      "Epoch 968/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4779 - accuracy: 0.7866 - f1_m: 0.1378 - val_loss: 0.5432 - val_accuracy: 0.7662 - val_f1_m: 0.0599\n",
      "Epoch 969/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7873 - f1_m: 0.1401 - val_loss: 0.5417 - val_accuracy: 0.7711 - val_f1_m: 0.0549\n",
      "Epoch 970/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7882 - f1_m: 0.1443 - val_loss: 0.5398 - val_accuracy: 0.7693 - val_f1_m: 0.0540\n",
      "Epoch 971/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7870 - f1_m: 0.1371 - val_loss: 0.5403 - val_accuracy: 0.7692 - val_f1_m: 0.0585\n",
      "Epoch 972/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7881 - f1_m: 0.1450 - val_loss: 0.5423 - val_accuracy: 0.7690 - val_f1_m: 0.0578\n",
      "Epoch 973/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7876 - f1_m: 0.1353 - val_loss: 0.5439 - val_accuracy: 0.7656 - val_f1_m: 0.0749\n",
      "Epoch 974/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 0.7874 - f1_m: 0.1365 - val_loss: 0.5418 - val_accuracy: 0.7658 - val_f1_m: 0.0689\n",
      "Epoch 975/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7877 - f1_m: 0.1377 - val_loss: 0.5425 - val_accuracy: 0.7647 - val_f1_m: 0.0712\n",
      "Epoch 976/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7882 - f1_m: 0.1446 - val_loss: 0.5407 - val_accuracy: 0.7665 - val_f1_m: 0.0669\n",
      "Epoch 977/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7878 - f1_m: 0.1414 - val_loss: 0.5423 - val_accuracy: 0.7735 - val_f1_m: 0.0483\n",
      "Epoch 978/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7872 - f1_m: 0.1393 - val_loss: 0.5408 - val_accuracy: 0.7682 - val_f1_m: 0.0661\n",
      "Epoch 979/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.7877 - f1_m: 0.1326 - val_loss: 0.5416 - val_accuracy: 0.7665 - val_f1_m: 0.0666\n",
      "Epoch 980/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4776 - accuracy: 0.7879 - f1_m: 0.1410 - val_loss: 0.5417 - val_accuracy: 0.7700 - val_f1_m: 0.0553\n",
      "Epoch 981/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7880 - f1_m: 0.1468 - val_loss: 0.5400 - val_accuracy: 0.7696 - val_f1_m: 0.0636\n",
      "Epoch 982/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4784 - accuracy: 0.7870 - f1_m: 0.1300 - val_loss: 0.5437 - val_accuracy: 0.7675 - val_f1_m: 0.0682\n",
      "Epoch 983/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4779 - accuracy: 0.7879 - f1_m: 0.1403 - val_loss: 0.5422 - val_accuracy: 0.7674 - val_f1_m: 0.0584\n",
      "Epoch 984/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7877 - f1_m: 0.1432 - val_loss: 0.5398 - val_accuracy: 0.7696 - val_f1_m: 0.0558\n",
      "Epoch 985/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4778 - accuracy: 0.7863 - f1_m: 0.1302 - val_loss: 0.5440 - val_accuracy: 0.7653 - val_f1_m: 0.0713\n",
      "Epoch 986/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7874 - f1_m: 0.1399 - val_loss: 0.5407 - val_accuracy: 0.7688 - val_f1_m: 0.0636\n",
      "Epoch 987/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.7870 - f1_m: 0.1385 - val_loss: 0.5408 - val_accuracy: 0.7668 - val_f1_m: 0.0653\n",
      "Epoch 988/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7880 - f1_m: 0.1397 - val_loss: 0.5432 - val_accuracy: 0.7682 - val_f1_m: 0.0574\n",
      "Epoch 989/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4777 - accuracy: 0.7876 - f1_m: 0.1400 - val_loss: 0.5412 - val_accuracy: 0.7691 - val_f1_m: 0.0637\n",
      "Epoch 990/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7873 - f1_m: 0.1368 - val_loss: 0.5428 - val_accuracy: 0.7660 - val_f1_m: 0.0703\n",
      "Epoch 991/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7875 - f1_m: 0.1439 - val_loss: 0.5408 - val_accuracy: 0.7704 - val_f1_m: 0.0557\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.7878 - f1_m: 0.1428 - val_loss: 0.5404 - val_accuracy: 0.7738 - val_f1_m: 0.0525\n",
      "Epoch 993/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4781 - accuracy: 0.7874 - f1_m: 0.1353 - val_loss: 0.5422 - val_accuracy: 0.7665 - val_f1_m: 0.0640\n",
      "Epoch 994/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4773 - accuracy: 0.7866 - f1_m: 0.1285 - val_loss: 0.5428 - val_accuracy: 0.7706 - val_f1_m: 0.0520\n",
      "Epoch 995/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7874 - f1_m: 0.1411 - val_loss: 0.5416 - val_accuracy: 0.7699 - val_f1_m: 0.0592\n",
      "Epoch 996/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7878 - f1_m: 0.1391 - val_loss: 0.5433 - val_accuracy: 0.7680 - val_f1_m: 0.0626\n",
      "Epoch 997/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.7879 - f1_m: 0.1400 - val_loss: 0.5443 - val_accuracy: 0.7658 - val_f1_m: 0.0703\n",
      "Epoch 998/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7874 - f1_m: 0.1382 - val_loss: 0.5415 - val_accuracy: 0.7675 - val_f1_m: 0.0742\n",
      "Epoch 999/1000\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4773 - accuracy: 0.7875 - f1_m: 0.1416 - val_loss: 0.5429 - val_accuracy: 0.7728 - val_f1_m: 0.0499\n",
      "Epoch 1000/1000\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7876 - f1_m: 0.1358 - val_loss: 0.5426 - val_accuracy: 0.7663 - val_f1_m: 0.0664\n"
     ]
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(X_train, y_train,validation_split=0.33, batch_size = 100,epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN  train roc-auc: 0.6723885319159919\n",
      "ANN test roc-auc: 0.5823163272165087\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.98      0.87     23126\n",
      "           1       0.50      0.08      0.13      6489\n",
      "\n",
      "    accuracy                           0.78     29615\n",
      "   macro avg       0.65      0.53      0.50     29615\n",
      "weighted avg       0.73      0.78      0.71     29615\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.96      0.86      2025\n",
      "           1       0.18      0.03      0.05       551\n",
      "\n",
      "    accuracy                           0.76      2576\n",
      "   macro avg       0.48      0.50      0.46      2576\n",
      "weighted avg       0.66      0.76      0.69      2576\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5823163272165087\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ytrain_pred = classifier.predict_proba(X_train)\n",
    "print('ANN  train roc-auc: {}'.format(roc_auc_score(y_train, ytrain_pred)))\n",
    "ytest_pred = classifier.predict_proba(X_test)\n",
    "print('ANN test roc-auc: {}'.format(roc_auc_score(y_test, ytest_pred)))\n",
    "y_pred_train = np.where(classifier.predict(X_train)>.5,1,0)\n",
    "# Train Prediction classification report\n",
    "print(classification_report(y_train,pd.DataFrame(y_pred_train.flatten()) ))\n",
    "\n",
    "y_pred_test = np.where(classifier.predict(X_test)>.5,1,0)\n",
    "# Test Prediction classification report\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "plt.show()\n",
    "\n",
    "from sklearn import metrics\n",
    "def plot_roc_curve(fpr, tpr,model):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    auc = metrics.roc_auc_score(y_test, model.predict_proba(X_test))\n",
    "    print('AUC:', auc)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show( )\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test,classifier.predict_proba(X_test) )\n",
    "plot_roc_curve(fpr,tpr,classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.70      0.79     23126\n",
      "           1       0.42      0.78      0.55      6489\n",
      "\n",
      "    accuracy                           0.72     29615\n",
      "   macro avg       0.67      0.74      0.67     29615\n",
      "weighted avg       0.81      0.72      0.74     29615\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.60      0.69      2025\n",
      "           1       0.25      0.50      0.34       551\n",
      "\n",
      "    accuracy                           0.58      2576\n",
      "   macro avg       0.53      0.55      0.51      2576\n",
      "weighted avg       0.69      0.58      0.62      2576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = pd.DataFrame(classifier.predict(X_test).flatten())\n",
    "from sklearn.metrics import f1_score\n",
    "accuracy_ls=[]\n",
    "for thres in thresholds:\n",
    "    y_pred = np.where(y_pred_test>thres,1,0)\n",
    "    accuracy_ls.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "accuracy_ls = pd.concat([pd.Series(thresholds), pd.Series(accuracy_ls)],axis=1)\n",
    "accuracy_ls.columns = ['thresholds', 'accuracy']\n",
    "accuracy_ls.sort_values(by='accuracy', ascending=False, inplace=True)\n",
    "accuracy_ls.head()\n",
    "\n",
    "# Making the Confusion Matrix for threshold as accuracy threshold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred_test = np.where(model.predict(X_test)>accuracy_ls.iloc[2,0],1,0)\n",
    "cm = confusion_matrix(y_test,  y_pred_test)\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "plt.show()\n",
    "\n",
    "y_pred_train = np.where(model.predict(X_train)>accuracy_ls.iloc[2,0],1,0)\n",
    "# Train Prediction classification report\n",
    "print(classification_report(y_train,pd.DataFrame(y_pred_train.flatten()) ))\n",
    "\n",
    "y_pred_test = np.where(model.predict(X_test)>accuracy_ls.iloc[2,0],1,0)\n",
    "# Test Prediction classification report\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcAAAAGbCAYAAABTbEBHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAW1UlEQVR4nO3cebScdZng8e9zl+wL2YBsbGow7EuQTWxAGlC0lWkYBY6CZ5SlGxAatZ1ji47dM4o43aNwZJHuttF2wBY9KiogNrvQEpCt2RlCEhICSSCQ/ebeZ/6oSriELDeBpCDP93NODlXv+9Zbv7q8t771LnUjM5EkqZq2Vg9AkqRWMICSpJIMoCSpJAMoSSrJAEqSSupo9QA2t9Ej23OHiZ2tHoa0WT3y7JhWD0FqicXzZs7NzDX+ApQL4A4TO/nD9RNbPQxps9r/r89o9RCklph65XnPrG2eh0AlSSUZQElSSQZQklSSAZQklWQAJUklGUBJUkkGUJJUkgGUJJVkACVJJRlASVJJBlCSVJIBlCSVZAAlSSUZQElSSQZQklSSAZQklWQAJUklGUBJUkkGUJJUkgGUJJVkACVJJRlASVJJBlCSVJIBlCSVZAAlSSUZQElSSQZQklSSAZQklWQAJUklGUBJUkkGUJJUkgGUJJVkACVJJRlASVJJBlCSVJIBlCSVZAAlSSUZQElSSQZQklSSAZQklWQAJUklGUBJUkkGUJJUkgGUJJVkACVJJRlASVJJBlCSVJIBlCSVZAAlSSUZQElSSQZQklSSAZQklWQAJUklGUBJUkkGUJJUkgGUJJVkACVJJRlASVJJBlCSVJIBlCSVZAAlSSUZQElSSQZQklSSAZQklWQAJUklGUBJUkkGUJJUkgGUJJVkACVJJRlASVJJBlCSVJIBlCSVZAAlSSUZQElSSQZQklSSAZQklWQAJUklGUBJUkkGUJJUkgGUJJVkACVJJRlASVJJBlCSVJIBlCSVZAAlSSUZQElSSQZQklSSAZQklWQAJUkldbR6AHp7i3PnwG8Xw+h28ubtXjvzkhdp+9o8eh7aEUa1wx+XEp9/vjEvIc8bCR8c0rj/81eIb78I3cARg8gvj96sr0N6I35+zd+xuLM/PdHGirY2Tj7mXCbNf5Yv3vUT+nevYEVbGxfs/+c8PLrxO/LOF2fx3+/8CUO6ltITwcnHnMPy9s4Wv4p6+hTAiDgW+CkwOTMfXc+y5wCXZ+bijRlQRJwCTMnMM1ebHsC3gQ8Ci4FTMvPejXkOvXnyvw6DTw0nzn7+tTOe7SJuWUyO77WJ7dyPvG4idATMWUG8fwZ55GB4uYf42jzy+okwup04ew7cthgOGbR5X4z0Bpx+5BksGDBk1f2z7rmWK/Y8kt+Pn8xBMx/h7Huu5fSj/oL2nm6+dtuP+Mp7T+SJkeMYvnQRK6K9hSOvq6+HQE8Abgc+3odlzwE2xTvXB4B3Nf+dClyyCZ5DG+rAgTDi9b+88ZW5jb246DVxUFsjfgDL8tV507vgHZ0wurGePGQg8auFm3bc0iaWwODlSwEY0rWEFwYOA2D/WY/z5IixPDFyHAALBgymp82zUa2w3j3AiBgCHAwcBvwC+GpzejtwAXAUjf/X36PxljYOuCki5mbmYRGxMDOHNB9zHPChzDwlIj4M/A3QD5gHnJSZc9YxlI8AV2ZmAndFxFYRMRZ4GfgxMAFoB/42M6/ewJ+D3kzXL4JtO2DX/q+fd+9S4tznYWYXedE2jSDu0AlPLocZXTC2g7huEXTl5h+3tJEygotvvJwk+NmkA/jZpAP5+/0+ykU3Xs5n7/klkcl/+8BZAGz/8gtkBN/57WWMWLaIG3bYix/sdniLX0FNfTkE+lHgusx8PCLmR8Q+zUOPpwI7Antn5oqIGJmZ8yPir4DDMnPuetZ7O3BAZmZEfBr4AnDeOpYfD8zodX9mc9pBwKzMPAYgIoav/sCIOLU5XrYb72nPTWpxD/Ht+eRV49Y8f58B5C3bwePLic/OIQ8fBFu1k9/YmjjtucYxiSkD4ZmuzTps6Y349NFnMnfQcEYseYWLb7yMacO35vBnHuDv9/sIN22/B0dMu48v//7H/OWRp9Oe3ez5/NOc/MHPsrSjH9+94VIeHTWBu8dOavXLKKcv+90nAFc1b1/VvA9wBHBpZq4AyMz5G/jcE4DrI+JB4PPArutZPtYwLYEHgSMi4oKIOCQzF7xuoczLM3NKZk4ZM8pj7ZvUM10wvXF+L/abBrNXEEfOgOdXvHa5Sf0ah0QfXd64f+Rg8tcTyWsnku/ohJ28IEBvH3MHNT53vzhwKDdP3J1d507nQ09N5abtdgfgxu33ZJd50wGYM2gr/rjNTiwYMIRlHf34/YTJ7Dzv2ZaNvbJ1BjAiRgGHA1dExDQaofpY84KUoBGg9em9zIBety8CLs7M3YHTVpu3JjOBib3uT6Cx5/c4sC+NEH49Is7vw5i0qUzuTz60I3n3DuTdO8DYDvKGibB1R+Nc34rm5jCjC55aDhOboZvbDORL3cS/LCBPHNaS4UsbakDXMgZ1LV11+4DZj/HUVmN5YdAw9pnzFAD7PfcEM4aOAeCucTvzzhdn03/Fctp7utnnuad4eqttWjb+ytZ3PPA4GufdTls5ISJuAd4L3ACcHhE39z4ECrwCDAVWHgKdExGTgceAY5vzAYYDKz/2nNyHsf4CODMirgL2BxZk5uyIGAfMz8wfRsRC4JQ+rEtvkjjjOfj9EpjfTezzNPm5UbC2eP3HEuLil6ATiCC/Pqbx9QggvjwX/nMZAPlXI+Ed/TbPC5DeoFFLF/LNm/8ZgI6eHq7bcR/uHP9uFnf047y7f057drO8vZP/deBxALzSfxA/2uVPuPJX/4eM4I7x7+aOCbu08iWUtb4AngB8Y7Vp1wAnAmcBk4AHIqKLxkUwFwOXA7+JiNmZeRjwReBaGufvHgJWXif8VeDfIuJZ4C4a5xPX5dc0vgLxJI2vQXyqOX134MKI6AG6gDPWsx69ifKSbdc9/+4dXr1z/DDy+DXHcX3rkd6qnh06ipM+/LnXTb9/m5345IfOXeNjfrPTvvxmp3039dC0HtG4qLKOKXsOyD9cP3H9C0pbkP3/2s+Fqmnqlefdk5lT1jTPL59IkkoygJKkkgygJKkkAyhJKskASpJKMoCSpJIMoCSpJAMoSSrJAEqSSjKAkqSSDKAkqSQDKEkqyQBKkkoygJKkkgygJKkkAyhJKskASpJKMoCSpJIMoCSpJAMoSSrJAEqSSjKAkqSSDKAkqSQDKEkqyQBKkkoygJKkkgygJKkkAyhJKskASpJKMoCSpJIMoCSpJAMoSSrJAEqSSjKAkqSSDKAkqSQDKEkqyQBKkkoygJKkkgygJKkkAyhJKskASpJKMoCSpJIMoCSpJAMoSSrJAEqSSjKAkqSSDKAkqSQDKEkqyQBKkkoygJKkkgygJKkkAyhJKskASpJKMoCSpJIMoCSpJAMoSSrJAEqSSjKAkqSSDKAkqSQDKEkqyQBKkkoygJKkkgygJKkkAyhJKskASpJKMoCSpJIMoCSpJAMoSSrJAEqSSjKAkqSSDKAkqSQDKEkqyQBKkkoygJKkkgygJKkkAyhJKskASpJKMoCSpJIMoCSpJAMoSSrJAEqSSjKAkqSSDKAkqSQDKEkqyQBKkkoygJKkkgygJKkkAyhJKskASpJK6mj1ADa3Jx7dimMO+rNWD0ParLaadmerhyC95bgHKEkqyQBKkkoygJKkkgygJKkkAyhJKskASpJKMoCSpJIMoCSpJAMoSSrJAEqSSjKAkqSSDKAkqSQDKEkqyQBKkkoygJKkkgygJKkkAyhJKskASpJKMoCSpJIMoCSpJAMoSSrJAEqSSjKAkqSSDKAkqSQDKEkqyQBKkkoygJKkkgygJKkkAyhJKskASpJKMoCSpJIMoCSpJAMoSSrJAEqSSjKAkqSSDKAkqSQDKEkqyQBKkkoygJKkkgygJKkkAyhJKskASpJKMoCSpJIMoCSpJAMoSSrJAEqSSjKAkqSSDKAkqSQDKEkqyQBKkkoygJKkkgygJKkkAyhJKskASpJKMoCSpJIMoCSpJAMoSSrJAEqSSjKAkqSSDKAkqSQDKEkqyQBKkkoygJKkkgygJKkkAyhJKskASpJKMoCSpJIMoCSpJAMoSSrJAEqSSjKAkqSSDKAkqSQDKEkqyQBKkkoygJKkkgygJKkkAyhJKskASpJKMoCSpJIMoCSpJAMoSSrJAEqSSjKAkqSSDKAkqSQDKEkqyQBKkkoygJKkkgygJKkkAyhJKskASpJKMoCSpJI6Wj0AbTk6e1Zw4eyr6aSb9kxuH/wufjjiID7x4h0cuOgpeiJY0DaI/z3mKOZ3DGFo9xK+9PwvmbRsDr8dsguXjH5/q1+CtMHG5GK+wN2MZCk9BL9mR34W7+Iz+QAHMJsVtDGLwXyLKSyKfgB8PB/laJ6mh+C77MXU2LbFr6KmPgUwIo4FfgpMzsxH17PsOcDlmbl4YwYUEacAUzLzzNWmvxv4Z2Af4EuZ+a2NWb82na5o54tjj2dpWz/as5tvzb6aqQN34JrhU/jBiIMB+LMF93LiS3dx8egjWB4d/GDEwWy/fC7bL5/b4tFLG6eb4DL24MkYwcDs4rv8jntyG+5la/6R3eiJNj6dD3ACj3IFe7BdvsyhzOAzHMkolnIBt/KpPJqeiFa/lHL6egj0BOB24ON9WPYcYNDGDmgd5gNnA4bvrSqCpW2NT7gd2UNH9pAEi9v6r1pkQK5YdXtZWyf/OWA8y8MDEXr7mh8DeTJGALAkOpnOUEazhHtiW3qi8Rb7CKMYzRIADmIWNzORrmjnuRjMLIawM/NbNv7K1vvOExFDgIOBw4BfAF9tTm8HLgCOAhL4HhDAOOCmiJibmYdFxMLMHNJ8zHHAhzLzlIj4MPA3QD9gHnBSZs5Z2zgy83ng+Yg4ZrXxDQZ+DEwA2oG/zcyr+/4j0JupLXv4zqx/ZVzXS1w7bE8eGzAWgJPn3877Fz7Morb+fHHs8S0epbRpbJOLeCcv8SgjXzP9KKZxCxMAGM0SHuk1/wUGroqjNq++7AF+FLguMx8H5kfEPs3ppwI7Antn5h7Av2bmd4BZwGGZedh61ns7cEBm7g1cBXxhY14AcDQwKzP3zMzdgOtWXyAiTo2IqRExdXn3Rh2ZVR/1RBtnjv8En5j4GSYte27Voc1/GflePrndqdw0ZDIffvm+1g5S2gQG5ArO504uYS8WR+eq6SfmI3QT/I7tgMZewupyM41Rr9WXAJ5AI1A0/3tC8/YRwKWZjWNambmh+/ATgOsj4kHg88CuG/j4lR4EjoiICyLikMxcsPoCmXl5Zk7JzCn92jfF0VmtblH7AB4YMJEpS6a9ZvrNg9/NwYueaM2gpE2kPXv4Cnfy72zH7TF+1fQ/zWnsz2y+wXugeY7vBQYyptce3xiWMI+Bm33MWk8AI2IUcDhwRURMoxGqj0VE0Pgg05cPLr2XGdDr9kXAxZm5O3DaavP6rLlnui+NEH49Is7fmPXojRvevZjB3UsB6NfTxd5LpjOjcyTjul5ctcwBi59iZufIta1CevvJ5DymMp2hXBOTVk2eks/xMR7jfA5mWa/z3HcylkOZQWd2s20uYjwLeQx/J1phfecAjwOuzMzTVk6IiFuA9wI3AKdHxM2ZuSIiRjb3Al8BhgIrL+ubExGTgceAY5vzAYYDzzZvn7yxLyAixgHzM/OHEbEQOGVj16U3ZkT3Ij73wnW0ZRIktw2exB8G7cSX5vyCCV0vkgTPdwzjol5fd/j+jCsY1LOMjuzhoMVP8aVt/5zp/Ua18FVIG2ZX5vGnTOf/MZxL87cA/BO78RfcRyc9XMCtkI0LYb4d+/BMDOfWnMAV3EA3wUXs5RWgLRKZa9+Ji4ibgW9k5nW9pp0NTAbOAr5J4xxcF/C9zLw4Is4C/hKY3bwI5jgaF8vMAB4ChjQvgvkI8A80IngXsF9mHrqOr0FsC0wFhgE9wEJgF+BA4MLmtC7gjMycurbXNLz/tnnQ+JP6+OORtgwrpk1v9RCklrgxf3JPZk5Z07x1BnBLZABVkQFUVesKoH8KTZJUkgGUJJVkACVJJRlASVJJBlCSVJIBlCSVZAAlSSUZQElSSQZQklSSAZQklWQAJUklGUBJUkkGUJJUkgGUJJVkACVJJRlASVJJBlCSVJIBlCSVZAAlSSUZQElSSQZQklSSAZQklWQAJUklGUBJUkkGUJJUkgGUJJVkACVJJRlASVJJBlCSVJIBlCSVZAAlSSUZQElSSQZQklSSAZQklWQAJUklGUBJUkkGUJJUkgGUJJVkACVJJRlASVJJBlCSVJIBlCSVZAAlSSUZQElSSQZQklSSAZQklWQAJUklGUBJUkkGUJJUkgGUJJVkACVJJRlASVJJBlCSVJIBlCSVZAAlSSUZQElSSQZQklSSAZQklWQAJUklGUBJUkkGUJJUkgGUJJVkACVJJRlASVJJBlCSVJIBlCSVZAAlSSUZQElSSQZQklSSAZQklWQAJUklGUBJUkkGUJJUkgGUJJVkACVJJRlASVJJBlCSVJIBlCSVZAAlSSUZQElSSQZQklSSAZQklWQAJUklGUBJUkkGUJJUkgGUJJVkACVJJRlASVJJBlCSVFJkZqvHsFlFxAvAM60eR2GjgbmtHoS0mbndt872mTlmTTPKBVCtFRFTM3NKq8chbU5u929NHgKVJJVkACVJJRlAbW6Xt3oAUgu43b8FeQ5QklSSe4CSpJIMoCSpJANYVER0R8R9EfFQRPxbRAx6A+v6fkQc17x9RUTsso5lD42IgzbiOaZFxOg1TN83Ih6MiCcj4jsRERu6btWxBW33/zMiZkTEwg1dp15lAOtakpl7ZeZuwHLg9N4zI6J9Y1aamZ/OzIfXscihwAa/EazDJcCpwLua/45+E9etLc+Wst3/EnjPm7i+kgygAG4D3tn8lHpTRPwIeDAi2iPiwoi4OyIeiIjTAKLh4oh4OCJ+BWy9ckURcXNETGnePjoi7o2I+yPidxGxA403nHObn8IPiYgxEXFN8znujoiDm48dFRE3RMQfI+Iy4HV7dhExFhiWmXdm42quK4GPNucd3/yUf39E3LoJf3Z6+3pbbvcAmXlXZs5efbrb/YbpaPUA1FoR0QF8ALiuOek9wG6Z+XREnAosyMz9IqI/cEdE3ADsDewM7A5sAzwM/NNq6x0DfA94X3NdIzNzfkRcCizMzG81l/sR8A+ZeXtEbAdcD0wGvgLcnplfi4hjaOzlrW48MLPX/ZnNaQDnA0dl5rMRsdXG/4S0JXqbb/fr4na/AQxgXQMj4r7m7duAf6RxiOYPmfl0c/qRwB4rz3MAw2kcZnwf8H8zsxuYFRH/vob1HwDcunJdmTl/LeM4Atil16m7YRExtPkc/6X52F9FxItreOyaPh2v/F7PHcD3I+LHwE/X8tyqZ0vY7tfF7X4DGMC6lmTmXr0nNH8ZF/WeBJyVmdevttwHeTU0axN9WAYah+EPzMwlaxjL+h4/E5jQ6/4EYBZAZp4eEfsDxwD3RcRemTmvD+PRlm1L2O7Xyu1+w3gOUOtyPXBGRHQCRMSkiBgM3Ap8vHmuZCxw2BoeeyfwJxGxY/OxI5vTXwGG9lruBuDMlXciYq/mzVuBk5rTPgCMWP0JmudAXomIA6LxzvFJ4OfNx7wjM/8jM8+n8Vf4J27E61dNb+ntfl3c7jeMAdS6XEHjPMe9EfEQcBmNowY/A54AHqRxFeYtqz8wM1+gcf7ipxFxP3B1c9YvgWNXXgwAnA1MaV5s8DCvXpX3P4D3RcS9NA5JTV/LGM9ojvNJ4CngN83pF0bj6xEP0XhTuX8jfwaq5y2/3UfENyNiJjAoImZGxFebs9zuN4B/Ck2SVJJ7gJKkkgygJKkkAyhJKskASpJKMoCSpJIMoCSpJAMoSSrp/wMXvuaFk+vexwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.79      0.84     23126\n",
      "           1       0.48      0.68      0.56      6489\n",
      "\n",
      "    accuracy                           0.77     29615\n",
      "   macro avg       0.69      0.74      0.70     29615\n",
      "weighted avg       0.81      0.77      0.78     29615\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.76      2025\n",
      "           1       0.27      0.40      0.32       551\n",
      "\n",
      "    accuracy                           0.64      2576\n",
      "   macro avg       0.54      0.55      0.54      2576\n",
      "weighted avg       0.70      0.64      0.67      2576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = pd.DataFrame(model.predict(X_test).flatten())\n",
    "from sklearn.metrics import f1_score\n",
    "f1score_ls=[]\n",
    "for thres in thresholds:\n",
    "    y_pred = np.where(y_pred_test>thres,1,0)\n",
    "    f1score_ls.append(f1_score(y_test, y_pred))\n",
    "    \n",
    "f1score_ls = pd.concat([pd.Series(thresholds), pd.Series(f1score_ls)],axis=1)\n",
    "f1score_ls.columns = ['thresholds', 'f1score']\n",
    "f1score_ls.sort_values(by='f1score', ascending=False, inplace=True)\n",
    "f1score_ls.head()\n",
    "\n",
    "# Making the Confusion Matrix for threshold as accuracy threshold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred_test = np.where(model.predict(X_test)>f1score_ls.iloc[0,0],1,0)\n",
    "cm = confusion_matrix(y_test,  y_pred_test)\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "plt.show()\n",
    "\n",
    "y_pred_train = np.where(model.predict(X_train)>f1score_ls.iloc[0,0],1,0)\n",
    "# Train Prediction classification report\n",
    "print(classification_report(y_train,pd.DataFrame(y_pred_train.flatten()) ))\n",
    "\n",
    "y_pred_test = np.where(model.predict(X_test)>f1score_ls.iloc[0,0],1,0)\n",
    "# Test Prediction classification report\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CeJkVoIycj0e",
    "outputId": "85d15003-a5ad-4ac0-b5a7-8e0d2504564f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "-fb6cR7icjyP",
    "outputId": "b4e44eee-050c-449e-d25a-687e4e386478"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "\n",
    "print(model_history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(model_history.history['accuracy'])\n",
    "plt.plot(model_history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "JkvZiaxCcjvi",
    "outputId": "161da802-8e36-41ce-9dff-2833da669d75"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "j1TqjEVAcjs8"
   },
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "Uy4Xdb5acjqn"
   },
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9N5-SKTxcjoT",
    "outputId": "06d4abc1-883b-482b-9b35-4548f97283ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1966,   59],\n",
       "       [ 535,   16]])"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "qvdnd4Y0cjl8"
   },
   "outputs": [],
   "source": [
    "# Calculate the Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "score=accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ogForjGPcjji",
    "outputId": "16562635-8de8-42d5-ac70-c8fc4e8067b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7694099378881988"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_F4Q2rVDt-Q"
   },
   "source": [
    "Tuning the keras ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "HUNT1PjOcjhP"
   },
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    for i in range(hp.Int('num_layers', 2, 20)):\n",
    "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=32,\n",
    "                                            max_value=512,\n",
    "                                            step=32),\n",
    "                               activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ASM1AudLFf7R",
    "outputId": "3f57a302-c32b-4cee-c63f-355dfc5a482e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\r",
      "\u001b[K     |█████▏                          | 10kB 15.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 20kB 19.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 30kB 7.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 40kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 51kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 61kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 71kB 2.4MB/s \n",
      "\u001b[?25h  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "3av-thCIcje9"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='project1',\n",
    "    project_name='Loan_Default_Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FZgTU_p2cjcm",
    "outputId": "0fb6ab93-d352-401d-fa5a-50fd2de99e3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 20, 'step': 1, 'sampling': None}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j4XzUq0DcjaB",
    "outputId": "41aa4ad5-a7b1-4eef-c642-8d88acf9ccd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 03m 54s]\n",
      "val_accuracy: 0.7861024737358093\n",
      "\n",
      "Best val_accuracy So Far: 0.7861024737358093\n",
      "Total elapsed time: 00h 15m 42s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train,\n",
    "             epochs=5,\n",
    "             validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2S4QhKNScjXl",
    "outputId": "0d186cd2-d363-49b4-a637-38f549a90f7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseTuner.get_best_hyperparameters of <kerastuner.tuners.randomsearch.RandomSearch object at 0x7f054266e6a0>>"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_sjSqc3xEHzR",
    "outputId": "160867fb-70b1-437d-e2fe-ff51c6f2013d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.sequential.Sequential at 0x7f053eb8d710>]"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RSvUE9CdEHwZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TySbBnZNEHuJ"
   },
   "outputs": [],
   "source": [
    "# Weighted Neural Network With Keras\n",
    "# Define Weights\n",
    "# Fit the model with thos specific weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "7wrv2SI8EHrx"
   },
   "outputs": [],
   "source": [
    "weights_assigned={0:1,1:10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kxyc_mqEEHpj",
    "outputId": "46e0c7fe-8f16-47a7-829d-61fe6a66eebc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.6764 - accuracy: 0.2426\n",
      "Epoch 2/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.6456 - accuracy: 0.2573\n",
      "Epoch 3/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.6370 - accuracy: 0.2700\n",
      "Epoch 4/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.6315 - accuracy: 0.2782\n",
      "Epoch 5/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.6261 - accuracy: 0.2826\n",
      "Epoch 6/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.6187 - accuracy: 0.2936\n",
      "Epoch 7/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.6097 - accuracy: 0.3064\n",
      "Epoch 8/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.6034 - accuracy: 0.3090\n",
      "Epoch 9/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.5932 - accuracy: 0.3250\n",
      "Epoch 10/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.5839 - accuracy: 0.3342\n",
      "Epoch 11/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.5713 - accuracy: 0.3455\n",
      "Epoch 12/1000\n",
      "2962/2962 [==============================] - 7s 2ms/step - loss: 1.5641 - accuracy: 0.3531\n",
      "Epoch 13/1000\n",
      "2962/2962 [==============================] - 7s 2ms/step - loss: 1.5513 - accuracy: 0.3601\n",
      "Epoch 14/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.5440 - accuracy: 0.3684\n",
      "Epoch 15/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.5345 - accuracy: 0.3749\n",
      "Epoch 16/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.5213 - accuracy: 0.3842\n",
      "Epoch 17/1000\n",
      "2962/2962 [==============================] - 8s 3ms/step - loss: 1.5122 - accuracy: 0.3915\n",
      "Epoch 18/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.5071 - accuracy: 0.3894\n",
      "Epoch 19/1000\n",
      "2962/2962 [==============================] - 7s 3ms/step - loss: 1.4980 - accuracy: 0.3962\n",
      "Epoch 20/1000\n",
      "2962/2962 [==============================] - 7s 2ms/step - loss: 1.4936 - accuracy: 0.4036\n",
      "Epoch 21/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.4856 - accuracy: 0.4058\n",
      "Epoch 22/1000\n",
      "2962/2962 [==============================] - 8s 3ms/step - loss: 1.4808 - accuracy: 0.4113\n",
      "Epoch 23/1000\n",
      "2962/2962 [==============================] - 7s 2ms/step - loss: 1.4679 - accuracy: 0.4188\n",
      "Epoch 24/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.4641 - accuracy: 0.4246\n",
      "Epoch 25/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.4600 - accuracy: 0.4245\n",
      "Epoch 26/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.4519 - accuracy: 0.4273\n",
      "Epoch 27/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.4471 - accuracy: 0.4325\n",
      "Epoch 28/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.4581 - accuracy: 0.4322\n",
      "Epoch 29/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.4425 - accuracy: 0.4359\n",
      "Epoch 30/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.4356 - accuracy: 0.4389\n",
      "Epoch 31/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.4356 - accuracy: 0.4414\n",
      "Epoch 32/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.4429 - accuracy: 0.4487\n",
      "Epoch 33/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.4294 - accuracy: 0.4465\n",
      "Epoch 34/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.4225 - accuracy: 0.4509\n",
      "Epoch 35/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.4149 - accuracy: 0.4533\n",
      "Epoch 36/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.4119 - accuracy: 0.4542\n",
      "Epoch 37/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.3986 - accuracy: 0.4596\n",
      "Epoch 38/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.4052 - accuracy: 0.4566\n",
      "Epoch 39/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.3958 - accuracy: 0.4622\n",
      "Epoch 40/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.3929 - accuracy: 0.4626\n",
      "Epoch 41/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.3859 - accuracy: 0.4647\n",
      "Epoch 42/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.3891 - accuracy: 0.4646\n",
      "Epoch 43/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.3820 - accuracy: 0.4657\n",
      "Epoch 44/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.3782 - accuracy: 0.4672\n",
      "Epoch 45/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.3758 - accuracy: 0.4719\n",
      "Epoch 46/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.3653 - accuracy: 0.4746\n",
      "Epoch 47/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.3833 - accuracy: 0.4712\n",
      "Epoch 48/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.3624 - accuracy: 0.4805\n",
      "Epoch 49/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.3723 - accuracy: 0.4765\n",
      "Epoch 50/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.3572 - accuracy: 0.4802\n",
      "Epoch 51/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.3589 - accuracy: 0.4846\n",
      "Epoch 52/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.3531 - accuracy: 0.4831\n",
      "Epoch 53/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.3512 - accuracy: 0.4835\n",
      "Epoch 54/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.3487 - accuracy: 0.4855\n",
      "Epoch 55/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.3359 - accuracy: 0.4904\n",
      "Epoch 56/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.3461 - accuracy: 0.4885\n",
      "Epoch 57/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.3376 - accuracy: 0.4902\n",
      "Epoch 58/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.3313 - accuracy: 0.4911\n",
      "Epoch 59/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.3324 - accuracy: 0.4935\n",
      "Epoch 60/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.3302 - accuracy: 0.4978\n",
      "Epoch 61/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.3244 - accuracy: 0.5002\n",
      "Epoch 62/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.3329 - accuracy: 0.4950\n",
      "Epoch 63/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.3220 - accuracy: 0.4997\n",
      "Epoch 64/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.3184 - accuracy: 0.5012\n",
      "Epoch 65/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.3149 - accuracy: 0.5030\n",
      "Epoch 66/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.3157 - accuracy: 0.4980\n",
      "Epoch 67/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.3136 - accuracy: 0.5016\n",
      "Epoch 68/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.3165 - accuracy: 0.5050\n",
      "Epoch 69/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.3076 - accuracy: 0.5055\n",
      "Epoch 70/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.3027 - accuracy: 0.5057\n",
      "Epoch 71/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.3024 - accuracy: 0.5112\n",
      "Epoch 72/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2967 - accuracy: 0.5078\n",
      "Epoch 73/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.3081 - accuracy: 0.5049\n",
      "Epoch 74/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2964 - accuracy: 0.5116\n",
      "Epoch 75/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2935 - accuracy: 0.5080\n",
      "Epoch 76/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2971 - accuracy: 0.5113\n",
      "Epoch 77/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2919 - accuracy: 0.5094\n",
      "Epoch 78/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2883 - accuracy: 0.5122\n",
      "Epoch 79/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2852 - accuracy: 0.5147\n",
      "Epoch 80/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2794 - accuracy: 0.5165\n",
      "Epoch 81/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2981 - accuracy: 0.5156\n",
      "Epoch 82/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2717 - accuracy: 0.5177\n",
      "Epoch 83/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2906 - accuracy: 0.5147\n",
      "Epoch 84/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2717 - accuracy: 0.5191\n",
      "Epoch 85/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2707 - accuracy: 0.5254\n",
      "Epoch 86/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.3018 - accuracy: 0.5161\n",
      "Epoch 87/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2701 - accuracy: 0.5226\n",
      "Epoch 88/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2650 - accuracy: 0.5259\n",
      "Epoch 89/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2673 - accuracy: 0.5232\n",
      "Epoch 90/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2601 - accuracy: 0.5245\n",
      "Epoch 91/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2648 - accuracy: 0.5232\n",
      "Epoch 92/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2662 - accuracy: 0.5254\n",
      "Epoch 93/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2678 - accuracy: 0.5245\n",
      "Epoch 94/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2630 - accuracy: 0.5257\n",
      "Epoch 95/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2674 - accuracy: 0.5253\n",
      "Epoch 96/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2606 - accuracy: 0.5287\n",
      "Epoch 97/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2599 - accuracy: 0.5278\n",
      "Epoch 98/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2616 - accuracy: 0.5259\n",
      "Epoch 99/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2449 - accuracy: 0.5298\n",
      "Epoch 100/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2530 - accuracy: 0.5311\n",
      "Epoch 101/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2558 - accuracy: 0.5281\n",
      "Epoch 102/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2446 - accuracy: 0.5327\n",
      "Epoch 103/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2614 - accuracy: 0.5266\n",
      "Epoch 104/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2447 - accuracy: 0.5306\n",
      "Epoch 105/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2450 - accuracy: 0.5329\n",
      "Epoch 106/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2549 - accuracy: 0.5286\n",
      "Epoch 107/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2493 - accuracy: 0.5333\n",
      "Epoch 108/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2381 - accuracy: 0.5336\n",
      "Epoch 109/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2538 - accuracy: 0.5307\n",
      "Epoch 110/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2424 - accuracy: 0.5335\n",
      "Epoch 111/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2435 - accuracy: 0.5335\n",
      "Epoch 112/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2416 - accuracy: 0.5346\n",
      "Epoch 113/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2366 - accuracy: 0.5384\n",
      "Epoch 114/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2420 - accuracy: 0.5368\n",
      "Epoch 115/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2272 - accuracy: 0.5403\n",
      "Epoch 116/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2569 - accuracy: 0.5318\n",
      "Epoch 117/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2443 - accuracy: 0.5344\n",
      "Epoch 118/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2266 - accuracy: 0.5410\n",
      "Epoch 119/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2382 - accuracy: 0.5378\n",
      "Epoch 120/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2300 - accuracy: 0.5394\n",
      "Epoch 121/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2201 - accuracy: 0.5428\n",
      "Epoch 122/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2235 - accuracy: 0.5404\n",
      "Epoch 123/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2528 - accuracy: 0.5377\n",
      "Epoch 124/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2215 - accuracy: 0.5406\n",
      "Epoch 125/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2207 - accuracy: 0.5417\n",
      "Epoch 126/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2327 - accuracy: 0.5400\n",
      "Epoch 127/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2357 - accuracy: 0.5387\n",
      "Epoch 128/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2267 - accuracy: 0.5438\n",
      "Epoch 129/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2198 - accuracy: 0.5436\n",
      "Epoch 130/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2377 - accuracy: 0.5411\n",
      "Epoch 131/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.2257 - accuracy: 0.5407\n",
      "Epoch 132/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2243 - accuracy: 0.5412\n",
      "Epoch 133/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2321 - accuracy: 0.5394\n",
      "Epoch 134/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2158 - accuracy: 0.5419\n",
      "Epoch 135/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2241 - accuracy: 0.5437\n",
      "Epoch 136/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2187 - accuracy: 0.5430\n",
      "Epoch 137/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2211 - accuracy: 0.5435\n",
      "Epoch 138/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2183 - accuracy: 0.5439\n",
      "Epoch 139/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.2234 - accuracy: 0.5463\n",
      "Epoch 140/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2173 - accuracy: 0.5471\n",
      "Epoch 141/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2161 - accuracy: 0.5486\n",
      "Epoch 142/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2158 - accuracy: 0.5489\n",
      "Epoch 143/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2112 - accuracy: 0.5468\n",
      "Epoch 144/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2157 - accuracy: 0.5481\n",
      "Epoch 145/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2025 - accuracy: 0.5488\n",
      "Epoch 146/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2105 - accuracy: 0.5495\n",
      "Epoch 147/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.2078 - accuracy: 0.5486\n",
      "Epoch 148/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.2062 - accuracy: 0.5496\n",
      "Epoch 149/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2218 - accuracy: 0.5456\n",
      "Epoch 150/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2097 - accuracy: 0.5493\n",
      "Epoch 151/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1997 - accuracy: 0.5516\n",
      "Epoch 152/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2154 - accuracy: 0.5480\n",
      "Epoch 153/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2065 - accuracy: 0.5477\n",
      "Epoch 154/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1942 - accuracy: 0.5534\n",
      "Epoch 155/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1979 - accuracy: 0.5521\n",
      "Epoch 156/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2099 - accuracy: 0.5520\n",
      "Epoch 157/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1933 - accuracy: 0.5535\n",
      "Epoch 158/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2108 - accuracy: 0.5497\n",
      "Epoch 159/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2016 - accuracy: 0.5514\n",
      "Epoch 160/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2088 - accuracy: 0.5481\n",
      "Epoch 161/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2029 - accuracy: 0.5509\n",
      "Epoch 162/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1996 - accuracy: 0.5505\n",
      "Epoch 163/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2065 - accuracy: 0.5513\n",
      "Epoch 164/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.2038 - accuracy: 0.5517\n",
      "Epoch 165/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1952 - accuracy: 0.5535\n",
      "Epoch 166/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2030 - accuracy: 0.5496\n",
      "Epoch 167/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1949 - accuracy: 0.5556\n",
      "Epoch 168/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2048 - accuracy: 0.5538\n",
      "Epoch 169/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1979 - accuracy: 0.5548\n",
      "Epoch 170/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1937 - accuracy: 0.5548\n",
      "Epoch 171/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1914 - accuracy: 0.5564\n",
      "Epoch 172/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1989 - accuracy: 0.5536\n",
      "Epoch 173/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1877 - accuracy: 0.5576\n",
      "Epoch 174/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1986 - accuracy: 0.5539\n",
      "Epoch 175/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1977 - accuracy: 0.5552\n",
      "Epoch 176/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1983 - accuracy: 0.5581\n",
      "Epoch 177/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1882 - accuracy: 0.5562\n",
      "Epoch 178/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1772 - accuracy: 0.5592\n",
      "Epoch 179/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2021 - accuracy: 0.5547\n",
      "Epoch 180/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1984 - accuracy: 0.5547\n",
      "Epoch 181/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1947 - accuracy: 0.5575\n",
      "Epoch 182/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1907 - accuracy: 0.5550\n",
      "Epoch 183/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1856 - accuracy: 0.5592\n",
      "Epoch 184/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.2018 - accuracy: 0.5558\n",
      "Epoch 185/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1815 - accuracy: 0.5595\n",
      "Epoch 186/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1899 - accuracy: 0.5565\n",
      "Epoch 187/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1876 - accuracy: 0.5575\n",
      "Epoch 188/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1877 - accuracy: 0.5602\n",
      "Epoch 189/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1896 - accuracy: 0.5573\n",
      "Epoch 190/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1940 - accuracy: 0.5585\n",
      "Epoch 191/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1839 - accuracy: 0.5569\n",
      "Epoch 192/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1838 - accuracy: 0.5614\n",
      "Epoch 193/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1883 - accuracy: 0.5587\n",
      "Epoch 194/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1714 - accuracy: 0.5634\n",
      "Epoch 195/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1896 - accuracy: 0.5589\n",
      "Epoch 196/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1906 - accuracy: 0.5574\n",
      "Epoch 197/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1799 - accuracy: 0.5620\n",
      "Epoch 198/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1819 - accuracy: 0.5607\n",
      "Epoch 199/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1855 - accuracy: 0.5587\n",
      "Epoch 200/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1822 - accuracy: 0.5612\n",
      "Epoch 201/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1814 - accuracy: 0.5598\n",
      "Epoch 202/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1828 - accuracy: 0.5626\n",
      "Epoch 203/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1817 - accuracy: 0.5618\n",
      "Epoch 204/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1702 - accuracy: 0.5638\n",
      "Epoch 205/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1825 - accuracy: 0.5629\n",
      "Epoch 206/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1744 - accuracy: 0.5632\n",
      "Epoch 207/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1800 - accuracy: 0.5651\n",
      "Epoch 208/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1793 - accuracy: 0.5639\n",
      "Epoch 209/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1807 - accuracy: 0.5635\n",
      "Epoch 210/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1738 - accuracy: 0.5654\n",
      "Epoch 211/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1801 - accuracy: 0.5614\n",
      "Epoch 212/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1742 - accuracy: 0.5653\n",
      "Epoch 213/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1776 - accuracy: 0.5639\n",
      "Epoch 214/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1773 - accuracy: 0.5653\n",
      "Epoch 215/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1785 - accuracy: 0.5627\n",
      "Epoch 216/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1896 - accuracy: 0.5625\n",
      "Epoch 217/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1828 - accuracy: 0.5627\n",
      "Epoch 218/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1666 - accuracy: 0.5674\n",
      "Epoch 219/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1774 - accuracy: 0.5642\n",
      "Epoch 220/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1727 - accuracy: 0.5629\n",
      "Epoch 221/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1711 - accuracy: 0.5656\n",
      "Epoch 222/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1665 - accuracy: 0.5664\n",
      "Epoch 223/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1682 - accuracy: 0.5659\n",
      "Epoch 224/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1656 - accuracy: 0.5635\n",
      "Epoch 225/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1566 - accuracy: 0.5702\n",
      "Epoch 226/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1783 - accuracy: 0.5641\n",
      "Epoch 227/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1732 - accuracy: 0.5660\n",
      "Epoch 228/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1715 - accuracy: 0.5671\n",
      "Epoch 229/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1719 - accuracy: 0.5657\n",
      "Epoch 230/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1745 - accuracy: 0.5680\n",
      "Epoch 231/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1842 - accuracy: 0.5632\n",
      "Epoch 232/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1623 - accuracy: 0.5677\n",
      "Epoch 233/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1574 - accuracy: 0.5708\n",
      "Epoch 234/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1628 - accuracy: 0.5691\n",
      "Epoch 235/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1637 - accuracy: 0.5696\n",
      "Epoch 236/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1743 - accuracy: 0.5672\n",
      "Epoch 237/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1705 - accuracy: 0.5671\n",
      "Epoch 238/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1745 - accuracy: 0.5660\n",
      "Epoch 239/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1589 - accuracy: 0.5693\n",
      "Epoch 240/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1715 - accuracy: 0.5667\n",
      "Epoch 241/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1684 - accuracy: 0.5693\n",
      "Epoch 242/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1473 - accuracy: 0.5745\n",
      "Epoch 243/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1635 - accuracy: 0.5679\n",
      "Epoch 244/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1686 - accuracy: 0.5684\n",
      "Epoch 245/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1645 - accuracy: 0.5672\n",
      "Epoch 246/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1673 - accuracy: 0.5657\n",
      "Epoch 247/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1574 - accuracy: 0.5716\n",
      "Epoch 248/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1574 - accuracy: 0.5693\n",
      "Epoch 249/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1538 - accuracy: 0.5716\n",
      "Epoch 250/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1631 - accuracy: 0.5707\n",
      "Epoch 251/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1663 - accuracy: 0.5681\n",
      "Epoch 252/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1691 - accuracy: 0.5683\n",
      "Epoch 253/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1580 - accuracy: 0.5703\n",
      "Epoch 254/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1619 - accuracy: 0.5700\n",
      "Epoch 255/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1800 - accuracy: 0.5658\n",
      "Epoch 256/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1509 - accuracy: 0.5706\n",
      "Epoch 257/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1573 - accuracy: 0.5717\n",
      "Epoch 258/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1634 - accuracy: 0.5699\n",
      "Epoch 259/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1648 - accuracy: 0.5702\n",
      "Epoch 260/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1582 - accuracy: 0.5724\n",
      "Epoch 261/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1701 - accuracy: 0.5693\n",
      "Epoch 262/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1631 - accuracy: 0.5682\n",
      "Epoch 263/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1604 - accuracy: 0.5704\n",
      "Epoch 264/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1547 - accuracy: 0.5720\n",
      "Epoch 265/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1552 - accuracy: 0.5724\n",
      "Epoch 266/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1668 - accuracy: 0.5710\n",
      "Epoch 267/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1597 - accuracy: 0.5715\n",
      "Epoch 268/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1538 - accuracy: 0.5724\n",
      "Epoch 269/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1845 - accuracy: 0.5693\n",
      "Epoch 270/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1583 - accuracy: 0.5713\n",
      "Epoch 271/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1553 - accuracy: 0.5735\n",
      "Epoch 272/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1494 - accuracy: 0.5734\n",
      "Epoch 273/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1728 - accuracy: 0.5703\n",
      "Epoch 274/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1553 - accuracy: 0.5713\n",
      "Epoch 275/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1519 - accuracy: 0.5769\n",
      "Epoch 276/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1574 - accuracy: 0.5737\n",
      "Epoch 277/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1680 - accuracy: 0.5706\n",
      "Epoch 278/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1515 - accuracy: 0.5734\n",
      "Epoch 279/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1464 - accuracy: 0.5742\n",
      "Epoch 280/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1732 - accuracy: 0.5702\n",
      "Epoch 281/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1480 - accuracy: 0.5756\n",
      "Epoch 282/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1506 - accuracy: 0.5737\n",
      "Epoch 283/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1531 - accuracy: 0.5759\n",
      "Epoch 284/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1558 - accuracy: 0.5749\n",
      "Epoch 285/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1699 - accuracy: 0.5687\n",
      "Epoch 286/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1469 - accuracy: 0.5770\n",
      "Epoch 287/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1498 - accuracy: 0.5747\n",
      "Epoch 288/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1600 - accuracy: 0.5714\n",
      "Epoch 289/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1468 - accuracy: 0.5766\n",
      "Epoch 290/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1580 - accuracy: 0.5736\n",
      "Epoch 291/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1440 - accuracy: 0.5736\n",
      "Epoch 292/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1450 - accuracy: 0.5763\n",
      "Epoch 293/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1460 - accuracy: 0.5760\n",
      "Epoch 294/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1553 - accuracy: 0.5766\n",
      "Epoch 295/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1601 - accuracy: 0.5729\n",
      "Epoch 296/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1465 - accuracy: 0.5762\n",
      "Epoch 297/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1480 - accuracy: 0.5757\n",
      "Epoch 298/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1544 - accuracy: 0.5742\n",
      "Epoch 299/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1600 - accuracy: 0.5745\n",
      "Epoch 300/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1420 - accuracy: 0.5762\n",
      "Epoch 301/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1486 - accuracy: 0.5758\n",
      "Epoch 302/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1535 - accuracy: 0.5747\n",
      "Epoch 303/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1550 - accuracy: 0.5742\n",
      "Epoch 304/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1500 - accuracy: 0.5748\n",
      "Epoch 305/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1459 - accuracy: 0.5761\n",
      "Epoch 306/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1469 - accuracy: 0.5747\n",
      "Epoch 307/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1586 - accuracy: 0.5739\n",
      "Epoch 308/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1440 - accuracy: 0.5774\n",
      "Epoch 309/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1522 - accuracy: 0.5748\n",
      "Epoch 310/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1419 - accuracy: 0.5761\n",
      "Epoch 311/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1383 - accuracy: 0.5764\n",
      "Epoch 312/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1576 - accuracy: 0.5749\n",
      "Epoch 313/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1475 - accuracy: 0.5751\n",
      "Epoch 314/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1553 - accuracy: 0.5745\n",
      "Epoch 315/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1637 - accuracy: 0.5759\n",
      "Epoch 316/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1362 - accuracy: 0.5790\n",
      "Epoch 317/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1487 - accuracy: 0.5800\n",
      "Epoch 318/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1464 - accuracy: 0.5769\n",
      "Epoch 319/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1369 - accuracy: 0.5772\n",
      "Epoch 320/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1573 - accuracy: 0.5758\n",
      "Epoch 321/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1413 - accuracy: 0.5770\n",
      "Epoch 322/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1382 - accuracy: 0.5787\n",
      "Epoch 323/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1451 - accuracy: 0.5779\n",
      "Epoch 324/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1389 - accuracy: 0.5793\n",
      "Epoch 325/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1528 - accuracy: 0.5747\n",
      "Epoch 326/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1378 - accuracy: 0.5809\n",
      "Epoch 327/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1470 - accuracy: 0.5758\n",
      "Epoch 328/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1382 - accuracy: 0.5780\n",
      "Epoch 329/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1491 - accuracy: 0.5772\n",
      "Epoch 330/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1701 - accuracy: 0.5752\n",
      "Epoch 331/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1294 - accuracy: 0.5800\n",
      "Epoch 332/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1393 - accuracy: 0.5794\n",
      "Epoch 333/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1351 - accuracy: 0.5790\n",
      "Epoch 334/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1531 - accuracy: 0.5768\n",
      "Epoch 335/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1459 - accuracy: 0.5772\n",
      "Epoch 336/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1402 - accuracy: 0.5786\n",
      "Epoch 337/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1436 - accuracy: 0.5767\n",
      "Epoch 338/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1515 - accuracy: 0.5768\n",
      "Epoch 339/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1284 - accuracy: 0.5820\n",
      "Epoch 340/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1539 - accuracy: 0.5765\n",
      "Epoch 341/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1353 - accuracy: 0.5785\n",
      "Epoch 342/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1355 - accuracy: 0.5803\n",
      "Epoch 343/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1504 - accuracy: 0.5754\n",
      "Epoch 344/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1372 - accuracy: 0.5781\n",
      "Epoch 345/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1374 - accuracy: 0.5791\n",
      "Epoch 346/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1549 - accuracy: 0.5756\n",
      "Epoch 347/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1445 - accuracy: 0.5779\n",
      "Epoch 348/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1522 - accuracy: 0.5764\n",
      "Epoch 349/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1392 - accuracy: 0.5807\n",
      "Epoch 350/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1373 - accuracy: 0.5805\n",
      "Epoch 351/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1417 - accuracy: 0.5811\n",
      "Epoch 352/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1381 - accuracy: 0.5779\n",
      "Epoch 353/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1387 - accuracy: 0.5821\n",
      "Epoch 354/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1383 - accuracy: 0.5794\n",
      "Epoch 355/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1341 - accuracy: 0.5830\n",
      "Epoch 356/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1314 - accuracy: 0.5813\n",
      "Epoch 357/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1315 - accuracy: 0.5834\n",
      "Epoch 358/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1309 - accuracy: 0.5814\n",
      "Epoch 359/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1445 - accuracy: 0.5799\n",
      "Epoch 360/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1368 - accuracy: 0.5802\n",
      "Epoch 361/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1228 - accuracy: 0.5815\n",
      "Epoch 362/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1432 - accuracy: 0.5797\n",
      "Epoch 363/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1322 - accuracy: 0.5817\n",
      "Epoch 364/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1351 - accuracy: 0.5805\n",
      "Epoch 365/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1374 - accuracy: 0.5810\n",
      "Epoch 366/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1266 - accuracy: 0.5816\n",
      "Epoch 367/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1356 - accuracy: 0.5802\n",
      "Epoch 368/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1388 - accuracy: 0.5797\n",
      "Epoch 369/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1311 - accuracy: 0.5816\n",
      "Epoch 370/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1319 - accuracy: 0.5809\n",
      "Epoch 371/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1425 - accuracy: 0.5798\n",
      "Epoch 372/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1509 - accuracy: 0.5796\n",
      "Epoch 373/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1318 - accuracy: 0.5798\n",
      "Epoch 374/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1411 - accuracy: 0.5788\n",
      "Epoch 375/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1361 - accuracy: 0.5801\n",
      "Epoch 376/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1272 - accuracy: 0.5833\n",
      "Epoch 377/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1322 - accuracy: 0.5810\n",
      "Epoch 378/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1357 - accuracy: 0.5781\n",
      "Epoch 379/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1263 - accuracy: 0.5826\n",
      "Epoch 380/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1433 - accuracy: 0.5811\n",
      "Epoch 381/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1439 - accuracy: 0.5781\n",
      "Epoch 382/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1338 - accuracy: 0.5796\n",
      "Epoch 383/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1233 - accuracy: 0.5824\n",
      "Epoch 384/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1378 - accuracy: 0.5795\n",
      "Epoch 385/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1229 - accuracy: 0.5825\n",
      "Epoch 386/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1542 - accuracy: 0.5757\n",
      "Epoch 387/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1330 - accuracy: 0.5823\n",
      "Epoch 388/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1346 - accuracy: 0.5813\n",
      "Epoch 389/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1486 - accuracy: 0.5801\n",
      "Epoch 390/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1359 - accuracy: 0.5801\n",
      "Epoch 391/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1451 - accuracy: 0.5791\n",
      "Epoch 392/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1468 - accuracy: 0.5762\n",
      "Epoch 393/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1287 - accuracy: 0.5836\n",
      "Epoch 394/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1458 - accuracy: 0.5775\n",
      "Epoch 395/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1272 - accuracy: 0.5832\n",
      "Epoch 396/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1259 - accuracy: 0.5828\n",
      "Epoch 397/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1275 - accuracy: 0.5835\n",
      "Epoch 398/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1426 - accuracy: 0.5812\n",
      "Epoch 399/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1335 - accuracy: 0.5818\n",
      "Epoch 400/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1290 - accuracy: 0.5828\n",
      "Epoch 401/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1329 - accuracy: 0.5820\n",
      "Epoch 402/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1498 - accuracy: 0.5761\n",
      "Epoch 403/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1267 - accuracy: 0.5832\n",
      "Epoch 404/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1230 - accuracy: 0.5840\n",
      "Epoch 405/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1423 - accuracy: 0.5798\n",
      "Epoch 406/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1255 - accuracy: 0.5825\n",
      "Epoch 407/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1385 - accuracy: 0.5792\n",
      "Epoch 408/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1267 - accuracy: 0.5831\n",
      "Epoch 409/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1347 - accuracy: 0.5804\n",
      "Epoch 410/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1384 - accuracy: 0.5813\n",
      "Epoch 411/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1412 - accuracy: 0.5815\n",
      "Epoch 412/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1308 - accuracy: 0.5838\n",
      "Epoch 413/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1280 - accuracy: 0.5839\n",
      "Epoch 414/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1281 - accuracy: 0.5817\n",
      "Epoch 415/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1413 - accuracy: 0.5823\n",
      "Epoch 416/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1224 - accuracy: 0.5860\n",
      "Epoch 417/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1317 - accuracy: 0.5807\n",
      "Epoch 418/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1513 - accuracy: 0.5806\n",
      "Epoch 419/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1280 - accuracy: 0.5828\n",
      "Epoch 420/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1334 - accuracy: 0.5836\n",
      "Epoch 421/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1355 - accuracy: 0.5798\n",
      "Epoch 422/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1300 - accuracy: 0.5840\n",
      "Epoch 423/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1290 - accuracy: 0.5835\n",
      "Epoch 424/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1254 - accuracy: 0.5849\n",
      "Epoch 425/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1256 - accuracy: 0.5854\n",
      "Epoch 426/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1325 - accuracy: 0.5819\n",
      "Epoch 427/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1266 - accuracy: 0.5803\n",
      "Epoch 428/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1118 - accuracy: 0.5889\n",
      "Epoch 429/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1446 - accuracy: 0.5792\n",
      "Epoch 430/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1317 - accuracy: 0.5822\n",
      "Epoch 431/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1212 - accuracy: 0.5849\n",
      "Epoch 432/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1234 - accuracy: 0.5842\n",
      "Epoch 433/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1231 - accuracy: 0.5856\n",
      "Epoch 434/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1202 - accuracy: 0.5862\n",
      "Epoch 435/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1310 - accuracy: 0.5820\n",
      "Epoch 436/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1220 - accuracy: 0.5851\n",
      "Epoch 437/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1307 - accuracy: 0.5858\n",
      "Epoch 438/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1283 - accuracy: 0.5848\n",
      "Epoch 439/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1257 - accuracy: 0.5875\n",
      "Epoch 440/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1348 - accuracy: 0.5850\n",
      "Epoch 441/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1171 - accuracy: 0.5871\n",
      "Epoch 442/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1193 - accuracy: 0.5875\n",
      "Epoch 443/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1230 - accuracy: 0.5829\n",
      "Epoch 444/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1238 - accuracy: 0.5856\n",
      "Epoch 445/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1358 - accuracy: 0.5820\n",
      "Epoch 446/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1283 - accuracy: 0.5839\n",
      "Epoch 447/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1218 - accuracy: 0.5880\n",
      "Epoch 448/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1287 - accuracy: 0.5856\n",
      "Epoch 449/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1196 - accuracy: 0.5883\n",
      "Epoch 450/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1331 - accuracy: 0.5823\n",
      "Epoch 451/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1321 - accuracy: 0.5838\n",
      "Epoch 452/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1351 - accuracy: 0.5816\n",
      "Epoch 453/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1123 - accuracy: 0.5860\n",
      "Epoch 454/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1203 - accuracy: 0.5868\n",
      "Epoch 455/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1211 - accuracy: 0.5880\n",
      "Epoch 456/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1259 - accuracy: 0.5844\n",
      "Epoch 457/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1247 - accuracy: 0.5868\n",
      "Epoch 458/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1290 - accuracy: 0.5846\n",
      "Epoch 459/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1300 - accuracy: 0.5844\n",
      "Epoch 460/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1138 - accuracy: 0.5861\n",
      "Epoch 461/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1370 - accuracy: 0.5809\n",
      "Epoch 462/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1218 - accuracy: 0.5862\n",
      "Epoch 463/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1277 - accuracy: 0.5854\n",
      "Epoch 464/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1163 - accuracy: 0.5888\n",
      "Epoch 465/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1425 - accuracy: 0.5814\n",
      "Epoch 466/1000\n",
      "2962/2962 [==============================] - 7s 2ms/step - loss: 1.1320 - accuracy: 0.5817\n",
      "Epoch 467/1000\n",
      "2962/2962 [==============================] - 7s 2ms/step - loss: 1.1120 - accuracy: 0.5880\n",
      "Epoch 468/1000\n",
      "2962/2962 [==============================] - 7s 2ms/step - loss: 1.1160 - accuracy: 0.5864\n",
      "Epoch 469/1000\n",
      "2962/2962 [==============================] - 7s 2ms/step - loss: 1.1402 - accuracy: 0.5821\n",
      "Epoch 470/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1299 - accuracy: 0.5841\n",
      "Epoch 471/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1157 - accuracy: 0.5865\n",
      "Epoch 472/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1286 - accuracy: 0.5848\n",
      "Epoch 473/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1154 - accuracy: 0.5872\n",
      "Epoch 474/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1075 - accuracy: 0.5896\n",
      "Epoch 475/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1182 - accuracy: 0.5862\n",
      "Epoch 476/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1200 - accuracy: 0.5872\n",
      "Epoch 477/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1259 - accuracy: 0.5872\n",
      "Epoch 478/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1090 - accuracy: 0.5877\n",
      "Epoch 479/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1194 - accuracy: 0.5862\n",
      "Epoch 480/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1125 - accuracy: 0.5884\n",
      "Epoch 481/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1436 - accuracy: 0.5831\n",
      "Epoch 482/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1305 - accuracy: 0.5828\n",
      "Epoch 483/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1263 - accuracy: 0.5821\n",
      "Epoch 484/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1411 - accuracy: 0.5801\n",
      "Epoch 485/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1282 - accuracy: 0.5814\n",
      "Epoch 486/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1298 - accuracy: 0.5864\n",
      "Epoch 487/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1368 - accuracy: 0.5815\n",
      "Epoch 488/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1148 - accuracy: 0.5880\n",
      "Epoch 489/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1227 - accuracy: 0.5855\n",
      "Epoch 490/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1251 - accuracy: 0.5842\n",
      "Epoch 491/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1176 - accuracy: 0.5846\n",
      "Epoch 492/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1195 - accuracy: 0.5866\n",
      "Epoch 493/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1166 - accuracy: 0.5850\n",
      "Epoch 494/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1184 - accuracy: 0.5859\n",
      "Epoch 495/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1333 - accuracy: 0.5845\n",
      "Epoch 496/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1197 - accuracy: 0.5867\n",
      "Epoch 497/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1144 - accuracy: 0.5862\n",
      "Epoch 498/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1145 - accuracy: 0.5900\n",
      "Epoch 499/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1081 - accuracy: 0.5909\n",
      "Epoch 500/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1351 - accuracy: 0.5830\n",
      "Epoch 501/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1376 - accuracy: 0.5830\n",
      "Epoch 502/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1206 - accuracy: 0.5860\n",
      "Epoch 503/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1177 - accuracy: 0.5868\n",
      "Epoch 504/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1350 - accuracy: 0.5799\n",
      "Epoch 505/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1214 - accuracy: 0.5883\n",
      "Epoch 506/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1153 - accuracy: 0.5858\n",
      "Epoch 507/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1252 - accuracy: 0.5846\n",
      "Epoch 508/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1329 - accuracy: 0.5824\n",
      "Epoch 509/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1044 - accuracy: 0.5892\n",
      "Epoch 510/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1269 - accuracy: 0.5856\n",
      "Epoch 511/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1166 - accuracy: 0.5874\n",
      "Epoch 512/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1304 - accuracy: 0.5855\n",
      "Epoch 513/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1118 - accuracy: 0.5861\n",
      "Epoch 514/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1102 - accuracy: 0.5890\n",
      "Epoch 515/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1236 - accuracy: 0.5866\n",
      "Epoch 516/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1333 - accuracy: 0.5842\n",
      "Epoch 517/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1134 - accuracy: 0.5869\n",
      "Epoch 518/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1143 - accuracy: 0.5867\n",
      "Epoch 519/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1504 - accuracy: 0.5802\n",
      "Epoch 520/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1186 - accuracy: 0.5840\n",
      "Epoch 521/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1141 - accuracy: 0.5875\n",
      "Epoch 522/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1184 - accuracy: 0.5873\n",
      "Epoch 523/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1269 - accuracy: 0.5841\n",
      "Epoch 524/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1148 - accuracy: 0.5878\n",
      "Epoch 525/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1170 - accuracy: 0.5888\n",
      "Epoch 526/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1201 - accuracy: 0.5874\n",
      "Epoch 527/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1290 - accuracy: 0.5835\n",
      "Epoch 528/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1097 - accuracy: 0.5894\n",
      "Epoch 529/1000\n",
      "2962/2962 [==============================] - 7s 2ms/step - loss: 1.1176 - accuracy: 0.5881\n",
      "Epoch 530/1000\n",
      "2962/2962 [==============================] - 7s 2ms/step - loss: 1.1241 - accuracy: 0.5874\n",
      "Epoch 531/1000\n",
      "2962/2962 [==============================] - 8s 3ms/step - loss: 1.1233 - accuracy: 0.5838\n",
      "Epoch 532/1000\n",
      "2962/2962 [==============================] - 8s 3ms/step - loss: 1.1333 - accuracy: 0.5855\n",
      "Epoch 533/1000\n",
      "2962/2962 [==============================] - 9s 3ms/step - loss: 1.1248 - accuracy: 0.5857\n",
      "Epoch 534/1000\n",
      "2962/2962 [==============================] - 12s 4ms/step - loss: 1.1100 - accuracy: 0.5880\n",
      "Epoch 535/1000\n",
      "2962/2962 [==============================] - 9s 3ms/step - loss: 1.1199 - accuracy: 0.5872\n",
      "Epoch 536/1000\n",
      "2962/2962 [==============================] - 8s 3ms/step - loss: 1.1138 - accuracy: 0.5879\n",
      "Epoch 537/1000\n",
      "2962/2962 [==============================] - 7s 3ms/step - loss: 1.1046 - accuracy: 0.5906\n",
      "Epoch 538/1000\n",
      "2962/2962 [==============================] - 8s 3ms/step - loss: 1.1121 - accuracy: 0.5875\n",
      "Epoch 539/1000\n",
      "2962/2962 [==============================] - 8s 3ms/step - loss: 1.1141 - accuracy: 0.5890\n",
      "Epoch 540/1000\n",
      "2962/2962 [==============================] - 8s 3ms/step - loss: 1.1109 - accuracy: 0.5880\n",
      "Epoch 541/1000\n",
      "2962/2962 [==============================] - 7s 2ms/step - loss: 1.1248 - accuracy: 0.5868\n",
      "Epoch 542/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1201 - accuracy: 0.5865\n",
      "Epoch 543/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1175 - accuracy: 0.5850\n",
      "Epoch 544/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1180 - accuracy: 0.5846\n",
      "Epoch 545/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1360 - accuracy: 0.5833\n",
      "Epoch 546/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1066 - accuracy: 0.5872\n",
      "Epoch 547/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1192 - accuracy: 0.5889\n",
      "Epoch 548/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1225 - accuracy: 0.5861\n",
      "Epoch 549/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1061 - accuracy: 0.5884\n",
      "Epoch 550/1000\n",
      "2962/2962 [==============================] - 7s 2ms/step - loss: 1.1083 - accuracy: 0.5867\n",
      "Epoch 551/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1214 - accuracy: 0.5860\n",
      "Epoch 552/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1298 - accuracy: 0.5860\n",
      "Epoch 553/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1172 - accuracy: 0.5867\n",
      "Epoch 554/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1105 - accuracy: 0.5880\n",
      "Epoch 555/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1256 - accuracy: 0.5882\n",
      "Epoch 556/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1208 - accuracy: 0.5880\n",
      "Epoch 557/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1255 - accuracy: 0.5872\n",
      "Epoch 558/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1305 - accuracy: 0.5829\n",
      "Epoch 559/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1103 - accuracy: 0.5886\n",
      "Epoch 560/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1274 - accuracy: 0.5828\n",
      "Epoch 561/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1219 - accuracy: 0.5844\n",
      "Epoch 562/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1181 - accuracy: 0.5839\n",
      "Epoch 563/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1102 - accuracy: 0.5882\n",
      "Epoch 564/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1165 - accuracy: 0.5880\n",
      "Epoch 565/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1345 - accuracy: 0.5817\n",
      "Epoch 566/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1295 - accuracy: 0.5848\n",
      "Epoch 567/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1168 - accuracy: 0.5858\n",
      "Epoch 568/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1287 - accuracy: 0.5847\n",
      "Epoch 569/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1095 - accuracy: 0.5878\n",
      "Epoch 570/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1058 - accuracy: 0.5894\n",
      "Epoch 571/1000\n",
      "2962/2962 [==============================] - 7s 2ms/step - loss: 1.1302 - accuracy: 0.5871\n",
      "Epoch 572/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1121 - accuracy: 0.5881\n",
      "Epoch 573/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1163 - accuracy: 0.5860\n",
      "Epoch 574/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1386 - accuracy: 0.5816\n",
      "Epoch 575/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1040 - accuracy: 0.5899\n",
      "Epoch 576/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1127 - accuracy: 0.5885\n",
      "Epoch 577/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1236 - accuracy: 0.5840\n",
      "Epoch 578/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1187 - accuracy: 0.5889\n",
      "Epoch 579/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1128 - accuracy: 0.5879\n",
      "Epoch 580/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1031 - accuracy: 0.5909\n",
      "Epoch 581/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1207 - accuracy: 0.5873\n",
      "Epoch 582/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1160 - accuracy: 0.5890\n",
      "Epoch 583/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1260 - accuracy: 0.5861\n",
      "Epoch 584/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1213 - accuracy: 0.5865\n",
      "Epoch 585/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1132 - accuracy: 0.5891\n",
      "Epoch 586/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1053 - accuracy: 0.5888\n",
      "Epoch 587/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1456 - accuracy: 0.5825\n",
      "Epoch 588/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1163 - accuracy: 0.5869\n",
      "Epoch 589/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1286 - accuracy: 0.5855\n",
      "Epoch 590/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1244 - accuracy: 0.5831\n",
      "Epoch 591/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1133 - accuracy: 0.5888\n",
      "Epoch 592/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1225 - accuracy: 0.5850\n",
      "Epoch 593/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1097 - accuracy: 0.5878\n",
      "Epoch 594/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1304 - accuracy: 0.5848\n",
      "Epoch 595/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1361 - accuracy: 0.5838\n",
      "Epoch 596/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1162 - accuracy: 0.5876\n",
      "Epoch 597/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1081 - accuracy: 0.5890\n",
      "Epoch 598/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1247 - accuracy: 0.5877\n",
      "Epoch 599/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1137 - accuracy: 0.5887\n",
      "Epoch 600/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1134 - accuracy: 0.5884\n",
      "Epoch 601/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1214 - accuracy: 0.5895\n",
      "Epoch 602/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1150 - accuracy: 0.5916\n",
      "Epoch 603/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1432 - accuracy: 0.5841\n",
      "Epoch 604/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1028 - accuracy: 0.5922\n",
      "Epoch 605/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1133 - accuracy: 0.5898\n",
      "Epoch 606/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1162 - accuracy: 0.5874\n",
      "Epoch 607/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1163 - accuracy: 0.5880\n",
      "Epoch 608/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1253 - accuracy: 0.5884\n",
      "Epoch 609/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1308 - accuracy: 0.5852\n",
      "Epoch 610/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1186 - accuracy: 0.5872\n",
      "Epoch 611/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1095 - accuracy: 0.5889\n",
      "Epoch 612/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1257 - accuracy: 0.5897\n",
      "Epoch 613/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1073 - accuracy: 0.5900\n",
      "Epoch 614/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1213 - accuracy: 0.5866\n",
      "Epoch 615/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1248 - accuracy: 0.5889\n",
      "Epoch 616/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1200 - accuracy: 0.5872\n",
      "Epoch 617/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1014 - accuracy: 0.5902\n",
      "Epoch 618/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1192 - accuracy: 0.5868\n",
      "Epoch 619/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1055 - accuracy: 0.5899\n",
      "Epoch 620/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1211 - accuracy: 0.5889\n",
      "Epoch 621/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1116 - accuracy: 0.5894\n",
      "Epoch 622/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1199 - accuracy: 0.5872\n",
      "Epoch 623/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1092 - accuracy: 0.5901\n",
      "Epoch 624/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1094 - accuracy: 0.5882\n",
      "Epoch 625/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1343 - accuracy: 0.5843\n",
      "Epoch 626/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1118 - accuracy: 0.5894\n",
      "Epoch 627/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1314 - accuracy: 0.5848\n",
      "Epoch 628/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1241 - accuracy: 0.5886\n",
      "Epoch 629/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1140 - accuracy: 0.5880\n",
      "Epoch 630/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1109 - accuracy: 0.5884\n",
      "Epoch 631/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1244 - accuracy: 0.5884\n",
      "Epoch 632/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1271 - accuracy: 0.5858\n",
      "Epoch 633/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1210 - accuracy: 0.5886\n",
      "Epoch 634/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1238 - accuracy: 0.5855\n",
      "Epoch 635/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1137 - accuracy: 0.5858\n",
      "Epoch 636/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1299 - accuracy: 0.5886\n",
      "Epoch 637/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1077 - accuracy: 0.5877\n",
      "Epoch 638/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1160 - accuracy: 0.5873\n",
      "Epoch 639/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1510 - accuracy: 0.5829\n",
      "Epoch 640/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1029 - accuracy: 0.5894\n",
      "Epoch 641/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1216 - accuracy: 0.5874\n",
      "Epoch 642/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1479 - accuracy: 0.5805\n",
      "Epoch 643/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1138 - accuracy: 0.5882\n",
      "Epoch 644/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1126 - accuracy: 0.5885\n",
      "Epoch 645/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1192 - accuracy: 0.5881\n",
      "Epoch 646/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1058 - accuracy: 0.5899\n",
      "Epoch 647/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1221 - accuracy: 0.5885\n",
      "Epoch 648/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1270 - accuracy: 0.5841\n",
      "Epoch 649/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1086 - accuracy: 0.5901\n",
      "Epoch 650/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1203 - accuracy: 0.5882\n",
      "Epoch 651/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1116 - accuracy: 0.5855\n",
      "Epoch 652/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1155 - accuracy: 0.5892\n",
      "Epoch 653/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1343 - accuracy: 0.5863\n",
      "Epoch 654/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1046 - accuracy: 0.5890\n",
      "Epoch 655/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1075 - accuracy: 0.5885\n",
      "Epoch 656/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1269 - accuracy: 0.5841\n",
      "Epoch 657/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1336 - accuracy: 0.5847\n",
      "Epoch 658/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1089 - accuracy: 0.5882\n",
      "Epoch 659/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1388 - accuracy: 0.5819\n",
      "Epoch 660/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1227 - accuracy: 0.5894\n",
      "Epoch 661/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1155 - accuracy: 0.5871\n",
      "Epoch 662/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1134 - accuracy: 0.5889\n",
      "Epoch 663/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1127 - accuracy: 0.5884\n",
      "Epoch 664/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1211 - accuracy: 0.5854\n",
      "Epoch 665/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1340 - accuracy: 0.5845\n",
      "Epoch 666/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1140 - accuracy: 0.5871\n",
      "Epoch 667/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1229 - accuracy: 0.5878\n",
      "Epoch 668/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1226 - accuracy: 0.5894\n",
      "Epoch 669/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1018 - accuracy: 0.5889\n",
      "Epoch 670/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1073 - accuracy: 0.5893\n",
      "Epoch 671/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1123 - accuracy: 0.5887\n",
      "Epoch 672/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1272 - accuracy: 0.5842\n",
      "Epoch 673/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1090 - accuracy: 0.5896\n",
      "Epoch 674/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1151 - accuracy: 0.5889\n",
      "Epoch 675/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1166 - accuracy: 0.5886\n",
      "Epoch 676/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1287 - accuracy: 0.5845\n",
      "Epoch 677/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1065 - accuracy: 0.5924\n",
      "Epoch 678/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1188 - accuracy: 0.5891\n",
      "Epoch 679/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1357 - accuracy: 0.5859\n",
      "Epoch 680/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1101 - accuracy: 0.5887\n",
      "Epoch 681/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1138 - accuracy: 0.5905\n",
      "Epoch 682/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1144 - accuracy: 0.5880\n",
      "Epoch 683/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1169 - accuracy: 0.5882\n",
      "Epoch 684/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1116 - accuracy: 0.5884\n",
      "Epoch 685/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1154 - accuracy: 0.5886\n",
      "Epoch 686/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1164 - accuracy: 0.5875\n",
      "Epoch 687/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1205 - accuracy: 0.5855\n",
      "Epoch 688/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1261 - accuracy: 0.5853\n",
      "Epoch 689/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.0978 - accuracy: 0.5891\n",
      "Epoch 690/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1198 - accuracy: 0.5881\n",
      "Epoch 691/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1236 - accuracy: 0.5849\n",
      "Epoch 692/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1256 - accuracy: 0.5854\n",
      "Epoch 693/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1164 - accuracy: 0.5859\n",
      "Epoch 694/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1098 - accuracy: 0.5904\n",
      "Epoch 695/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1134 - accuracy: 0.5876\n",
      "Epoch 696/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1143 - accuracy: 0.5856\n",
      "Epoch 697/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1095 - accuracy: 0.5866\n",
      "Epoch 698/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1153 - accuracy: 0.5881\n",
      "Epoch 699/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.0987 - accuracy: 0.5917\n",
      "Epoch 700/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1144 - accuracy: 0.5887\n",
      "Epoch 701/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1494 - accuracy: 0.5805\n",
      "Epoch 702/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.0985 - accuracy: 0.5892\n",
      "Epoch 703/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1126 - accuracy: 0.5881\n",
      "Epoch 704/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1184 - accuracy: 0.5899\n",
      "Epoch 705/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1209 - accuracy: 0.5874\n",
      "Epoch 706/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1020 - accuracy: 0.5914\n",
      "Epoch 707/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1219 - accuracy: 0.5865\n",
      "Epoch 708/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1148 - accuracy: 0.5893\n",
      "Epoch 709/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1285 - accuracy: 0.5860\n",
      "Epoch 710/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1226 - accuracy: 0.5853\n",
      "Epoch 711/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1013 - accuracy: 0.5898\n",
      "Epoch 712/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1252 - accuracy: 0.5865\n",
      "Epoch 713/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1183 - accuracy: 0.5855\n",
      "Epoch 714/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1322 - accuracy: 0.5857\n",
      "Epoch 715/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1225 - accuracy: 0.5877\n",
      "Epoch 716/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1097 - accuracy: 0.5900\n",
      "Epoch 717/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1227 - accuracy: 0.5866\n",
      "Epoch 718/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1260 - accuracy: 0.5867\n",
      "Epoch 719/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1212 - accuracy: 0.5868\n",
      "Epoch 720/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1015 - accuracy: 0.5905\n",
      "Epoch 721/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1199 - accuracy: 0.5856\n",
      "Epoch 722/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1247 - accuracy: 0.5858\n",
      "Epoch 723/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1292 - accuracy: 0.5851\n",
      "Epoch 724/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1359 - accuracy: 0.5828\n",
      "Epoch 725/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1130 - accuracy: 0.5876\n",
      "Epoch 726/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1141 - accuracy: 0.5877\n",
      "Epoch 727/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1143 - accuracy: 0.5889\n",
      "Epoch 728/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1098 - accuracy: 0.5903\n",
      "Epoch 729/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1226 - accuracy: 0.5870\n",
      "Epoch 730/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1133 - accuracy: 0.5913\n",
      "Epoch 731/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1137 - accuracy: 0.5896\n",
      "Epoch 732/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1233 - accuracy: 0.5862\n",
      "Epoch 733/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1060 - accuracy: 0.5894\n",
      "Epoch 734/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1123 - accuracy: 0.5912\n",
      "Epoch 735/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1253 - accuracy: 0.5850\n",
      "Epoch 736/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1191 - accuracy: 0.5878\n",
      "Epoch 737/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1154 - accuracy: 0.5866\n",
      "Epoch 738/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1216 - accuracy: 0.5871\n",
      "Epoch 739/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1085 - accuracy: 0.5886\n",
      "Epoch 740/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1178 - accuracy: 0.5876\n",
      "Epoch 741/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1097 - accuracy: 0.5885\n",
      "Epoch 742/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1120 - accuracy: 0.5894\n",
      "Epoch 743/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1198 - accuracy: 0.5878\n",
      "Epoch 744/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1199 - accuracy: 0.5867\n",
      "Epoch 745/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1238 - accuracy: 0.5871\n",
      "Epoch 746/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1347 - accuracy: 0.5847\n",
      "Epoch 747/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1131 - accuracy: 0.5878\n",
      "Epoch 748/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1138 - accuracy: 0.5866\n",
      "Epoch 749/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1261 - accuracy: 0.5874\n",
      "Epoch 750/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1158 - accuracy: 0.5861\n",
      "Epoch 751/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1054 - accuracy: 0.5904\n",
      "Epoch 752/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1202 - accuracy: 0.5878\n",
      "Epoch 753/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1113 - accuracy: 0.5885\n",
      "Epoch 754/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1054 - accuracy: 0.5897\n",
      "Epoch 755/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1190 - accuracy: 0.5894\n",
      "Epoch 756/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1084 - accuracy: 0.5890\n",
      "Epoch 757/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1191 - accuracy: 0.5862\n",
      "Epoch 758/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1246 - accuracy: 0.5863\n",
      "Epoch 759/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1121 - accuracy: 0.5862\n",
      "Epoch 760/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1109 - accuracy: 0.5892\n",
      "Epoch 761/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1221 - accuracy: 0.5855\n",
      "Epoch 762/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1204 - accuracy: 0.5876\n",
      "Epoch 763/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1101 - accuracy: 0.5873\n",
      "Epoch 764/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.0994 - accuracy: 0.5908\n",
      "Epoch 765/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1172 - accuracy: 0.5885\n",
      "Epoch 766/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1352 - accuracy: 0.5846\n",
      "Epoch 767/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1064 - accuracy: 0.5901\n",
      "Epoch 768/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1102 - accuracy: 0.5889\n",
      "Epoch 769/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1143 - accuracy: 0.5873\n",
      "Epoch 770/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1103 - accuracy: 0.5899\n",
      "Epoch 771/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1349 - accuracy: 0.5825\n",
      "Epoch 772/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.0979 - accuracy: 0.5911\n",
      "Epoch 773/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1174 - accuracy: 0.5886\n",
      "Epoch 774/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1040 - accuracy: 0.5906\n",
      "Epoch 775/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1169 - accuracy: 0.5893\n",
      "Epoch 776/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1197 - accuracy: 0.5867\n",
      "Epoch 777/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1211 - accuracy: 0.5844\n",
      "Epoch 778/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1231 - accuracy: 0.5877\n",
      "Epoch 779/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1045 - accuracy: 0.5894\n",
      "Epoch 780/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1238 - accuracy: 0.5886\n",
      "Epoch 781/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1284 - accuracy: 0.5883\n",
      "Epoch 782/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1023 - accuracy: 0.5896\n",
      "Epoch 783/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1286 - accuracy: 0.5882\n",
      "Epoch 784/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1271 - accuracy: 0.5824\n",
      "Epoch 785/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1188 - accuracy: 0.5877\n",
      "Epoch 786/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1309 - accuracy: 0.5829\n",
      "Epoch 787/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1732 - accuracy: 0.5845\n",
      "Epoch 788/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1106 - accuracy: 0.5872\n",
      "Epoch 789/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1246 - accuracy: 0.5862\n",
      "Epoch 790/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1166 - accuracy: 0.5881\n",
      "Epoch 791/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1184 - accuracy: 0.5862\n",
      "Epoch 792/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1220 - accuracy: 0.5853\n",
      "Epoch 793/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1337 - accuracy: 0.5843\n",
      "Epoch 794/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1080 - accuracy: 0.5891\n",
      "Epoch 795/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1005 - accuracy: 0.5905\n",
      "Epoch 796/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1001 - accuracy: 0.5906\n",
      "Epoch 797/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1319 - accuracy: 0.5856\n",
      "Epoch 798/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1260 - accuracy: 0.5872\n",
      "Epoch 799/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1139 - accuracy: 0.5872\n",
      "Epoch 800/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1418 - accuracy: 0.5860\n",
      "Epoch 801/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1132 - accuracy: 0.5870\n",
      "Epoch 802/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1284 - accuracy: 0.5870\n",
      "Epoch 803/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1204 - accuracy: 0.5863\n",
      "Epoch 804/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1125 - accuracy: 0.5899\n",
      "Epoch 805/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1038 - accuracy: 0.5890\n",
      "Epoch 806/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1291 - accuracy: 0.5848\n",
      "Epoch 807/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1053 - accuracy: 0.5906\n",
      "Epoch 808/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1141 - accuracy: 0.5891\n",
      "Epoch 809/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1258 - accuracy: 0.5854\n",
      "Epoch 810/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1101 - accuracy: 0.5902\n",
      "Epoch 811/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1229 - accuracy: 0.5867\n",
      "Epoch 812/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1276 - accuracy: 0.5856\n",
      "Epoch 813/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1150 - accuracy: 0.5877\n",
      "Epoch 814/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1197 - accuracy: 0.5851\n",
      "Epoch 815/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1253 - accuracy: 0.5854\n",
      "Epoch 816/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1184 - accuracy: 0.5877\n",
      "Epoch 817/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1233 - accuracy: 0.5879\n",
      "Epoch 818/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1103 - accuracy: 0.5887\n",
      "Epoch 819/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1224 - accuracy: 0.5858\n",
      "Epoch 820/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1129 - accuracy: 0.5880\n",
      "Epoch 821/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1335 - accuracy: 0.5855\n",
      "Epoch 822/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1308 - accuracy: 0.5859\n",
      "Epoch 823/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1055 - accuracy: 0.5882\n",
      "Epoch 824/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1145 - accuracy: 0.5887\n",
      "Epoch 825/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1334 - accuracy: 0.5852\n",
      "Epoch 826/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1333 - accuracy: 0.5877\n",
      "Epoch 827/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1349 - accuracy: 0.5833\n",
      "Epoch 828/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1038 - accuracy: 0.5896\n",
      "Epoch 829/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1218 - accuracy: 0.5863\n",
      "Epoch 830/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1086 - accuracy: 0.5896\n",
      "Epoch 831/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1303 - accuracy: 0.5843\n",
      "Epoch 832/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1028 - accuracy: 0.5906\n",
      "Epoch 833/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1458 - accuracy: 0.5846\n",
      "Epoch 834/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1241 - accuracy: 0.5853\n",
      "Epoch 835/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1088 - accuracy: 0.5886\n",
      "Epoch 836/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1191 - accuracy: 0.5885\n",
      "Epoch 837/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1049 - accuracy: 0.5891\n",
      "Epoch 838/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1254 - accuracy: 0.5839\n",
      "Epoch 839/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1101 - accuracy: 0.5862\n",
      "Epoch 840/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1096 - accuracy: 0.5896\n",
      "Epoch 841/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1317 - accuracy: 0.5856\n",
      "Epoch 842/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1188 - accuracy: 0.5866\n",
      "Epoch 843/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1187 - accuracy: 0.5870\n",
      "Epoch 844/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1344 - accuracy: 0.5831\n",
      "Epoch 845/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1188 - accuracy: 0.5872\n",
      "Epoch 846/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1301 - accuracy: 0.5830\n",
      "Epoch 847/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1148 - accuracy: 0.5893\n",
      "Epoch 848/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1184 - accuracy: 0.5880\n",
      "Epoch 849/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1168 - accuracy: 0.5870\n",
      "Epoch 850/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1074 - accuracy: 0.5865\n",
      "Epoch 851/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1352 - accuracy: 0.5876\n",
      "Epoch 852/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1275 - accuracy: 0.5855\n",
      "Epoch 853/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1135 - accuracy: 0.5858\n",
      "Epoch 854/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1241 - accuracy: 0.5871\n",
      "Epoch 855/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1364 - accuracy: 0.5853\n",
      "Epoch 856/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1227 - accuracy: 0.5860\n",
      "Epoch 857/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1326 - accuracy: 0.5854\n",
      "Epoch 858/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1052 - accuracy: 0.5885\n",
      "Epoch 859/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1108 - accuracy: 0.5903\n",
      "Epoch 860/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1202 - accuracy: 0.5878\n",
      "Epoch 861/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1090 - accuracy: 0.5874\n",
      "Epoch 862/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1065 - accuracy: 0.5896\n",
      "Epoch 863/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1105 - accuracy: 0.5873\n",
      "Epoch 864/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1258 - accuracy: 0.5871\n",
      "Epoch 865/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1251 - accuracy: 0.5864\n",
      "Epoch 866/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1248 - accuracy: 0.5858\n",
      "Epoch 867/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1059 - accuracy: 0.5884\n",
      "Epoch 868/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1265 - accuracy: 0.5869\n",
      "Epoch 869/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1367 - accuracy: 0.5849\n",
      "Epoch 870/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1233 - accuracy: 0.5818\n",
      "Epoch 871/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1049 - accuracy: 0.5871\n",
      "Epoch 872/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1323 - accuracy: 0.5850\n",
      "Epoch 873/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.0987 - accuracy: 0.5900\n",
      "Epoch 874/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1382 - accuracy: 0.5830\n",
      "Epoch 875/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1070 - accuracy: 0.5866\n",
      "Epoch 876/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1266 - accuracy: 0.5851\n",
      "Epoch 877/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1255 - accuracy: 0.5848\n",
      "Epoch 878/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1230 - accuracy: 0.5849\n",
      "Epoch 879/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1127 - accuracy: 0.5873\n",
      "Epoch 880/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1375 - accuracy: 0.5841\n",
      "Epoch 881/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1338 - accuracy: 0.5842\n",
      "Epoch 882/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1302 - accuracy: 0.5831\n",
      "Epoch 883/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1287 - accuracy: 0.5827\n",
      "Epoch 884/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1222 - accuracy: 0.5860\n",
      "Epoch 885/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1226 - accuracy: 0.5865\n",
      "Epoch 886/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1262 - accuracy: 0.5863\n",
      "Epoch 887/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1183 - accuracy: 0.5877\n",
      "Epoch 888/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1256 - accuracy: 0.5857\n",
      "Epoch 889/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1159 - accuracy: 0.5886\n",
      "Epoch 890/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1249 - accuracy: 0.5861\n",
      "Epoch 891/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1181 - accuracy: 0.5862\n",
      "Epoch 892/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1200 - accuracy: 0.5858\n",
      "Epoch 893/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1184 - accuracy: 0.5864\n",
      "Epoch 894/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1001 - accuracy: 0.5918\n",
      "Epoch 895/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1092 - accuracy: 0.5897\n",
      "Epoch 896/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1232 - accuracy: 0.5853\n",
      "Epoch 897/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1304 - accuracy: 0.5850\n",
      "Epoch 898/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1289 - accuracy: 0.5830\n",
      "Epoch 899/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1199 - accuracy: 0.5871\n",
      "Epoch 900/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1156 - accuracy: 0.5870\n",
      "Epoch 901/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1259 - accuracy: 0.5844\n",
      "Epoch 902/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1085 - accuracy: 0.5898\n",
      "Epoch 903/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1268 - accuracy: 0.5834\n",
      "Epoch 904/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1424 - accuracy: 0.5838\n",
      "Epoch 905/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1220 - accuracy: 0.5858\n",
      "Epoch 906/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1096 - accuracy: 0.5891\n",
      "Epoch 907/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1282 - accuracy: 0.5864\n",
      "Epoch 908/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1123 - accuracy: 0.5893\n",
      "Epoch 909/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1270 - accuracy: 0.5835\n",
      "Epoch 910/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1241 - accuracy: 0.5855\n",
      "Epoch 911/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1032 - accuracy: 0.5891\n",
      "Epoch 912/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1264 - accuracy: 0.5868\n",
      "Epoch 913/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1142 - accuracy: 0.5868\n",
      "Epoch 914/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1162 - accuracy: 0.5874\n",
      "Epoch 915/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1338 - accuracy: 0.5865\n",
      "Epoch 916/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1106 - accuracy: 0.5897\n",
      "Epoch 917/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1119 - accuracy: 0.5881\n",
      "Epoch 918/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1232 - accuracy: 0.5860\n",
      "Epoch 919/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1108 - accuracy: 0.5876\n",
      "Epoch 920/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1348 - accuracy: 0.5850\n",
      "Epoch 921/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1282 - accuracy: 0.5869\n",
      "Epoch 922/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1242 - accuracy: 0.5855\n",
      "Epoch 923/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1008 - accuracy: 0.5896\n",
      "Epoch 924/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1354 - accuracy: 0.5828\n",
      "Epoch 925/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1479 - accuracy: 0.5825\n",
      "Epoch 926/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1266 - accuracy: 0.5861\n",
      "Epoch 927/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1220 - accuracy: 0.5859\n",
      "Epoch 928/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1115 - accuracy: 0.5866\n",
      "Epoch 929/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1113 - accuracy: 0.5879\n",
      "Epoch 930/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1035 - accuracy: 0.5893\n",
      "Epoch 931/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1291 - accuracy: 0.5866\n",
      "Epoch 932/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1114 - accuracy: 0.5877\n",
      "Epoch 933/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1106 - accuracy: 0.5901\n",
      "Epoch 934/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1255 - accuracy: 0.5860\n",
      "Epoch 935/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1148 - accuracy: 0.5871\n",
      "Epoch 936/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1374 - accuracy: 0.5832\n",
      "Epoch 937/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1013 - accuracy: 0.5908\n",
      "Epoch 938/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1249 - accuracy: 0.5827\n",
      "Epoch 939/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1301 - accuracy: 0.5864\n",
      "Epoch 940/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1166 - accuracy: 0.5870\n",
      "Epoch 941/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1265 - accuracy: 0.5860\n",
      "Epoch 942/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.0976 - accuracy: 0.5922\n",
      "Epoch 943/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1176 - accuracy: 0.5851\n",
      "Epoch 944/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1178 - accuracy: 0.5858\n",
      "Epoch 945/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1267 - accuracy: 0.5870\n",
      "Epoch 946/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1236 - accuracy: 0.5829\n",
      "Epoch 947/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1156 - accuracy: 0.5884\n",
      "Epoch 948/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1110 - accuracy: 0.5892\n",
      "Epoch 949/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1298 - accuracy: 0.5854\n",
      "Epoch 950/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1110 - accuracy: 0.5865\n",
      "Epoch 951/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1211 - accuracy: 0.5864\n",
      "Epoch 952/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1233 - accuracy: 0.5867\n",
      "Epoch 953/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1087 - accuracy: 0.5885\n",
      "Epoch 954/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1385 - accuracy: 0.5827\n",
      "Epoch 955/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1209 - accuracy: 0.5834\n",
      "Epoch 956/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1137 - accuracy: 0.5858\n",
      "Epoch 957/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1107 - accuracy: 0.5874\n",
      "Epoch 958/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1309 - accuracy: 0.5862\n",
      "Epoch 959/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1191 - accuracy: 0.5849\n",
      "Epoch 960/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1447 - accuracy: 0.5802\n",
      "Epoch 961/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1191 - accuracy: 0.5890\n",
      "Epoch 962/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1243 - accuracy: 0.5880\n",
      "Epoch 963/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1361 - accuracy: 0.5835\n",
      "Epoch 964/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1067 - accuracy: 0.5884\n",
      "Epoch 965/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1023 - accuracy: 0.5906\n",
      "Epoch 966/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1204 - accuracy: 0.5861\n",
      "Epoch 967/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1323 - accuracy: 0.5855\n",
      "Epoch 968/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1277 - accuracy: 0.5847\n",
      "Epoch 969/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1200 - accuracy: 0.5845\n",
      "Epoch 970/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1444 - accuracy: 0.5840\n",
      "Epoch 971/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1209 - accuracy: 0.5867\n",
      "Epoch 972/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1209 - accuracy: 0.5858\n",
      "Epoch 973/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1187 - accuracy: 0.5864\n",
      "Epoch 974/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1312 - accuracy: 0.5848\n",
      "Epoch 975/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1222 - accuracy: 0.5870\n",
      "Epoch 976/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1258 - accuracy: 0.5845\n",
      "Epoch 977/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1196 - accuracy: 0.5842\n",
      "Epoch 978/1000\n",
      "2962/2962 [==============================] - 6s 2ms/step - loss: 1.1317 - accuracy: 0.5836\n",
      "Epoch 979/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1146 - accuracy: 0.5861\n",
      "Epoch 980/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1189 - accuracy: 0.5886\n",
      "Epoch 981/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1291 - accuracy: 0.5840\n",
      "Epoch 982/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1416 - accuracy: 0.5817\n",
      "Epoch 983/1000\n",
      "2962/2962 [==============================] - 5s 2ms/step - loss: 1.1430 - accuracy: 0.5847\n",
      "Epoch 984/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1156 - accuracy: 0.5866\n",
      "Epoch 985/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1307 - accuracy: 0.5832\n",
      "Epoch 986/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1175 - accuracy: 0.5845\n",
      "Epoch 987/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1040 - accuracy: 0.5886\n",
      "Epoch 988/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1331 - accuracy: 0.5841\n",
      "Epoch 989/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1140 - accuracy: 0.5879\n",
      "Epoch 990/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1291 - accuracy: 0.5851\n",
      "Epoch 991/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1324 - accuracy: 0.5825\n",
      "Epoch 992/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1454 - accuracy: 0.5827\n",
      "Epoch 993/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1270 - accuracy: 0.5836\n",
      "Epoch 994/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1311 - accuracy: 0.5838\n",
      "Epoch 995/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1198 - accuracy: 0.5836\n",
      "Epoch 996/1000\n",
      "2962/2962 [==============================] - 4s 2ms/step - loss: 1.1101 - accuracy: 0.5886\n",
      "Epoch 997/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1274 - accuracy: 0.5835\n",
      "Epoch 998/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1188 - accuracy: 0.5858\n",
      "Epoch 999/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1409 - accuracy: 0.5825\n",
      "Epoch 1000/1000\n",
      "2962/2962 [==============================] - 4s 1ms/step - loss: 1.1181 - accuracy: 0.5862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f053eb653c8>"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Initialising the ANN\n",
    "model = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "model.add(Dense(32, activation = 'relu', input_dim = 48))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "model.add(Dense(units = 32, activation = 'relu'))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "model.add(Dense(units = 32, activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "\n",
    "model.add(Dense(units = 1,activation='sigmoid'))\n",
    "\n",
    "#model.add(Dense(1))\n",
    "# Compiling the ANN\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model.fit(X_train, y_train, batch_size = 10,class_weight=weights_assigned, epochs = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "nNFwixX9EHnQ"
   },
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8nk5OJZFEDP",
    "outputId": "78ce5310-e0a7-4054-a84b-1ffec68be6e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5755273240572696"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fF095TGoFEAs",
    "outputId": "77a47efa-cc77-4621-9a25-ab1751854532"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  82, 1943],\n",
       "       [  14,  537]])"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0g5A7o-8FD-K"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p8oQhqu8FD78"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Ann_Loan_Default.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
